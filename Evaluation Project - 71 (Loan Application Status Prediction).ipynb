{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7389c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries need for Modelling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aeb4a4d",
   "metadata": {},
   "source": [
    "Loan Application Status Prediction\n",
    "Problem Statement:\n",
    "This dataset includes details of applicants who have applied for loan. The dataset includes details like credit history, loan amount, their income, dependents etc. \n",
    "\n",
    "Independent Variables:\n",
    "\n",
    "- Loan_ID\n",
    "\n",
    "- Gender\n",
    "\n",
    "- Married\n",
    "\n",
    "- Dependents\n",
    "\n",
    "- Education\n",
    "\n",
    "- Self_Employed\n",
    "\n",
    "- ApplicantIncome\n",
    "\n",
    "- CoapplicantIncome\n",
    "\n",
    "- Loan_Amount\n",
    "\n",
    "- Loan_Amount_Term\n",
    "\n",
    "- Credit History\n",
    "\n",
    "- Property_Area\n",
    "\n",
    "Dependent Variable (Target Variable):\n",
    "\n",
    "- Loan_Status\n",
    "\n",
    "You have to build a model that can predict whether the loan of the applicant will be approved or not on the basis of the details provided in the dataset. \n",
    "\n",
    "Note: The link of the dataset is below. \n",
    "\n",
    "Downlaod Files:\n",
    "https://github.com/dsrscientist/DSData/blob/master/loan_prediction.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69958cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV file and converting into dataframe\n",
    "dt=pd.read_csv('loan_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6399d9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001002    Male      No          0      Graduate            No   \n",
       "1    LP001003    Male     Yes          1      Graduate            No   \n",
       "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
       "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
       "4    LP001008    Male      No          0      Graduate            No   \n",
       "..        ...     ...     ...        ...           ...           ...   \n",
       "609  LP002978  Female      No          0      Graduate            No   \n",
       "610  LP002979    Male     Yes         3+      Graduate            No   \n",
       "611  LP002983    Male     Yes          1      Graduate            No   \n",
       "612  LP002984    Male     Yes          2      Graduate            No   \n",
       "613  LP002990  Female      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  \n",
       "0               1.0         Urban           Y  \n",
       "1               1.0         Rural           N  \n",
       "2               1.0         Urban           Y  \n",
       "3               1.0         Urban           Y  \n",
       "4               1.0         Urban           Y  \n",
       "..              ...           ...         ...  \n",
       "609             1.0         Rural           Y  \n",
       "610             1.0         Rural           Y  \n",
       "611             1.0         Urban           Y  \n",
       "612             1.0         Urban           Y  \n",
       "613             0.0     Semiurban           N  \n",
       "\n",
       "[614 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset available for analysis\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d264f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is (614, 13)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the dataset is', dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898d86a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe columns\n",
    "dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af262162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This column Loan_ID has ['LP001002' 'LP001003' 'LP001005' 'LP001006' 'LP001008' 'LP001011'\n",
      " 'LP001013' 'LP001014' 'LP001018' 'LP001020' 'LP001024' 'LP001027'\n",
      " 'LP001028' 'LP001029' 'LP001030' 'LP001032' 'LP001034' 'LP001036'\n",
      " 'LP001038' 'LP001041' 'LP001043' 'LP001046' 'LP001047' 'LP001050'\n",
      " 'LP001052' 'LP001066' 'LP001068' 'LP001073' 'LP001086' 'LP001087'\n",
      " 'LP001091' 'LP001095' 'LP001097' 'LP001098' 'LP001100' 'LP001106'\n",
      " 'LP001109' 'LP001112' 'LP001114' 'LP001116' 'LP001119' 'LP001120'\n",
      " 'LP001123' 'LP001131' 'LP001136' 'LP001137' 'LP001138' 'LP001144'\n",
      " 'LP001146' 'LP001151' 'LP001155' 'LP001157' 'LP001164' 'LP001179'\n",
      " 'LP001186' 'LP001194' 'LP001195' 'LP001197' 'LP001198' 'LP001199'\n",
      " 'LP001205' 'LP001206' 'LP001207' 'LP001213' 'LP001222' 'LP001225'\n",
      " 'LP001228' 'LP001233' 'LP001238' 'LP001241' 'LP001243' 'LP001245'\n",
      " 'LP001248' 'LP001250' 'LP001253' 'LP001255' 'LP001256' 'LP001259'\n",
      " 'LP001263' 'LP001264' 'LP001265' 'LP001266' 'LP001267' 'LP001273'\n",
      " 'LP001275' 'LP001279' 'LP001280' 'LP001282' 'LP001289' 'LP001310'\n",
      " 'LP001316' 'LP001318' 'LP001319' 'LP001322' 'LP001325' 'LP001326'\n",
      " 'LP001327' 'LP001333' 'LP001334' 'LP001343' 'LP001345' 'LP001349'\n",
      " 'LP001350' 'LP001356' 'LP001357' 'LP001367' 'LP001369' 'LP001370'\n",
      " 'LP001379' 'LP001384' 'LP001385' 'LP001387' 'LP001391' 'LP001392'\n",
      " 'LP001398' 'LP001401' 'LP001404' 'LP001405' 'LP001421' 'LP001422'\n",
      " 'LP001426' 'LP001430' 'LP001431' 'LP001432' 'LP001439' 'LP001443'\n",
      " 'LP001448' 'LP001449' 'LP001451' 'LP001465' 'LP001469' 'LP001473'\n",
      " 'LP001478' 'LP001482' 'LP001487' 'LP001488' 'LP001489' 'LP001491'\n",
      " 'LP001492' 'LP001493' 'LP001497' 'LP001498' 'LP001504' 'LP001507'\n",
      " 'LP001508' 'LP001514' 'LP001516' 'LP001518' 'LP001519' 'LP001520'\n",
      " 'LP001528' 'LP001529' 'LP001531' 'LP001532' 'LP001535' 'LP001536'\n",
      " 'LP001541' 'LP001543' 'LP001546' 'LP001552' 'LP001560' 'LP001562'\n",
      " 'LP001565' 'LP001570' 'LP001572' 'LP001574' 'LP001577' 'LP001578'\n",
      " 'LP001579' 'LP001580' 'LP001581' 'LP001585' 'LP001586' 'LP001594'\n",
      " 'LP001603' 'LP001606' 'LP001608' 'LP001610' 'LP001616' 'LP001630'\n",
      " 'LP001633' 'LP001634' 'LP001636' 'LP001637' 'LP001639' 'LP001640'\n",
      " 'LP001641' 'LP001643' 'LP001644' 'LP001647' 'LP001653' 'LP001656'\n",
      " 'LP001657' 'LP001658' 'LP001664' 'LP001665' 'LP001666' 'LP001669'\n",
      " 'LP001671' 'LP001673' 'LP001674' 'LP001677' 'LP001682' 'LP001688'\n",
      " 'LP001691' 'LP001692' 'LP001693' 'LP001698' 'LP001699' 'LP001702'\n",
      " 'LP001708' 'LP001711' 'LP001713' 'LP001715' 'LP001716' 'LP001720'\n",
      " 'LP001722' 'LP001726' 'LP001732' 'LP001734' 'LP001736' 'LP001743'\n",
      " 'LP001744' 'LP001749' 'LP001750' 'LP001751' 'LP001754' 'LP001758'\n",
      " 'LP001760' 'LP001761' 'LP001765' 'LP001768' 'LP001770' 'LP001776'\n",
      " 'LP001778' 'LP001784' 'LP001786' 'LP001788' 'LP001790' 'LP001792'\n",
      " 'LP001798' 'LP001800' 'LP001806' 'LP001807' 'LP001811' 'LP001813'\n",
      " 'LP001814' 'LP001819' 'LP001824' 'LP001825' 'LP001835' 'LP001836'\n",
      " 'LP001841' 'LP001843' 'LP001844' 'LP001846' 'LP001849' 'LP001854'\n",
      " 'LP001859' 'LP001864' 'LP001865' 'LP001868' 'LP001870' 'LP001871'\n",
      " 'LP001872' 'LP001875' 'LP001877' 'LP001882' 'LP001883' 'LP001884'\n",
      " 'LP001888' 'LP001891' 'LP001892' 'LP001894' 'LP001896' 'LP001900'\n",
      " 'LP001903' 'LP001904' 'LP001907' 'LP001908' 'LP001910' 'LP001914'\n",
      " 'LP001915' 'LP001917' 'LP001922' 'LP001924' 'LP001925' 'LP001926'\n",
      " 'LP001931' 'LP001935' 'LP001936' 'LP001938' 'LP001940' 'LP001945'\n",
      " 'LP001947' 'LP001949' 'LP001953' 'LP001954' 'LP001955' 'LP001963'\n",
      " 'LP001964' 'LP001972' 'LP001974' 'LP001977' 'LP001978' 'LP001990'\n",
      " 'LP001993' 'LP001994' 'LP001996' 'LP001998' 'LP002002' 'LP002004'\n",
      " 'LP002006' 'LP002008' 'LP002024' 'LP002031' 'LP002035' 'LP002036'\n",
      " 'LP002043' 'LP002050' 'LP002051' 'LP002053' 'LP002054' 'LP002055'\n",
      " 'LP002065' 'LP002067' 'LP002068' 'LP002082' 'LP002086' 'LP002087'\n",
      " 'LP002097' 'LP002098' 'LP002100' 'LP002101' 'LP002103' 'LP002106'\n",
      " 'LP002110' 'LP002112' 'LP002113' 'LP002114' 'LP002115' 'LP002116'\n",
      " 'LP002119' 'LP002126' 'LP002128' 'LP002129' 'LP002130' 'LP002131'\n",
      " 'LP002137' 'LP002138' 'LP002139' 'LP002140' 'LP002141' 'LP002142'\n",
      " 'LP002143' 'LP002144' 'LP002149' 'LP002151' 'LP002158' 'LP002160'\n",
      " 'LP002161' 'LP002170' 'LP002175' 'LP002178' 'LP002180' 'LP002181'\n",
      " 'LP002187' 'LP002188' 'LP002190' 'LP002191' 'LP002194' 'LP002197'\n",
      " 'LP002201' 'LP002205' 'LP002209' 'LP002211' 'LP002219' 'LP002223'\n",
      " 'LP002224' 'LP002225' 'LP002226' 'LP002229' 'LP002231' 'LP002234'\n",
      " 'LP002236' 'LP002237' 'LP002239' 'LP002243' 'LP002244' 'LP002250'\n",
      " 'LP002255' 'LP002262' 'LP002263' 'LP002265' 'LP002266' 'LP002272'\n",
      " 'LP002277' 'LP002281' 'LP002284' 'LP002287' 'LP002288' 'LP002296'\n",
      " 'LP002297' 'LP002300' 'LP002301' 'LP002305' 'LP002308' 'LP002314'\n",
      " 'LP002315' 'LP002317' 'LP002318' 'LP002319' 'LP002328' 'LP002332'\n",
      " 'LP002335' 'LP002337' 'LP002341' 'LP002342' 'LP002345' 'LP002347'\n",
      " 'LP002348' 'LP002357' 'LP002361' 'LP002362' 'LP002364' 'LP002366'\n",
      " 'LP002367' 'LP002368' 'LP002369' 'LP002370' 'LP002377' 'LP002379'\n",
      " 'LP002386' 'LP002387' 'LP002390' 'LP002393' 'LP002398' 'LP002401'\n",
      " 'LP002403' 'LP002407' 'LP002408' 'LP002409' 'LP002418' 'LP002422'\n",
      " 'LP002424' 'LP002429' 'LP002434' 'LP002435' 'LP002443' 'LP002444'\n",
      " 'LP002446' 'LP002447' 'LP002448' 'LP002449' 'LP002453' 'LP002455'\n",
      " 'LP002459' 'LP002467' 'LP002472' 'LP002473' 'LP002478' 'LP002484'\n",
      " 'LP002487' 'LP002489' 'LP002493' 'LP002494' 'LP002500' 'LP002501'\n",
      " 'LP002502' 'LP002505' 'LP002515' 'LP002517' 'LP002519' 'LP002522'\n",
      " 'LP002524' 'LP002527' 'LP002529' 'LP002530' 'LP002531' 'LP002533'\n",
      " 'LP002534' 'LP002536' 'LP002537' 'LP002541' 'LP002543' 'LP002544'\n",
      " 'LP002545' 'LP002547' 'LP002555' 'LP002556' 'LP002560' 'LP002562'\n",
      " 'LP002571' 'LP002582' 'LP002585' 'LP002586' 'LP002587' 'LP002588'\n",
      " 'LP002600' 'LP002602' 'LP002603' 'LP002606' 'LP002615' 'LP002618'\n",
      " 'LP002619' 'LP002622' 'LP002624' 'LP002625' 'LP002626' 'LP002634'\n",
      " 'LP002637' 'LP002640' 'LP002643' 'LP002648' 'LP002652' 'LP002659'\n",
      " 'LP002670' 'LP002682' 'LP002683' 'LP002684' 'LP002689' 'LP002690'\n",
      " 'LP002692' 'LP002693' 'LP002697' 'LP002699' 'LP002705' 'LP002706'\n",
      " 'LP002714' 'LP002716' 'LP002717' 'LP002720' 'LP002723' 'LP002729'\n",
      " 'LP002731' 'LP002732' 'LP002734' 'LP002738' 'LP002739' 'LP002740'\n",
      " 'LP002741' 'LP002743' 'LP002753' 'LP002755' 'LP002757' 'LP002767'\n",
      " 'LP002768' 'LP002772' 'LP002776' 'LP002777' 'LP002778' 'LP002784'\n",
      " 'LP002785' 'LP002788' 'LP002789' 'LP002792' 'LP002794' 'LP002795'\n",
      " 'LP002798' 'LP002804' 'LP002807' 'LP002813' 'LP002820' 'LP002821'\n",
      " 'LP002832' 'LP002833' 'LP002836' 'LP002837' 'LP002840' 'LP002841'\n",
      " 'LP002842' 'LP002847' 'LP002855' 'LP002862' 'LP002863' 'LP002868'\n",
      " 'LP002872' 'LP002874' 'LP002877' 'LP002888' 'LP002892' 'LP002893'\n",
      " 'LP002894' 'LP002898' 'LP002911' 'LP002912' 'LP002916' 'LP002917'\n",
      " 'LP002925' 'LP002926' 'LP002928' 'LP002931' 'LP002933' 'LP002936'\n",
      " 'LP002938' 'LP002940' 'LP002941' 'LP002943' 'LP002945' 'LP002948'\n",
      " 'LP002949' 'LP002950' 'LP002953' 'LP002958' 'LP002959' 'LP002960'\n",
      " 'LP002961' 'LP002964' 'LP002974' 'LP002978' 'LP002979' 'LP002983'\n",
      " 'LP002984' 'LP002990'] unique elements\n",
      "****************************************************************************************************\n",
      "This column Gender has ['Male' 'Female' nan] unique elements\n",
      "****************************************************************************************************\n",
      "This column Married has ['No' 'Yes' nan] unique elements\n",
      "****************************************************************************************************\n",
      "This column Dependents has ['0' '1' '2' '3+' nan] unique elements\n",
      "****************************************************************************************************\n",
      "This column Education has ['Graduate' 'Not Graduate'] unique elements\n",
      "****************************************************************************************************\n",
      "This column Self_Employed has ['No' 'Yes' nan] unique elements\n",
      "****************************************************************************************************\n",
      "This column ApplicantIncome has [ 5849  4583  3000  2583  6000  5417  2333  3036  4006 12841  3200  2500\n",
      "  3073  1853  1299  4950  3596  3510  4887  2600  7660  5955  3365  3717\n",
      "  9560  2799  4226  1442  3750  4166  3167  4692  3500 12500  2275  1828\n",
      "  3667  3748  3600  1800  2400  3941  4695  3410  5649  5821  2645  4000\n",
      "  1928  3086  4230  4616 11500  2708  2132  3366  8080  3357  3029  2609\n",
      "  4945  5726 10750  7100  4300  3208  1875  4755  5266  1000  3333  3846\n",
      "  2395  1378  3988  2366  8566  5695  2958  6250  3273  4133  3620  6782\n",
      "  2484  1977  4188  1759  4288  4843 13650  4652  3816  3052 11417  7333\n",
      "  3800  2071  5316  2929  3572  7451  5050 14583  2214  5568 10408  5667\n",
      "  2137  2957  3692 23803  3865 10513  6080 20166  2014  2718  3459  4895\n",
      "  3316 14999  4200  5042  6950  2698 11757  2330 14866  1538 10000  4860\n",
      "  6277  2577  9166  2281  3254 39999  9538  2980  1863  7933  3089  4167\n",
      "  9323  3707  2439  2237  8000  1820 51763  3522  5708  4344  3497  2045\n",
      "  5516  6400  1916  4600 33846  3625 39147  2178  2383   674  9328  4885\n",
      " 12000  6033  3858  4191  3125  8333  1907  3416 11000  4923  3992  3917\n",
      "  4408  3244  3975  2479  3418  3430  7787  5703  3173  3850   150  3727\n",
      "  5000  4283  2221  4009  2971  7578  3250  4735  4758  2491  3716  3189\n",
      "  3155  5500  5746  3463  3812  3315  5819  2510  2965  3406  6050  9703\n",
      "  6608  2882  1809  1668  3427  2661 16250  3083  6045  5250 14683  4931\n",
      "  6083  2060  3481  7200  5166  4095  4708  4333  2876  3237 11146  2833\n",
      "  2620  3900  2750  3993  3103  4100  4053  3927  2301  1811 20667  3158\n",
      "  3704  4124  9508  3075  4400  3153  4416  6875  4666  2875  1625  2000\n",
      "  3762 20233  7667  2917  2927  2507  2473  3399  2058  3541  4342  3601\n",
      "  3166 15000  8666  4917  5818  4384  2935 63337  9833  5503  1830  4160\n",
      "  2647  2378  4554  2499  3523  6333  2625  9083  8750  2666  2423  3813\n",
      "  3875  5167  4723  4750  3013  6822  6216  5124  6325 19730 15759  5185\n",
      "  3062  2764  4817  4310  3069  5391  5941  7167  4566  2346  3010  5488\n",
      "  9167  9504  1993  3100  3276  3180  3033  3902  1500  2889  2755  1963\n",
      "  7441  4547  2167  2213  8300 81000  3867  6256  6096  2253  2149  2995\n",
      "  1600  1025  3246  5829  2720  7250 14880  4606  5935  2920  2717  8624\n",
      "  6500 12876  2425 10047  1926 10416  7142  3660  7901  4707 37719  3466\n",
      "  3539  3340  2769  2309  1958  3948  2483  7085  3859  4301  3708  4354\n",
      "  8334  2083  7740  3015  5191  2947 16692   210  3450  2653  4691  5532\n",
      " 16525  6700  2873 16667  4350  3095 10833  3547 18333  2435  2699  5333\n",
      "  3691 17263  3597  3326  4625  2895  6283   645  3159  4865  4050  3814\n",
      " 20833  3583 13262  3598  6065  3283  2130  5815  2031  3074  4683  3400\n",
      "  2192  5677  7948  4680 17500  3775  5285  2679  6783  4281  3588 11250\n",
      " 18165  2550  6133  3617  6417  4608  2138  3652  2239  3017  2768  3358\n",
      "  2526  2785  6633  2492  2454  3593  5468  2667 10139  3887  4180  3675\n",
      " 19484  5923  5800  8799  4467  3417  5116 16666  6125  6406  3087  3229\n",
      "  1782  3182  6540  1836  1880  2787  2297  2165  2726  9357 16120  3833\n",
      "  6383  2987  9963  5780   416  2894  3676  3987  3232  2900  4106  8072\n",
      "  7583] unique elements\n",
      "****************************************************************************************************\n",
      "This column CoapplicantIncome has [0.00000000e+00 1.50800000e+03 2.35800000e+03 4.19600000e+03\n",
      " 1.51600000e+03 2.50400000e+03 1.52600000e+03 1.09680000e+04\n",
      " 7.00000000e+02 1.84000000e+03 8.10600000e+03 2.84000000e+03\n",
      " 1.08600000e+03 3.50000000e+03 5.62500000e+03 1.91100000e+03\n",
      " 1.91700000e+03 2.92500000e+03 2.25300000e+03 1.04000000e+03\n",
      " 2.08300000e+03 3.36900000e+03 1.66700000e+03 3.00000000e+03\n",
      " 2.06700000e+03 1.33000000e+03 1.45900000e+03 7.21000000e+03\n",
      " 1.66800000e+03 1.21300000e+03 2.33600000e+03 3.44000000e+03\n",
      " 2.27500000e+03 1.64400000e+03 1.16700000e+03 1.59100000e+03\n",
      " 2.20000000e+03 2.25000000e+03 2.85900000e+03 3.79600000e+03\n",
      " 3.44900000e+03 4.59500000e+03 2.25400000e+03 3.06600000e+03\n",
      " 1.87500000e+03 1.77400000e+03 4.75000000e+03 3.02200000e+03\n",
      " 4.00000000e+03 2.16600000e+03 1.88100000e+03 2.53100000e+03\n",
      " 2.00000000e+03 2.11800000e+03 4.16700000e+03 2.90000000e+03\n",
      " 5.65400000e+03 1.82000000e+03 2.30200000e+03 9.97000000e+02\n",
      " 3.54100000e+03 3.26300000e+03 3.80600000e+03 3.58300000e+03\n",
      " 7.54000000e+02 1.03000000e+03 1.12600000e+03 3.60000000e+03\n",
      " 2.33300000e+03 4.11400000e+03 2.28300000e+03 1.39800000e+03\n",
      " 2.14200000e+03 2.66700000e+03 8.98000000e+03 2.01400000e+03\n",
      " 1.64000000e+03 3.85000000e+03 2.56900000e+03 1.92900000e+03\n",
      " 7.75000000e+03 1.43000000e+03 2.03400000e+03 4.48600000e+03\n",
      " 1.42500000e+03 1.66600000e+03 8.30000000e+02 3.75000000e+03\n",
      " 1.04100000e+03 1.28000000e+03 1.44700000e+03 3.16600000e+03\n",
      " 3.33300000e+03 1.76900000e+03 7.36000000e+02 1.96400000e+03\n",
      " 1.61900000e+03 1.13000000e+04 1.45100000e+03 7.25000000e+03\n",
      " 5.06300000e+03 2.13800000e+03 5.29600000e+03 2.58300000e+03\n",
      " 2.36500000e+03 2.81600000e+03 2.50000000e+03 1.08300000e+03\n",
      " 1.25000000e+03 3.02100000e+03 9.83000000e+02 1.80000000e+03\n",
      " 1.77500000e+03 2.38300000e+03 1.71700000e+03 2.79100000e+03\n",
      " 1.01000000e+03 1.69500000e+03 2.05400000e+03 2.59800000e+03\n",
      " 1.77900000e+03 1.26000000e+03 5.00000000e+03 1.98300000e+03\n",
      " 5.70100000e+03 1.30000000e+03 4.41700000e+03 4.33300000e+03\n",
      " 1.84300000e+03 1.86800000e+03 3.89000000e+03 2.16700000e+03\n",
      " 7.10100000e+03 2.10000000e+03 4.25000000e+03 2.20900000e+03\n",
      " 3.44700000e+03 1.38700000e+03 1.81100000e+03 1.56000000e+03\n",
      " 1.85700000e+03 2.22300000e+03 1.84200000e+03 3.27400000e+03\n",
      " 2.42600000e+03 8.00000000e+02 9.85799988e+02 3.05300000e+03\n",
      " 2.41600000e+03 3.33400000e+03 2.54100000e+03 2.93400000e+03\n",
      " 1.75000000e+03 1.80300000e+03 1.86300000e+03 2.40500000e+03\n",
      " 2.13400000e+03 1.89000000e+02 1.59000000e+03 2.98500000e+03\n",
      " 4.98300000e+03 2.16000000e+03 2.45100000e+03 1.79300000e+03\n",
      " 1.83300000e+03 4.49000000e+03 6.88000000e+02 4.60000000e+03\n",
      " 1.58700000e+03 1.22900000e+03 2.33000000e+03 2.45800000e+03\n",
      " 3.23000000e+03 2.16800000e+03 4.58300000e+03 6.25000000e+03\n",
      " 5.05000000e+02 3.16700000e+03 3.66700000e+03 3.03300000e+03\n",
      " 5.26600000e+03 7.87300000e+03 1.98700000e+03 9.23000000e+02\n",
      " 4.99600000e+03 4.23200000e+03 1.60000000e+03 3.13600000e+03\n",
      " 2.41700000e+03 2.11500000e+03 1.62500000e+03 1.40000000e+03\n",
      " 4.84000000e+02 2.00000000e+04 2.40000000e+03 2.03300000e+03\n",
      " 3.23700000e+03 2.77300000e+03 1.41700000e+03 1.71900000e+03\n",
      " 4.30000000e+03 1.61200008e+01 2.34000000e+03 1.85100000e+03\n",
      " 1.12500000e+03 5.06400000e+03 1.99300000e+03 8.33300000e+03\n",
      " 1.21000000e+03 1.37600000e+03 1.71000000e+03 1.54200000e+03\n",
      " 1.25500000e+03 1.45600000e+03 1.73300000e+03 2.46600000e+03\n",
      " 4.08300000e+03 2.18800000e+03 1.66400000e+03 2.91700000e+03\n",
      " 2.07900000e+03 1.50000000e+03 4.64800000e+03 1.01400000e+03\n",
      " 1.87200000e+03 1.60300000e+03 3.15000000e+03 2.43600000e+03\n",
      " 2.78500000e+03 1.13100000e+03 2.15700000e+03 9.13000000e+02\n",
      " 1.70000000e+03 2.85700000e+03 4.41600000e+03 3.68300000e+03\n",
      " 5.62400000e+03 5.30200000e+03 1.48300000e+03 6.66700000e+03\n",
      " 3.01300000e+03 1.28700000e+03 2.00400000e+03 2.03500000e+03\n",
      " 6.66600000e+03 3.66600000e+03 3.42800000e+03 1.63200000e+03\n",
      " 1.91500000e+03 1.74200000e+03 1.42400000e+03 7.16600000e+03\n",
      " 2.08700000e+03 1.30200000e+03 5.50000000e+03 2.04200000e+03\n",
      " 3.90600000e+03 5.36000000e+02 2.84500000e+03 2.52400000e+03\n",
      " 6.63000000e+02 1.95000000e+03 1.78300000e+03 2.01600000e+03\n",
      " 2.37500000e+03 3.25000000e+03 4.26600000e+03 1.03200000e+03\n",
      " 2.66900000e+03 2.30600000e+03 2.42000000e+02 2.06400000e+03\n",
      " 4.61000000e+02 2.21000000e+03 2.73900000e+03 2.23200000e+03\n",
      " 3.38370000e+04 1.52200000e+03 3.41600000e+03 3.30000000e+03\n",
      " 1.00000000e+03 4.16670000e+04 2.79200000e+03 4.30100000e+03\n",
      " 3.80000000e+03 1.41100000e+03 2.40000000e+02] unique elements\n",
      "****************************************************************************************************\n",
      "This column LoanAmount has [ nan 128.  66. 120. 141. 267.  95. 158. 168. 349.  70. 109. 200. 114.\n",
      "  17. 125. 100.  76. 133. 115. 104. 315. 116. 112. 151. 191. 122. 110.\n",
      "  35. 201.  74. 106. 320. 144. 184.  80.  47.  75. 134.  96.  88.  44.\n",
      " 286.  97. 135. 180.  99. 165. 258. 126. 312. 136. 172.  81. 187. 113.\n",
      " 176. 130. 111. 167. 265.  50. 210. 175. 131. 188.  25. 137. 160. 225.\n",
      " 216.  94. 139. 152. 118. 185. 154.  85. 259. 194.  93. 370. 182. 650.\n",
      " 102. 290.  84. 242. 129.  30. 244. 600. 255.  98. 275. 121.  63. 700.\n",
      "  87. 101. 495.  67.  73. 260. 108.  58.  48. 164. 170.  83.  90. 166.\n",
      " 124.  55.  59. 127. 214. 240.  72.  60. 138.  42. 280. 140. 155. 123.\n",
      " 279. 192. 304. 330. 150. 207. 436.  78.  54.  89. 143. 105. 132. 480.\n",
      "  56. 159. 300. 376. 117.  71. 490. 173.  46. 228. 308. 236. 570. 380.\n",
      " 296. 156. 103.  45.  65.  53. 360.  62. 218. 178. 239. 405. 148. 190.\n",
      " 149. 153. 162. 230.  86. 234. 246. 500. 186. 119. 107. 209. 208. 243.\n",
      "  40. 250. 311. 400. 161. 196. 324. 157. 145. 181.  26. 211.   9. 205.\n",
      "  36.  61. 146. 292. 142. 350. 496. 253.] unique elements\n",
      "****************************************************************************************************\n",
      "This column Loan_Amount_Term has [360. 120. 240.  nan 180.  60. 300. 480.  36.  84.  12.] unique elements\n",
      "****************************************************************************************************\n",
      "This column Credit_History has [ 1.  0. nan] unique elements\n",
      "****************************************************************************************************\n",
      "This column Property_Area has ['Urban' 'Rural' 'Semiurban'] unique elements\n",
      "****************************************************************************************************\n",
      "This column Loan_Status has ['Y' 'N'] unique elements\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# To find the data type of the dataset\n",
    "for col in dt:\n",
    "    print ('This column', col ,'has', dt[col].unique(),'unique elements')\n",
    "    print ('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9224525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing for the null values in the dataset\n",
    "dt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5807c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(dt.isnull(), yticklabels = False, cbar = False, cmap ='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe33807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Getting information on the dataset\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3bcc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.116605</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>-0.045306</td>\n",
       "      <td>-0.014715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>-0.116605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188619</td>\n",
       "      <td>-0.059878</td>\n",
       "      <td>-0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.188619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>-0.008433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>-0.045306</td>\n",
       "      <td>-0.059878</td>\n",
       "      <td>0.039447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>-0.014715</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>-0.008433</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "ApplicantIncome           1.000000          -0.116605    0.570909   \n",
       "CoapplicantIncome        -0.116605           1.000000    0.188619   \n",
       "LoanAmount                0.570909           0.188619    1.000000   \n",
       "Loan_Amount_Term         -0.045306          -0.059878    0.039447   \n",
       "Credit_History           -0.014715          -0.002056   -0.008433   \n",
       "\n",
       "                   Loan_Amount_Term  Credit_History  \n",
       "ApplicantIncome           -0.045306       -0.014715  \n",
       "CoapplicantIncome         -0.059878       -0.002056  \n",
       "LoanAmount                 0.039447       -0.008433  \n",
       "Loan_Amount_Term           1.000000        0.001470  \n",
       "Credit_History             0.001470        1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find the correlection in the dataset\n",
    "dt.corr().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "067f5fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e=dt.corr()\n",
    "# Ploting the heatmap for better understanding\n",
    "plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(e,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34728d19",
   "metadata": {},
   "source": [
    "# Exploratory data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c81d54e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Loan_Status', ylabel='count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3da430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    422\n",
       "N    192\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9676d9e",
   "metadata": {},
   "source": [
    "Total data has 614 rows where N is only 192 which is not even 50% so upscaling have to be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe9d36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Gender', ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Gender'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a065348",
   "metadata": {},
   "source": [
    "the male applications are more than female applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0ea4c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Married', ylabel='count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Married'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f031a1d8",
   "metadata": {},
   "source": [
    "Married people applicaions are more that others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01c0236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Dependents', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT8ElEQVR4nO3df5BdZ33f8ffHsjAuuMGu1q4sKZHjijQyAbnZqJm4Q1xMsOO2yDCYyFNcJ3UjtyMnMIE0doYW3I5m6PBrOhBIRO0gGIKq1hhUmgYUjY3HBCyvXCEsCRcVO7aQai0/XOxOqyDx7R/37PFFWknX8p69++P9mrlzz3nu85z97h3pfvb8em6qCkmSAM4adgGSpJnDUJAktQwFSVLLUJAktQwFSVLr7GEX8EIsWrSoli9fPuwyJGlW2blz53eqamSy12Z1KCxfvpyxsbFhlyFJs0qSvzzZax4+kiS1DAVJUstQkCS1OguFJC9OsiPJ15LsSXJH0/7uJN9Osqt5XNs35vYk+5M8muTqrmqTJE2uyxPNR4DXVNWzSRYCDyT5b81rH6yq9/V3TrISWAtcBlwM/HmSl1fVsQ5rlCT16WxPoXqebVYXNo9Tzb63BthcVUeq6jFgP7C6q/okSSfq9JxCkgVJdgGHgW1V9WDz0q1Jdie5K8n5TdsS4Mm+4QeatuO3uS7JWJKx8fHxLsuXpHmn01CoqmNVtQpYCqxO8grgo8ClwCrgEPD+pnsm28Qk29xYVaNVNToyMum9F5KkMzQtVx9V1dPAfcA1VfVUExY/Aj7Gc4eIDgDL+oYtBQ5OR32SpJ7OTjQnGQF+WFVPJzkXeC3w75IsrqpDTbc3AI80y1uBP0nyAXonmlcAO15oHT//u594oZuYM3a+958MuwRJM1yXVx8tBjYlWUBvj2RLVX0+ySeTrKJ3aOhx4BaAqtqTZAuwFzgKrPfKI0maXp2FQlXtBi6fpP3GU4zZAGzoqiZJ0ql5R7MkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqdVZKCR5cZIdSb6WZE+SO5r2C5JsS/LN5vn8vjG3J9mf5NEkV3dVmyRpcl3uKRwBXlNVrwJWAdck+UXgNmB7Va0AtjfrJFkJrAUuA64BPpJkQYf1SZKO01koVM+zzerC5lHAGmBT074JuK5ZXgNsrqojVfUYsB9Y3VV9kqQTdXpOIcmCJLuAw8C2qnoQuKiqDgE0zxc23ZcAT/YNP9C0Hb/NdUnGkoyNj493Wb4kzTudhkJVHauqVcBSYHWSV5yieybbxCTb3FhVo1U1OjIyMkWVSpJgmq4+qqqngfvonSt4KsligOb5cNPtALCsb9hS4OB01CdJ6uny6qORJC9rls8FXgt8A9gK3NR0uwn4XLO8FVib5JwklwArgB1d1SdJOtHZHW57MbCpuYLoLGBLVX0+yVeALUluBp4Argeoqj1JtgB7gaPA+qo61mF9kqTjdBYKVbUbuHyS9u8CV51kzAZgQ1c1SZJOzTuaJUktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEmtzkIhybIk9ybZl2RPkrc27e9O8u0ku5rHtX1jbk+yP8mjSa7uqjZJ0uTO7nDbR4G3V9XDSc4DdibZ1rz2wap6X3/nJCuBtcBlwMXAnyd5eVUd67BGSVKfzvYUqupQVT3cLD8D7AOWnGLIGmBzVR2pqseA/cDqruqTJJ1oWs4pJFkOXA482DTdmmR3kruSnN+0LQGe7Bt2gElCJMm6JGNJxsbHx7ssW5Lmnc5DIclLgbuBt1XVD4CPApcCq4BDwPsnuk4yvE5oqNpYVaNVNToyMtJN0ZI0T3UaCkkW0guET1XVZwCq6qmqOlZVPwI+xnOHiA4Ay/qGLwUOdlmfJOnHdXn1UYA7gX1V9YG+9sV93d4APNIsbwXWJjknySXACmBHV/VJkk7U5dVHVwA3Al9Psqtp+33ghiSr6B0aehy4BaCq9iTZAuyld+XSeq88kqTp1VkoVNUDTH6e4E9PMWYDsKGrmiRJp+YdzZKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKkVmehkGRZknuT7EuyJ8lbm/YLkmxL8s3m+fy+Mbcn2Z/k0SRXd1WbJGlyXe4pHAXeXlU/C/wisD7JSuA2YHtVrQC2N+s0r60FLgOuAT6SZEGH9UmSjtNZKFTVoap6uFl+BtgHLAHWAJuabpuA65rlNcDmqjpSVY8B+4HVXdUnSTrRQKGQZPsgbacYvxy4HHgQuKiqDkEvOIALm25LgCf7hh1o2o7f1rokY0nGxsfHBy1BkjSAU4ZCkhcnuQBYlOT85nzABc2H/MWD/IAkLwXuBt5WVT84VddJ2uqEhqqNVTVaVaMjIyODlCBJGtDZp3n9FuBt9AJgJ899cP8A+IPTbTzJQnqB8Kmq+kzT/FSSxVV1KMli4HDTfgBY1jd8KXBwkF9CkjQ1TrmnUFX/vqouAd5RVT9dVZc0j1dV1YdPNTZJgDuBfVX1gb6XtgI3Ncs3AZ/ra1+b5JwklwArgB1n8DtJks7Q6fYUAKiqDyX5JWB5/5iq+sQphl0B3Ah8Pcmupu33gfcAW5LcDDwBXN9sa0+SLcBeelcura+qY8/rt5EkvSADhUKSTwKXAruAiQ/qAk4aClX1AJOfJwC46iRjNgAbBqlJkjT1BgoFYBRYWVUnnPiVJM0dg96n8AjwN7ssRJI0fIPuKSwC9ibZARyZaKyq13dSlSRpKAYNhXd3WYQkaWYY9OqjL3VdiCRp+Aa9+ugZnru7+EXAQuD/VNVf76owSdL0G3RP4bz+9STX4WR1kjTnnNEsqVX1WeA1U1uKJGnYBj189Ma+1bPo3bfgPQuSNMcMevXRP+pbPgo8Tu/7DyRJc8ig5xR+o+tCJEnDN+iX7CxNck+Sw0meSnJ3kqVdFydJml6Dnmj+Y3pTW19M79vQ/kvTJkmaQwYNhZGq+uOqOto8Pg74tWeSNMcMGgrfSfKWJAuax1uA73ZZmCRp+g0aCv8UeDPwv4BDwJsATz5L0hwz6CWp/xa4qaq+D5DkAuB99MJCkjRHDLqn8MqJQACoqu8Bl3dTkiRpWAYNhbOSnD+x0uwpDLqXIUmaJQb9YH8/8BdJ/jO96S3ejN+lLElzzqB3NH8iyRi9SfACvLGq9nZamSRp2g08S2pV7a2qD1fVhwYJhCR3NXdAP9LX9u4k306yq3lc2/fa7Un2J3k0ydXP/1eRJL1QZzR19oA+DlwzSfsHq2pV8/hTgCQrgbXAZc2YjyRZ0GFtkqRJdBYKVXU/8L0Bu68BNlfVkap6DNiPX+IjSdOuyz2Fk7k1ye7m8NLEFU1LgCf7+hxo2k6QZF2SsSRj4+PjXdcqSfPKdIfCR4FLgVX07ox+f9OeSfpO+iU+VbWxqkaranRkxOmXJGkqTWsoVNVTVXWsqn4EfIznDhEdAJb1dV0KHJzO2iRJ0xwKSRb3rb4BmLgyaSuwNsk5SS4BVgA7prM2SVKHdyUn+TRwJbAoyQHgXcCVSVbROzT0OHALQFXtSbIF2Evv6z7XV9WxrmqTJE2us1Coqhsmab7zFP034F3SkjRUw7j6SJI0QxkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJanUWCknuSnI4ySN9bRck2Zbkm83z+X2v3Z5kf5JHk1zdVV2SpJPrck/h48A1x7XdBmyvqhXA9madJCuBtcBlzZiPJFnQYW2SpEmc3dWGq+r+JMuPa14DXNksbwLuA36vad9cVUeAx5LsB1YDX+mqPj1/T/ybnxt2CTPGT/7rr7/gbVzxoSumoJK54cu/9eVhl6DGdJ9TuKiqDgE0zxc27UuAJ/v6HWjaTpBkXZKxJGPj4+OdFitJ881MOdGcSdpqso5VtbGqRqtqdGRkpOOyJGl+me5QeCrJYoDm+XDTfgBY1tdvKXBwmmuTpHlvukNhK3BTs3wT8Lm+9rVJzklyCbAC2DHNtUnSvNfZieYkn6Z3UnlRkgPAu4D3AFuS3Aw8AVwPUFV7kmwB9gJHgfVVdayr2iRJk+vy6qMbTvLSVSfpvwHY0FU9kqTTmyknmiVJM4ChIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpNbZw/ihSR4HngGOAUerajTJBcB/BJYDjwNvrqrvD6M+SZqvhrmn8PeralVVjTbrtwHbq2oFsL1ZlyRNo6HsKZzEGuDKZnkTcB/we8MqRtLs8qVX//KwS5gxfvn+L53x2GHtKRTwxSQ7k6xr2i6qqkMAzfOFkw1Msi7JWJKx8fHxaSpXkuaHYe0pXFFVB5NcCGxL8o1BB1bVRmAjwOjoaHVVoCTNR0PZU6iqg83zYeAeYDXwVJLFAM3z4WHUJknz2bSHQpKXJDlvYhl4HfAIsBW4qel2E/C56a5Nkua7YRw+ugi4J8nEz/+TqvqzJA8BW5LcDDwBXD+E2iRpXpv2UKiqbwGvmqT9u8BV012PJOk53tEsSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWoZCpKklqEgSWrNuFBIck2SR5PsT3LbsOuRpPlkRoVCkgXAHwC/CqwEbkiycrhVSdL8MaNCAVgN7K+qb1XVXwGbgTVDrkmS5o1U1bBraCV5E3BNVf2zZv1G4O9W1a19fdYB65rVnwEenfZCn79FwHeGXcQc4vs5tXw/p85seS9/qqpGJnvh7Omu5DQySduPpVZVbQQ2Tk85UyPJWFWNDruOucL3c2r5fk6dufBezrTDRweAZX3rS4GDQ6pFkuadmRYKDwErklyS5EXAWmDrkGuSpHljRh0+qqqjSW4FvgAsAO6qqj1DLmsqzKrDXbOA7+fU8v2cOrP+vZxRJ5olScM10w4fSZKGyFCQJLUMhY45bcfUSXJXksNJHhl2LbNdkmVJ7k2yL8meJG8ddk2zSZIXJ9mR5GvN+3fHsGuaKp5T6FAzbcf/AH6F3uW2DwE3VNXeoRY2SyV5NfAs8ImqesWw65nNkiwGFlfVw0nOA3YC1/lvczBJArykqp5NshB4AHhrVX21r8/jVbV8WDWeKfcUuuW0HVOoqu4HvjfsOuaCqjpUVQ83y88A+4Alw61q9qieZ5vVhc1jTvyFbSh0awnwZN/6AfyPpxkmyXLgcuDBIZcyqyRZkGQXcBjYVlVz4v2bUfcpzEGnnbZDGqYkLwXuBt5WVT8Ydj2zSVUdA1YleRlwT5JX0DsScH3T5eImNAC+XFXrp7/K589Q6JbTdmjGao6F3w18qqo+M+x6ZquqejrJffQm89wAbID2nMKqYdZ2Jjx81C2n7dCM1JwovRPYV1UfGHY9s02SkWYPgSTnAq8FvjHUoqaIodChqjoKTEzbsQ/YMkem7RiKJJ8GvgL8TJIDSW4edk2z2BXAjcBrkuxqHtcOu6hZZDFwb5Ld9P7421ZVnx9yTVPCS1IlSS33FCRJLUNBktQyFCRJLUNBktQyFCRJLUNBc16SY80ll3uaWS1/J8nQ/u0neTzJojMce12SlVNdkzTBUNB88H+ralVVXUZvxtprgXcNuaYzdR1gKKgzhoLmlao6DKwDbk3PgiTvTfJQkt1JbgFIcmWS+5Pck2Rvkj+c2LtI8rokX0nycJL/1MwfNLEHcEfT/vUkf7tp/xtJvpjkvyf5I/rmxErylmZe/l1J/qiZbp0kzybZ0OzZfDXJRUl+CXg98N6m/6VJfrupb3eSzdP6ZmpOMhQ071TVt+j9278QuBn431X1C8AvAL+Z5JKm62rg7cDPAZcCb2wO+7wTeG1V/R1gDPidvs1/p2n/KPCOpu1dwANVdTm9aU5+EiDJzwK/BlzRzJFzDPjHzZiXAF+tqlcB9wO/WVV/0Yz/3WbP538CtwGXV9UrgX8+Ve+R5i8nxNN8NfHX+uuAVyZ5U7P+E8AK4K+AHU2ATEyx8feA/0fv8M2Xe9MH8SJ6U29MmJhYbifwxmb51RPLVfVfk3y/ab8K+HngoWZb59Kbhpnm53++b1u/cpLfYzfwqSSfBT470G8unYKhoHknyU/T+6v8ML1w+K2q+sJxfa7kxGnOq+m/rapuOMnmjzTPx/jx/1+TzScTYFNV3T7Jaz+s5+agOX5b/f4BvdB5PfCvklzWzLklnREPH2leSTIC/CHw4eZD9wvAv2imkSbJy5O8pOm+upnh9ix6h3keAL4KXJHkbzX9/1qSl5/mx95Pc1goya8C5zft24E3Jbmwee2CJD91mm09A5zX9D8LWFZV9wL/EngZ8NIB3gbppNxT0HxwbvNlJwuBo8AngYnpov8DsBx4uJlOepzeFT7QOyz0HnrnFO4H7qmqHyX5deDTSc5p+r2T3ndxn8wdTf+HgS8BTwBU1d4k7wS+2HzA/xBYD/zlKba1GfhYkt+mNxX7nUl+gt5exwer6unTvRnSqThLqjSJ5vDRO6rqHw65FGlaefhIktRyT0GS1HJPQZLUMhQkSS1DQZLUMhQkSS1DQZLU+v+Q3pCIxwughwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Dependents'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d63671bf",
   "metadata": {},
   "source": [
    "The applicates with 0 dependents are more than 1,2,3+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa9a262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Education', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Education'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c56fe81",
   "metadata": {},
   "source": [
    "The number of graduate applications are more than Non-graduate applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eecf6357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Self_Employed', ylabel='count'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Self_Employed'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60a78199",
   "metadata": {},
   "source": [
    "The non self-Employed applications are more than self-Employed people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d8b0047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Loan_Amount_Term', ylabel='count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Loan_Amount_Term'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d298ce4",
   "metadata": {},
   "source": [
    "The loan term of 360 months are more compared to 180 months followed by 480 and 300 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84f90ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Credit_History', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Credit_History'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7483d17a",
   "metadata": {},
   "source": [
    "Most of the applicaions having Credit histroy only some have no credit histroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca297dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Property_Area', ylabel='count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(dt['Property_Area'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ed21f74",
   "metadata": {},
   "source": [
    "Applications having Semiurban property area are more followed by urban and rural property area"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e610db5d",
   "metadata": {},
   "source": [
    "Bivarient analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61e67776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Gender', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05cf3fc0",
   "metadata": {},
   "source": [
    "Male applicants are more and have apoted for more loan amount than female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45affa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Married', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16c6d229",
   "metadata": {},
   "source": [
    "Married people have applied for higher loan amount than unmarried people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0565c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Dependents', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c54a364",
   "metadata": {},
   "source": [
    "People having higher dependenta have more loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c1f8319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Education', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c76ab237",
   "metadata": {},
   "source": [
    "Graduate people have opted for more loan amount than nongraduate people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4561524a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Self_Employed', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d3c686f",
   "metadata": {},
   "source": [
    "Self employed people have opted for more loan amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee11e168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.scatterplot(x='ApplicantIncome', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98d4b719",
   "metadata": {},
   "source": [
    "We can observed that as the Applicant income increases the loan amount also increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb70cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Loan_Amount_Term', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37c5c852",
   "metadata": {},
   "source": [
    "Loan applicants with 300 and 480 monts have higher loan amount and chance of acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "978d8015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Property_Area', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1030e43d",
   "metadata": {},
   "source": [
    "Rural people have applied for higher loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7db8f9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(*, x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "chart =sns.barplot(x='Credit_History', y='LoanAmount', hue='Loan_Status', data=dt)\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=0, horizontalalignment='right')\n",
    "plt.show()\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ebb0726",
   "metadata": {},
   "source": [
    "The applicants with no credit history have applied for higher amount of loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5b77132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x499a71feb0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd467724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing the NAN values\n",
    "dt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f522095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Male'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Gender'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfb2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Gender'].fillna(dt['Gender'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9a4e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Married'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b8c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Married'].fillna(dt['Married'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6782be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Dependents'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e149631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Dependents'].fillna(dt['Dependents'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3391e7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Self_Employed'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb01ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Self_Employed'].fillna(dt['Self_Employed'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5b8e0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['LoanAmount'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d90245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.41216216216216"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['LoanAmount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae243f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['LoanAmount'].fillna(dt['LoanAmount'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67c67d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt['LoanAmount'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7386efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Loan_Amount_Term'].fillna(dt['Loan_Amount_Term'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2416848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['Credit_History'].fillna(dt['Credit_History'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89d876bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c142781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning to a variable\n",
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb50099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting all the catagorical variables to numerical in trianing dataset\n",
    "dt['Gender']=le.fit_transform(dt['Gender'])\n",
    "dt['Married']=le.fit_transform(dt['Married'])\n",
    "dt['Dependents']=le.fit_transform(dt['Dependents'])\n",
    "dt['Education']=le.fit_transform(dt['Education'])\n",
    "dt['Self_Employed']=le.fit_transform(dt['Self_Employed'])\n",
    "dt['Credit_History']=le.fit_transform(dt['Credit_History'])\n",
    "dt['Loan_Status']=le.fit_transform(dt['Loan_Status'])\n",
    "dt['Property_Area']=le.fit_transform(dt['Property_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "248dbd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender  Married  Dependents  Education  Self_Employed  \\\n",
       "0    LP001002       1        0           0          0              0   \n",
       "1    LP001003       1        1           1          0              0   \n",
       "2    LP001005       1        1           0          0              1   \n",
       "3    LP001006       1        1           0          1              0   \n",
       "4    LP001008       1        0           0          0              0   \n",
       "..        ...     ...      ...         ...        ...            ...   \n",
       "609  LP002978       0        0           0          0              0   \n",
       "610  LP002979       1        1           3          0              0   \n",
       "611  LP002983       1        1           1          0              0   \n",
       "612  LP002984       1        1           2          0              0   \n",
       "613  LP002990       0        0           0          0              1   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0       120.0             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History  Property_Area  Loan_Status  \n",
       "0                 1              2            1  \n",
       "1                 1              0            0  \n",
       "2                 1              2            1  \n",
       "3                 1              2            1  \n",
       "4                 1              2            1  \n",
       "..              ...            ...          ...  \n",
       "609               1              0            1  \n",
       "610               1              0            1  \n",
       "611               1              2            1  \n",
       "612               1              2            1  \n",
       "613               0              1            0  \n",
       "\n",
       "[614 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "626a636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.drop('Loan_ID',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4862b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsmapling have to be performed to remove the biases\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "351a103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "osmp=SMOTE(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f67c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment of X and y\n",
    "X=dt.drop(['Loan_Status'], axis=1)\n",
    "y=dt.Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1efa0578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of the data\n",
    "scalar= StandardScaler()\n",
    "X_scaled=scalar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e45376f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(X_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcc89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ns,y_train_ns=osmp.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "858f9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PCA components\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9468cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.94619872,  0.77193395, -1.26884616, ...,  0.53798448,\n",
       "        -0.43178976, -0.23621366],\n",
       "       [-2.31352278,  1.42275827, -0.03433917, ...,  1.04315686,\n",
       "        -0.19878762,  0.07380541],\n",
       "       [-1.61668386,  1.7672789 , -0.04808222, ...,  0.67801216,\n",
       "         0.30202043,  1.57658717],\n",
       "       ...,\n",
       "       [-1.22229725,  0.77641039,  0.72014429, ..., -0.8948593 ,\n",
       "         0.76718637, -0.00333528],\n",
       "       [-0.18143658, -0.74080354, -0.81252999, ..., -0.73143681,\n",
       "        -0.69211307,  0.17902617],\n",
       "       [ 0.42544882, -0.63132954, -1.66487606, ...,  0.18492539,\n",
       "        -0.45809662,  0.05111687]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA()\n",
    "pca.fit_transform(X_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5e5afec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting Scree plot to check the best components\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Pricipal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95786102",
   "metadata": {},
   "source": [
    "Considering 10 parameters for accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10fc9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=10)\n",
    "new_pcomp=pca.fit_transform(X_train_ns)\n",
    "prin_comp=pd.DataFrame(new_pcomp, columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67d86650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.946199</td>\n",
       "      <td>0.771934</td>\n",
       "      <td>-1.268846</td>\n",
       "      <td>-1.306101</td>\n",
       "      <td>1.312658</td>\n",
       "      <td>0.588173</td>\n",
       "      <td>1.299204</td>\n",
       "      <td>-1.054427</td>\n",
       "      <td>0.537984</td>\n",
       "      <td>-0.431790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.313523</td>\n",
       "      <td>1.422758</td>\n",
       "      <td>-0.034339</td>\n",
       "      <td>-0.320989</td>\n",
       "      <td>-0.217471</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>0.058236</td>\n",
       "      <td>-0.334989</td>\n",
       "      <td>1.043157</td>\n",
       "      <td>-0.198788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.616684</td>\n",
       "      <td>1.767279</td>\n",
       "      <td>-0.048082</td>\n",
       "      <td>-0.348936</td>\n",
       "      <td>-1.654643</td>\n",
       "      <td>-0.019553</td>\n",
       "      <td>0.456770</td>\n",
       "      <td>-0.856227</td>\n",
       "      <td>0.678012</td>\n",
       "      <td>0.302020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.100263</td>\n",
       "      <td>-1.330688</td>\n",
       "      <td>-1.604615</td>\n",
       "      <td>1.234828</td>\n",
       "      <td>-1.072044</td>\n",
       "      <td>-0.681296</td>\n",
       "      <td>-1.289365</td>\n",
       "      <td>-0.789729</td>\n",
       "      <td>0.557706</td>\n",
       "      <td>0.764951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.638523</td>\n",
       "      <td>0.265686</td>\n",
       "      <td>0.434779</td>\n",
       "      <td>-0.371133</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>-0.506395</td>\n",
       "      <td>-0.272660</td>\n",
       "      <td>0.794407</td>\n",
       "      <td>-0.271762</td>\n",
       "      <td>0.986747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-0.283789</td>\n",
       "      <td>-1.553587</td>\n",
       "      <td>-1.322218</td>\n",
       "      <td>1.621575</td>\n",
       "      <td>-0.293609</td>\n",
       "      <td>-0.065751</td>\n",
       "      <td>0.710024</td>\n",
       "      <td>-0.456542</td>\n",
       "      <td>-1.847865</td>\n",
       "      <td>-1.127390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>-1.634455</td>\n",
       "      <td>0.205182</td>\n",
       "      <td>0.593917</td>\n",
       "      <td>-0.242862</td>\n",
       "      <td>-0.754012</td>\n",
       "      <td>-0.327847</td>\n",
       "      <td>0.407768</td>\n",
       "      <td>0.293793</td>\n",
       "      <td>-1.142908</td>\n",
       "      <td>0.706919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-1.222297</td>\n",
       "      <td>0.776410</td>\n",
       "      <td>0.720144</td>\n",
       "      <td>-0.062446</td>\n",
       "      <td>-0.866154</td>\n",
       "      <td>-0.591930</td>\n",
       "      <td>0.257429</td>\n",
       "      <td>0.558428</td>\n",
       "      <td>-0.894859</td>\n",
       "      <td>0.767186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>-0.181437</td>\n",
       "      <td>-0.740804</td>\n",
       "      <td>-0.812530</td>\n",
       "      <td>2.000393</td>\n",
       "      <td>-0.849226</td>\n",
       "      <td>-0.778581</td>\n",
       "      <td>-0.689330</td>\n",
       "      <td>0.485268</td>\n",
       "      <td>-0.731437</td>\n",
       "      <td>-0.692113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.425449</td>\n",
       "      <td>-0.631330</td>\n",
       "      <td>-1.664876</td>\n",
       "      <td>1.318669</td>\n",
       "      <td>0.401644</td>\n",
       "      <td>-0.793464</td>\n",
       "      <td>-0.715870</td>\n",
       "      <td>0.931263</td>\n",
       "      <td>0.184925</td>\n",
       "      <td>-0.458097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0   -1.946199  0.771934 -1.268846 -1.306101  1.312658  0.588173  1.299204   \n",
       "1   -2.313523  1.422758 -0.034339 -0.320989 -0.217471 -0.017399  0.058236   \n",
       "2   -1.616684  1.767279 -0.048082 -0.348936 -1.654643 -0.019553  0.456770   \n",
       "3    1.100263 -1.330688 -1.604615  1.234828 -1.072044 -0.681296 -1.289365   \n",
       "4   -1.638523  0.265686  0.434779 -0.371133  0.012326 -0.506395 -0.272660   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "539 -0.283789 -1.553587 -1.322218  1.621575 -0.293609 -0.065751  0.710024   \n",
       "540 -1.634455  0.205182  0.593917 -0.242862 -0.754012 -0.327847  0.407768   \n",
       "541 -1.222297  0.776410  0.720144 -0.062446 -0.866154 -0.591930  0.257429   \n",
       "542 -0.181437 -0.740804 -0.812530  2.000393 -0.849226 -0.778581 -0.689330   \n",
       "543  0.425449 -0.631330 -1.664876  1.318669  0.401644 -0.793464 -0.715870   \n",
       "\n",
       "          PC8       PC9      PC10  \n",
       "0   -1.054427  0.537984 -0.431790  \n",
       "1   -0.334989  1.043157 -0.198788  \n",
       "2   -0.856227  0.678012  0.302020  \n",
       "3   -0.789729  0.557706  0.764951  \n",
       "4    0.794407 -0.271762  0.986747  \n",
       "..        ...       ...       ...  \n",
       "539 -0.456542 -1.847865 -1.127390  \n",
       "540  0.293793 -1.142908  0.706919  \n",
       "541  0.558428 -0.894859  0.767186  \n",
       "542  0.485268 -0.731437 -0.692113  \n",
       "543  0.931263  0.184925 -0.458097  \n",
       "\n",
       "[544 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prin_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce2edeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error,mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54071212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7431192660550459 random_state 1\n",
      "accuracy of the optimum model 0.7431192660550459 random_state 1\n",
      "accuracy of the model 0.7064220183486238 random_state 2\n",
      "accuracy of the model 0.7064220183486238 random_state 3\n",
      "accuracy of the model 0.7247706422018348 random_state 4\n",
      "accuracy of the model 0.6605504587155964 random_state 5\n",
      "accuracy of the model 0.7981651376146789 random_state 6\n",
      "accuracy of the optimum model 0.7981651376146789 random_state 6\n",
      "accuracy of the model 0.7155963302752294 random_state 7\n",
      "accuracy of the model 0.7614678899082569 random_state 8\n",
      "accuracy of the model 0.6972477064220184 random_state 9\n",
      "accuracy of the model 0.7431192660550459 random_state 10\n",
      "accuracy of the model 0.6972477064220184 random_state 11\n",
      "accuracy of the model 0.7431192660550459 random_state 12\n",
      "accuracy of the model 0.6880733944954128 random_state 13\n",
      "accuracy of the model 0.6880733944954128 random_state 14\n",
      "accuracy of the model 0.7431192660550459 random_state 15\n",
      "accuracy of the model 0.6697247706422018 random_state 16\n",
      "accuracy of the model 0.7247706422018348 random_state 17\n",
      "accuracy of the model 0.7155963302752294 random_state 18\n",
      "accuracy of the model 0.7889908256880734 random_state 19\n",
      "accuracy of the model 0.7614678899082569 random_state 20\n",
      "accuracy of the model 0.7339449541284404 random_state 21\n",
      "accuracy of the model 0.7247706422018348 random_state 22\n",
      "accuracy of the model 0.7431192660550459 random_state 23\n",
      "accuracy of the model 0.7155963302752294 random_state 24\n",
      "accuracy of the model 0.7431192660550459 random_state 25\n",
      "accuracy of the model 0.7247706422018348 random_state 26\n",
      "accuracy of the model 0.7339449541284404 random_state 27\n",
      "accuracy of the model 0.7706422018348624 random_state 28\n",
      "accuracy of the model 0.7247706422018348 random_state 29\n",
      "accuracy of the model 0.7522935779816514 random_state 30\n",
      "accuracy of the model 0.7339449541284404 random_state 31\n",
      "accuracy of the model 0.7522935779816514 random_state 32\n",
      "accuracy of the model 0.7155963302752294 random_state 33\n",
      "accuracy of the model 0.7431192660550459 random_state 34\n",
      "accuracy of the model 0.6972477064220184 random_state 35\n",
      "accuracy of the model 0.6880733944954128 random_state 36\n",
      "accuracy of the model 0.7522935779816514 random_state 37\n",
      "accuracy of the model 0.7064220183486238 random_state 38\n",
      "accuracy of the model 0.7064220183486238 random_state 39\n",
      "accuracy of the model 0.7064220183486238 random_state 40\n",
      "accuracy of the model 0.7155963302752294 random_state 41\n",
      "accuracy of the model 0.6972477064220184 random_state 42\n",
      "accuracy of the model 0.7522935779816514 random_state 43\n",
      "accuracy of the model 0.7064220183486238 random_state 44\n",
      "accuracy of the model 0.7706422018348624 random_state 45\n",
      "accuracy of the model 0.6788990825688074 random_state 46\n",
      "accuracy of the model 0.7522935779816514 random_state 47\n",
      "accuracy of the model 0.7155963302752294 random_state 48\n",
      "accuracy of the model 0.7155963302752294 random_state 49\n",
      "accuracy of the model 0.7706422018348624 random_state 50\n",
      "accuracy of the model 0.7247706422018348 random_state 51\n",
      "accuracy of the model 0.7431192660550459 random_state 52\n",
      "accuracy of the model 0.6972477064220184 random_state 53\n",
      "accuracy of the model 0.7155963302752294 random_state 54\n",
      "accuracy of the model 0.7706422018348624 random_state 55\n",
      "accuracy of the model 0.6880733944954128 random_state 56\n",
      "accuracy of the model 0.7155963302752294 random_state 57\n",
      "accuracy of the model 0.7614678899082569 random_state 58\n",
      "accuracy of the model 0.7155963302752294 random_state 59\n",
      "accuracy of the model 0.7706422018348624 random_state 60\n",
      "accuracy of the model 0.6972477064220184 random_state 61\n",
      "accuracy of the model 0.7247706422018348 random_state 62\n",
      "accuracy of the model 0.7339449541284404 random_state 63\n",
      "accuracy of the model 0.7614678899082569 random_state 64\n",
      "accuracy of the model 0.7339449541284404 random_state 65\n",
      "accuracy of the model 0.7522935779816514 random_state 66\n",
      "accuracy of the model 0.7889908256880734 random_state 67\n",
      "accuracy of the model 0.7706422018348624 random_state 68\n",
      "accuracy of the model 0.7798165137614679 random_state 69\n",
      "accuracy of the model 0.7431192660550459 random_state 70\n",
      "accuracy of the model 0.7706422018348624 random_state 71\n",
      "accuracy of the model 0.7247706422018348 random_state 72\n",
      "accuracy of the model 0.7064220183486238 random_state 73\n",
      "accuracy of the model 0.7522935779816514 random_state 74\n",
      "accuracy of the model 0.6880733944954128 random_state 75\n",
      "accuracy of the model 0.7706422018348624 random_state 76\n",
      "accuracy of the model 0.6330275229357798 random_state 77\n",
      "accuracy of the model 0.7064220183486238 random_state 78\n",
      "accuracy of the model 0.7339449541284404 random_state 79\n",
      "accuracy of the model 0.7706422018348624 random_state 80\n",
      "accuracy of the model 0.7798165137614679 random_state 81\n",
      "accuracy of the model 0.7339449541284404 random_state 82\n",
      "accuracy of the model 0.6605504587155964 random_state 83\n",
      "accuracy of the model 0.7064220183486238 random_state 84\n",
      "accuracy of the model 0.7064220183486238 random_state 85\n",
      "accuracy of the model 0.6605504587155964 random_state 86\n",
      "accuracy of the model 0.7522935779816514 random_state 87\n",
      "accuracy of the model 0.7064220183486238 random_state 88\n",
      "accuracy of the model 0.7614678899082569 random_state 89\n",
      "accuracy of the model 0.6697247706422018 random_state 90\n",
      "accuracy of the model 0.7614678899082569 random_state 91\n",
      "accuracy of the model 0.6972477064220184 random_state 92\n",
      "accuracy of the model 0.7889908256880734 random_state 93\n",
      "accuracy of the model 0.7155963302752294 random_state 94\n",
      "accuracy of the model 0.7798165137614679 random_state 95\n",
      "accuracy of the model 0.7247706422018348 random_state 96\n",
      "accuracy of the model 0.7064220183486238 random_state 97\n",
      "accuracy of the model 0.6697247706422018 random_state 98\n",
      "accuracy of the model 0.7522935779816514 random_state 99\n",
      "accuracy of the model 0.6513761467889908 random_state 100\n",
      "accuracy of the model 0.7155963302752294 random_state 101\n",
      "accuracy of the model 0.7155963302752294 random_state 102\n",
      "accuracy of the model 0.7522935779816514 random_state 103\n",
      "accuracy of the model 0.7339449541284404 random_state 104\n",
      "accuracy of the model 0.7247706422018348 random_state 105\n",
      "accuracy of the model 0.7155963302752294 random_state 106\n",
      "accuracy of the model 0.7064220183486238 random_state 107\n",
      "accuracy of the model 0.7247706422018348 random_state 108\n",
      "accuracy of the model 0.7064220183486238 random_state 109\n",
      "accuracy of the model 0.7431192660550459 random_state 110\n",
      "accuracy of the model 0.7706422018348624 random_state 111\n",
      "accuracy of the model 0.7522935779816514 random_state 112\n",
      "accuracy of the model 0.7247706422018348 random_state 113\n",
      "accuracy of the model 0.7522935779816514 random_state 114\n",
      "accuracy of the model 0.6880733944954128 random_state 115\n",
      "accuracy of the model 0.7431192660550459 random_state 116\n",
      "accuracy of the model 0.6513761467889908 random_state 117\n",
      "accuracy of the model 0.6972477064220184 random_state 118\n",
      "accuracy of the model 0.7064220183486238 random_state 119\n",
      "accuracy of the model 0.7247706422018348 random_state 120\n",
      "accuracy of the model 0.7431192660550459 random_state 121\n",
      "accuracy of the model 0.7247706422018348 random_state 122\n",
      "accuracy of the model 0.7431192660550459 random_state 123\n",
      "accuracy of the model 0.7889908256880734 random_state 124\n",
      "accuracy of the model 0.6880733944954128 random_state 125\n",
      "accuracy of the model 0.6697247706422018 random_state 126\n",
      "accuracy of the model 0.7247706422018348 random_state 127\n",
      "accuracy of the model 0.8256880733944955 random_state 128\n",
      "accuracy of the optimum model 0.8256880733944955 random_state 128\n",
      "accuracy of the model 0.7247706422018348 random_state 129\n",
      "accuracy of the model 0.7155963302752294 random_state 130\n",
      "accuracy of the model 0.7431192660550459 random_state 131\n",
      "accuracy of the model 0.6880733944954128 random_state 132\n",
      "accuracy of the model 0.6972477064220184 random_state 133\n",
      "accuracy of the model 0.7155963302752294 random_state 134\n",
      "accuracy of the model 0.7247706422018348 random_state 135\n",
      "accuracy of the model 0.7614678899082569 random_state 136\n",
      "accuracy of the model 0.6972477064220184 random_state 137\n",
      "accuracy of the model 0.7614678899082569 random_state 138\n",
      "accuracy of the model 0.7614678899082569 random_state 139\n",
      "accuracy of the model 0.7339449541284404 random_state 140\n",
      "accuracy of the model 0.7155963302752294 random_state 141\n",
      "accuracy of the model 0.7155963302752294 random_state 142\n",
      "accuracy of the model 0.7614678899082569 random_state 143\n",
      "accuracy of the model 0.7247706422018348 random_state 144\n",
      "accuracy of the model 0.7155963302752294 random_state 145\n",
      "accuracy of the model 0.7247706422018348 random_state 146\n",
      "accuracy of the model 0.7064220183486238 random_state 147\n",
      "accuracy of the model 0.6972477064220184 random_state 148\n",
      "accuracy of the model 0.6788990825688074 random_state 149\n",
      "accuracy of the model 0.6513761467889908 random_state 150\n",
      "accuracy of the model 0.6788990825688074 random_state 151\n",
      "accuracy of the model 0.7431192660550459 random_state 152\n",
      "accuracy of the model 0.6697247706422018 random_state 153\n",
      "accuracy of the model 0.8165137614678899 random_state 154\n",
      "accuracy of the model 0.7431192660550459 random_state 155\n",
      "accuracy of the model 0.7431192660550459 random_state 156\n",
      "accuracy of the model 0.7798165137614679 random_state 157\n",
      "accuracy of the model 0.7431192660550459 random_state 158\n",
      "accuracy of the model 0.7247706422018348 random_state 159\n",
      "accuracy of the model 0.6880733944954128 random_state 160\n",
      "accuracy of the model 0.7431192660550459 random_state 161\n",
      "accuracy of the model 0.7339449541284404 random_state 162\n",
      "accuracy of the model 0.7614678899082569 random_state 163\n",
      "accuracy of the model 0.7247706422018348 random_state 164\n",
      "accuracy of the model 0.7155963302752294 random_state 165\n",
      "accuracy of the model 0.7431192660550459 random_state 166\n",
      "accuracy of the model 0.6788990825688074 random_state 167\n",
      "accuracy of the model 0.7247706422018348 random_state 168\n",
      "accuracy of the model 0.7155963302752294 random_state 169\n",
      "accuracy of the model 0.6880733944954128 random_state 170\n",
      "accuracy of the model 0.7614678899082569 random_state 171\n",
      "accuracy of the model 0.7431192660550459 random_state 172\n",
      "accuracy of the model 0.6605504587155964 random_state 173\n",
      "accuracy of the model 0.7614678899082569 random_state 174\n",
      "accuracy of the model 0.7798165137614679 random_state 175\n",
      "accuracy of the model 0.7247706422018348 random_state 176\n",
      "accuracy of the model 0.7247706422018348 random_state 177\n",
      "accuracy of the model 0.7981651376146789 random_state 178\n",
      "accuracy of the model 0.7706422018348624 random_state 179\n",
      "accuracy of the model 0.7798165137614679 random_state 180\n",
      "accuracy of the model 0.6880733944954128 random_state 181\n",
      "accuracy of the model 0.7155963302752294 random_state 182\n",
      "accuracy of the model 0.7247706422018348 random_state 183\n",
      "accuracy of the model 0.7247706422018348 random_state 184\n",
      "accuracy of the model 0.6788990825688074 random_state 185\n",
      "accuracy of the model 0.7247706422018348 random_state 186\n",
      "accuracy of the model 0.7522935779816514 random_state 187\n",
      "accuracy of the model 0.7155963302752294 random_state 188\n",
      "accuracy of the model 0.7431192660550459 random_state 189\n",
      "accuracy of the model 0.7431192660550459 random_state 190\n",
      "accuracy of the model 0.7339449541284404 random_state 191\n",
      "accuracy of the model 0.7798165137614679 random_state 192\n",
      "accuracy of the model 0.7247706422018348 random_state 193\n",
      "accuracy of the model 0.7431192660550459 random_state 194\n",
      "accuracy of the model 0.7064220183486238 random_state 195\n",
      "accuracy of the model 0.7339449541284404 random_state 196\n",
      "accuracy of the model 0.7339449541284404 random_state 197\n",
      "accuracy of the model 0.7155963302752294 random_state 198\n",
      "accuracy of the model 0.7064220183486238 random_state 199\n",
      "accuracy of the model 0.7339449541284404 random_state 200\n",
      "accuracy of the model 0.7247706422018348 random_state 201\n",
      "accuracy of the model 0.6972477064220184 random_state 202\n",
      "accuracy of the model 0.7981651376146789 random_state 203\n",
      "accuracy of the model 0.7247706422018348 random_state 204\n",
      "accuracy of the model 0.6972477064220184 random_state 205\n",
      "accuracy of the model 0.6697247706422018 random_state 206\n",
      "accuracy of the model 0.6788990825688074 random_state 207\n",
      "accuracy of the model 0.6697247706422018 random_state 208\n",
      "accuracy of the model 0.7522935779816514 random_state 209\n",
      "accuracy of the model 0.6788990825688074 random_state 210\n",
      "accuracy of the model 0.6880733944954128 random_state 211\n",
      "accuracy of the model 0.7064220183486238 random_state 212\n",
      "accuracy of the model 0.6788990825688074 random_state 213\n",
      "accuracy of the model 0.7339449541284404 random_state 214\n",
      "accuracy of the model 0.7706422018348624 random_state 215\n",
      "accuracy of the model 0.6880733944954128 random_state 216\n",
      "accuracy of the model 0.7155963302752294 random_state 217\n",
      "accuracy of the model 0.7798165137614679 random_state 218\n",
      "accuracy of the model 0.7247706422018348 random_state 219\n",
      "accuracy of the model 0.6972477064220184 random_state 220\n",
      "accuracy of the model 0.7339449541284404 random_state 221\n",
      "accuracy of the model 0.6422018348623854 random_state 222\n",
      "accuracy of the model 0.7522935779816514 random_state 223\n",
      "accuracy of the model 0.7889908256880734 random_state 224\n",
      "accuracy of the model 0.7155963302752294 random_state 225\n",
      "accuracy of the model 0.8073394495412844 random_state 226\n",
      "accuracy of the model 0.7431192660550459 random_state 227\n",
      "accuracy of the model 0.7431192660550459 random_state 228\n",
      "accuracy of the model 0.7614678899082569 random_state 229\n",
      "accuracy of the model 0.7155963302752294 random_state 230\n",
      "accuracy of the model 0.7614678899082569 random_state 231\n",
      "accuracy of the model 0.7247706422018348 random_state 232\n",
      "accuracy of the model 0.7614678899082569 random_state 233\n",
      "accuracy of the model 0.7614678899082569 random_state 234\n",
      "accuracy of the model 0.7614678899082569 random_state 235\n",
      "accuracy of the model 0.7798165137614679 random_state 236\n",
      "accuracy of the model 0.7064220183486238 random_state 237\n",
      "accuracy of the model 0.7064220183486238 random_state 238\n",
      "accuracy of the model 0.7064220183486238 random_state 239\n",
      "accuracy of the model 0.7889908256880734 random_state 240\n",
      "accuracy of the model 0.8073394495412844 random_state 241\n",
      "accuracy of the model 0.6330275229357798 random_state 242\n",
      "accuracy of the model 0.7064220183486238 random_state 243\n",
      "accuracy of the model 0.7798165137614679 random_state 244\n",
      "accuracy of the model 0.7522935779816514 random_state 245\n",
      "accuracy of the model 0.6788990825688074 random_state 246\n",
      "accuracy of the model 0.7339449541284404 random_state 247\n",
      "accuracy of the model 0.7247706422018348 random_state 248\n",
      "accuracy of the model 0.7247706422018348 random_state 249\n",
      "accuracy of the model 0.7247706422018348 random_state 250\n",
      "accuracy of the model 0.7522935779816514 random_state 251\n",
      "accuracy of the model 0.6605504587155964 random_state 252\n",
      "accuracy of the model 0.7889908256880734 random_state 253\n",
      "accuracy of the model 0.8073394495412844 random_state 254\n",
      "accuracy of the model 0.7431192660550459 random_state 255\n",
      "accuracy of the model 0.7339449541284404 random_state 256\n",
      "accuracy of the model 0.7339449541284404 random_state 257\n",
      "accuracy of the model 0.7706422018348624 random_state 258\n",
      "accuracy of the model 0.6697247706422018 random_state 259\n",
      "accuracy of the model 0.7889908256880734 random_state 260\n",
      "accuracy of the model 0.7798165137614679 random_state 261\n",
      "accuracy of the model 0.6697247706422018 random_state 262\n",
      "accuracy of the model 0.6788990825688074 random_state 263\n",
      "accuracy of the model 0.7247706422018348 random_state 264\n",
      "accuracy of the model 0.7064220183486238 random_state 265\n",
      "accuracy of the model 0.7981651376146789 random_state 266\n",
      "accuracy of the model 0.7522935779816514 random_state 267\n",
      "accuracy of the model 0.6788990825688074 random_state 268\n",
      "accuracy of the model 0.7064220183486238 random_state 269\n",
      "accuracy of the model 0.7431192660550459 random_state 270\n",
      "accuracy of the model 0.7522935779816514 random_state 271\n",
      "accuracy of the model 0.6972477064220184 random_state 272\n",
      "accuracy of the model 0.7064220183486238 random_state 273\n",
      "accuracy of the model 0.7247706422018348 random_state 274\n",
      "accuracy of the model 0.7981651376146789 random_state 275\n",
      "accuracy of the model 0.7247706422018348 random_state 276\n",
      "accuracy of the model 0.7706422018348624 random_state 277\n",
      "accuracy of the model 0.7155963302752294 random_state 278\n",
      "accuracy of the model 0.7522935779816514 random_state 279\n",
      "accuracy of the model 0.7155963302752294 random_state 280\n",
      "accuracy of the model 0.7431192660550459 random_state 281\n",
      "accuracy of the model 0.6788990825688074 random_state 282\n",
      "accuracy of the model 0.6788990825688074 random_state 283\n",
      "accuracy of the model 0.7247706422018348 random_state 284\n",
      "accuracy of the model 0.6788990825688074 random_state 285\n",
      "accuracy of the model 0.7706422018348624 random_state 286\n",
      "accuracy of the model 0.7155963302752294 random_state 287\n",
      "accuracy of the model 0.6697247706422018 random_state 288\n",
      "accuracy of the model 0.7155963302752294 random_state 289\n",
      "accuracy of the model 0.7522935779816514 random_state 290\n",
      "accuracy of the model 0.7431192660550459 random_state 291\n",
      "accuracy of the model 0.7339449541284404 random_state 292\n",
      "accuracy of the model 0.7155963302752294 random_state 293\n",
      "accuracy of the model 0.7339449541284404 random_state 294\n",
      "accuracy of the model 0.7064220183486238 random_state 295\n",
      "accuracy of the model 0.7339449541284404 random_state 296\n",
      "accuracy of the model 0.7339449541284404 random_state 297\n",
      "accuracy of the model 0.6697247706422018 random_state 298\n",
      "accuracy of the model 0.7155963302752294 random_state 299\n",
      "accuracy of the model 0.7522935779816514 random_state 300\n",
      "accuracy of the model 0.7431192660550459 random_state 301\n",
      "accuracy of the model 0.7064220183486238 random_state 302\n",
      "accuracy of the model 0.7155963302752294 random_state 303\n",
      "accuracy of the model 0.6605504587155964 random_state 304\n",
      "accuracy of the model 0.7614678899082569 random_state 305\n",
      "accuracy of the model 0.7798165137614679 random_state 306\n",
      "accuracy of the model 0.7522935779816514 random_state 307\n",
      "accuracy of the model 0.7431192660550459 random_state 308\n",
      "accuracy of the model 0.6605504587155964 random_state 309\n",
      "accuracy of the model 0.7522935779816514 random_state 310\n",
      "accuracy of the model 0.7339449541284404 random_state 311\n",
      "accuracy of the model 0.6697247706422018 random_state 312\n",
      "accuracy of the model 0.6697247706422018 random_state 313\n",
      "accuracy of the model 0.7522935779816514 random_state 314\n",
      "accuracy of the model 0.7339449541284404 random_state 315\n",
      "accuracy of the model 0.7247706422018348 random_state 316\n",
      "accuracy of the model 0.6605504587155964 random_state 317\n",
      "accuracy of the model 0.6880733944954128 random_state 318\n",
      "accuracy of the model 0.7431192660550459 random_state 319\n",
      "accuracy of the model 0.6880733944954128 random_state 320\n",
      "accuracy of the model 0.7155963302752294 random_state 321\n",
      "accuracy of the model 0.7706422018348624 random_state 322\n",
      "accuracy of the model 0.7064220183486238 random_state 323\n",
      "accuracy of the model 0.6972477064220184 random_state 324\n",
      "accuracy of the model 0.7522935779816514 random_state 325\n",
      "accuracy of the model 0.7155963302752294 random_state 326\n",
      "accuracy of the model 0.6972477064220184 random_state 327\n",
      "accuracy of the model 0.7798165137614679 random_state 328\n",
      "accuracy of the model 0.7431192660550459 random_state 329\n",
      "accuracy of the model 0.7064220183486238 random_state 330\n",
      "accuracy of the model 0.7064220183486238 random_state 331\n",
      "accuracy of the model 0.7431192660550459 random_state 332\n",
      "accuracy of the model 0.7798165137614679 random_state 333\n",
      "accuracy of the model 0.7706422018348624 random_state 334\n",
      "accuracy of the model 0.7155963302752294 random_state 335\n",
      "accuracy of the model 0.7247706422018348 random_state 336\n",
      "accuracy of the model 0.7247706422018348 random_state 337\n",
      "accuracy of the model 0.7798165137614679 random_state 338\n",
      "accuracy of the model 0.7339449541284404 random_state 339\n",
      "accuracy of the model 0.7889908256880734 random_state 340\n",
      "accuracy of the model 0.7155963302752294 random_state 341\n",
      "accuracy of the model 0.6788990825688074 random_state 342\n",
      "accuracy of the model 0.7155963302752294 random_state 343\n",
      "accuracy of the model 0.7064220183486238 random_state 344\n",
      "accuracy of the model 0.7247706422018348 random_state 345\n",
      "accuracy of the model 0.8165137614678899 random_state 346\n",
      "accuracy of the model 0.7155963302752294 random_state 347\n",
      "accuracy of the model 0.6880733944954128 random_state 348\n",
      "accuracy of the model 0.7064220183486238 random_state 349\n",
      "accuracy of the model 0.6972477064220184 random_state 350\n",
      "accuracy of the model 0.7889908256880734 random_state 351\n",
      "accuracy of the model 0.7522935779816514 random_state 352\n",
      "accuracy of the model 0.6605504587155964 random_state 353\n",
      "accuracy of the model 0.7064220183486238 random_state 354\n",
      "accuracy of the model 0.6697247706422018 random_state 355\n",
      "accuracy of the model 0.7798165137614679 random_state 356\n",
      "accuracy of the model 0.7706422018348624 random_state 357\n",
      "accuracy of the model 0.7614678899082569 random_state 358\n",
      "accuracy of the model 0.7155963302752294 random_state 359\n",
      "accuracy of the model 0.7155963302752294 random_state 360\n",
      "accuracy of the model 0.7522935779816514 random_state 361\n",
      "accuracy of the model 0.6880733944954128 random_state 362\n",
      "accuracy of the model 0.7247706422018348 random_state 363\n",
      "accuracy of the model 0.7614678899082569 random_state 364\n",
      "accuracy of the model 0.7614678899082569 random_state 365\n",
      "accuracy of the model 0.7155963302752294 random_state 366\n",
      "accuracy of the model 0.6880733944954128 random_state 367\n",
      "accuracy of the model 0.7706422018348624 random_state 368\n",
      "accuracy of the model 0.7431192660550459 random_state 369\n",
      "accuracy of the model 0.7706422018348624 random_state 370\n",
      "accuracy of the model 0.7614678899082569 random_state 371\n",
      "accuracy of the model 0.7155963302752294 random_state 372\n",
      "accuracy of the model 0.7522935779816514 random_state 373\n",
      "accuracy of the model 0.7614678899082569 random_state 374\n",
      "accuracy of the model 0.7339449541284404 random_state 375\n",
      "accuracy of the model 0.7431192660550459 random_state 376\n",
      "accuracy of the model 0.6972477064220184 random_state 377\n",
      "accuracy of the model 0.6972477064220184 random_state 378\n",
      "accuracy of the model 0.7339449541284404 random_state 379\n",
      "accuracy of the model 0.6788990825688074 random_state 380\n",
      "accuracy of the model 0.6972477064220184 random_state 381\n",
      "accuracy of the model 0.7064220183486238 random_state 382\n",
      "accuracy of the model 0.6422018348623854 random_state 383\n",
      "accuracy of the model 0.7247706422018348 random_state 384\n",
      "accuracy of the model 0.6880733944954128 random_state 385\n",
      "accuracy of the model 0.7889908256880734 random_state 386\n",
      "accuracy of the model 0.6880733944954128 random_state 387\n",
      "accuracy of the model 0.6880733944954128 random_state 388\n",
      "accuracy of the model 0.7247706422018348 random_state 389\n",
      "accuracy of the model 0.7339449541284404 random_state 390\n",
      "accuracy of the model 0.7706422018348624 random_state 391\n",
      "accuracy of the model 0.7155963302752294 random_state 392\n",
      "accuracy of the model 0.7522935779816514 random_state 393\n",
      "accuracy of the model 0.6697247706422018 random_state 394\n",
      "accuracy of the model 0.7339449541284404 random_state 395\n",
      "accuracy of the model 0.8256880733944955 random_state 396\n",
      "accuracy of the model 0.6972477064220184 random_state 397\n",
      "accuracy of the model 0.7431192660550459 random_state 398\n",
      "accuracy of the model 0.7431192660550459 random_state 399\n",
      "accuracy of the model 0.7247706422018348 random_state 400\n",
      "accuracy of the model 0.6513761467889908 random_state 401\n",
      "accuracy of the model 0.7522935779816514 random_state 402\n",
      "accuracy of the model 0.6788990825688074 random_state 403\n",
      "accuracy of the model 0.6972477064220184 random_state 404\n",
      "accuracy of the model 0.7247706422018348 random_state 405\n",
      "accuracy of the model 0.7706422018348624 random_state 406\n",
      "accuracy of the model 0.7339449541284404 random_state 407\n",
      "accuracy of the model 0.6880733944954128 random_state 408\n",
      "accuracy of the model 0.7706422018348624 random_state 409\n",
      "accuracy of the model 0.7247706422018348 random_state 410\n",
      "accuracy of the model 0.7155963302752294 random_state 411\n",
      "accuracy of the model 0.6788990825688074 random_state 412\n",
      "accuracy of the model 0.7339449541284404 random_state 413\n",
      "accuracy of the model 0.6788990825688074 random_state 414\n",
      "accuracy of the model 0.7981651376146789 random_state 415\n",
      "accuracy of the model 0.7522935779816514 random_state 416\n",
      "accuracy of the model 0.7614678899082569 random_state 417\n",
      "accuracy of the model 0.7798165137614679 random_state 418\n",
      "accuracy of the model 0.7155963302752294 random_state 419\n",
      "accuracy of the model 0.6788990825688074 random_state 420\n",
      "accuracy of the model 0.7155963302752294 random_state 421\n",
      "accuracy of the model 0.7339449541284404 random_state 422\n",
      "accuracy of the model 0.6788990825688074 random_state 423\n",
      "accuracy of the model 0.6697247706422018 random_state 424\n",
      "accuracy of the model 0.7247706422018348 random_state 425\n",
      "accuracy of the model 0.6788990825688074 random_state 426\n",
      "accuracy of the model 0.7155963302752294 random_state 427\n",
      "accuracy of the model 0.7431192660550459 random_state 428\n",
      "accuracy of the model 0.7155963302752294 random_state 429\n",
      "accuracy of the model 0.6972477064220184 random_state 430\n",
      "accuracy of the model 0.7614678899082569 random_state 431\n",
      "accuracy of the model 0.7522935779816514 random_state 432\n",
      "accuracy of the model 0.6972477064220184 random_state 433\n",
      "accuracy of the model 0.7339449541284404 random_state 434\n",
      "accuracy of the model 0.7522935779816514 random_state 435\n",
      "accuracy of the model 0.6972477064220184 random_state 436\n",
      "accuracy of the model 0.6788990825688074 random_state 437\n",
      "accuracy of the model 0.7155963302752294 random_state 438\n",
      "accuracy of the model 0.7706422018348624 random_state 439\n",
      "accuracy of the model 0.7522935779816514 random_state 440\n",
      "accuracy of the model 0.7614678899082569 random_state 441\n",
      "accuracy of the model 0.7614678899082569 random_state 442\n",
      "accuracy of the model 0.6972477064220184 random_state 443\n",
      "accuracy of the model 0.7614678899082569 random_state 444\n",
      "accuracy of the model 0.7522935779816514 random_state 445\n",
      "accuracy of the model 0.7339449541284404 random_state 446\n",
      "accuracy of the model 0.7522935779816514 random_state 447\n",
      "accuracy of the model 0.7247706422018348 random_state 448\n",
      "accuracy of the model 0.7522935779816514 random_state 449\n",
      "accuracy of the model 0.6972477064220184 random_state 450\n",
      "accuracy of the model 0.7339449541284404 random_state 451\n",
      "accuracy of the model 0.7339449541284404 random_state 452\n",
      "accuracy of the model 0.7431192660550459 random_state 453\n",
      "accuracy of the model 0.7614678899082569 random_state 454\n",
      "accuracy of the model 0.7339449541284404 random_state 455\n",
      "accuracy of the model 0.7339449541284404 random_state 456\n",
      "accuracy of the model 0.6788990825688074 random_state 457\n",
      "accuracy of the model 0.7247706422018348 random_state 458\n",
      "accuracy of the model 0.6605504587155964 random_state 459\n",
      "accuracy of the model 0.7522935779816514 random_state 460\n",
      "accuracy of the model 0.6880733944954128 random_state 461\n",
      "accuracy of the model 0.7614678899082569 random_state 462\n",
      "accuracy of the model 0.6880733944954128 random_state 463\n",
      "accuracy of the model 0.7431192660550459 random_state 464\n",
      "accuracy of the model 0.6972477064220184 random_state 465\n",
      "accuracy of the model 0.7614678899082569 random_state 466\n",
      "accuracy of the model 0.6880733944954128 random_state 467\n",
      "accuracy of the model 0.6880733944954128 random_state 468\n",
      "accuracy of the model 0.7339449541284404 random_state 469\n",
      "accuracy of the model 0.7706422018348624 random_state 470\n",
      "accuracy of the model 0.7339449541284404 random_state 471\n",
      "accuracy of the model 0.7431192660550459 random_state 472\n",
      "accuracy of the model 0.7339449541284404 random_state 473\n",
      "accuracy of the model 0.7614678899082569 random_state 474\n",
      "accuracy of the model 0.7614678899082569 random_state 475\n",
      "accuracy of the model 0.7339449541284404 random_state 476\n",
      "accuracy of the model 0.6513761467889908 random_state 477\n",
      "accuracy of the model 0.7431192660550459 random_state 478\n",
      "accuracy of the model 0.7155963302752294 random_state 479\n",
      "accuracy of the model 0.6697247706422018 random_state 480\n",
      "accuracy of the model 0.6697247706422018 random_state 481\n",
      "accuracy of the model 0.7431192660550459 random_state 482\n",
      "accuracy of the model 0.6880733944954128 random_state 483\n",
      "accuracy of the model 0.7431192660550459 random_state 484\n",
      "accuracy of the model 0.7339449541284404 random_state 485\n",
      "accuracy of the model 0.7522935779816514 random_state 486\n",
      "accuracy of the model 0.7706422018348624 random_state 487\n",
      "accuracy of the model 0.7522935779816514 random_state 488\n",
      "accuracy of the model 0.7339449541284404 random_state 489\n",
      "accuracy of the model 0.7522935779816514 random_state 490\n",
      "accuracy of the model 0.7614678899082569 random_state 491\n",
      "accuracy of the model 0.7798165137614679 random_state 492\n",
      "accuracy of the model 0.6972477064220184 random_state 493\n",
      "accuracy of the model 0.8623853211009175 random_state 494\n",
      "accuracy of the optimum model 0.8623853211009175 random_state 494\n",
      "accuracy of the model 0.7064220183486238 random_state 495\n",
      "accuracy of the model 0.7798165137614679 random_state 496\n",
      "accuracy of the model 0.7247706422018348 random_state 497\n",
      "accuracy of the model 0.7247706422018348 random_state 498\n",
      "accuracy of the model 0.7614678899082569 random_state 499\n",
      "accuracy of the model 0.7339449541284404 random_state 500\n",
      "accuracy of the model 0.7339449541284404 random_state 501\n",
      "accuracy of the model 0.7522935779816514 random_state 502\n",
      "accuracy of the model 0.6788990825688074 random_state 503\n",
      "accuracy of the model 0.7155963302752294 random_state 504\n",
      "accuracy of the model 0.7339449541284404 random_state 505\n",
      "accuracy of the model 0.7064220183486238 random_state 506\n",
      "accuracy of the model 0.6972477064220184 random_state 507\n",
      "accuracy of the model 0.7339449541284404 random_state 508\n",
      "accuracy of the model 0.7431192660550459 random_state 509\n",
      "accuracy of the model 0.7614678899082569 random_state 510\n",
      "accuracy of the model 0.7339449541284404 random_state 511\n",
      "accuracy of the model 0.7339449541284404 random_state 512\n",
      "accuracy of the model 0.7522935779816514 random_state 513\n",
      "accuracy of the model 0.7706422018348624 random_state 514\n",
      "accuracy of the model 0.7155963302752294 random_state 515\n",
      "accuracy of the model 0.7339449541284404 random_state 516\n",
      "accuracy of the model 0.7706422018348624 random_state 517\n",
      "accuracy of the model 0.7522935779816514 random_state 518\n",
      "accuracy of the model 0.6972477064220184 random_state 519\n",
      "accuracy of the model 0.7614678899082569 random_state 520\n",
      "accuracy of the model 0.6697247706422018 random_state 521\n",
      "accuracy of the model 0.7247706422018348 random_state 522\n",
      "accuracy of the model 0.7798165137614679 random_state 523\n",
      "accuracy of the model 0.7431192660550459 random_state 524\n",
      "accuracy of the model 0.7155963302752294 random_state 525\n",
      "accuracy of the model 0.7064220183486238 random_state 526\n",
      "accuracy of the model 0.6605504587155964 random_state 527\n",
      "accuracy of the model 0.7431192660550459 random_state 528\n",
      "accuracy of the model 0.7798165137614679 random_state 529\n",
      "accuracy of the model 0.7706422018348624 random_state 530\n",
      "accuracy of the model 0.6788990825688074 random_state 531\n",
      "accuracy of the model 0.7339449541284404 random_state 532\n",
      "accuracy of the model 0.6972477064220184 random_state 533\n",
      "accuracy of the model 0.7889908256880734 random_state 534\n",
      "accuracy of the model 0.6605504587155964 random_state 535\n",
      "accuracy of the model 0.7064220183486238 random_state 536\n",
      "accuracy of the model 0.7614678899082569 random_state 537\n",
      "accuracy of the model 0.7339449541284404 random_state 538\n",
      "accuracy of the model 0.7522935779816514 random_state 539\n",
      "accuracy of the model 0.7339449541284404 random_state 540\n",
      "accuracy of the model 0.7614678899082569 random_state 541\n",
      "accuracy of the model 0.6788990825688074 random_state 542\n",
      "accuracy of the model 0.7155963302752294 random_state 543\n",
      "accuracy of the model 0.7614678899082569 random_state 544\n",
      "accuracy of the model 0.7522935779816514 random_state 545\n",
      "accuracy of the model 0.6697247706422018 random_state 546\n",
      "accuracy of the model 0.6972477064220184 random_state 547\n",
      "accuracy of the model 0.8348623853211009 random_state 548\n",
      "accuracy of the model 0.7431192660550459 random_state 549\n",
      "accuracy of the model 0.7614678899082569 random_state 550\n",
      "accuracy of the model 0.6880733944954128 random_state 551\n",
      "accuracy of the model 0.7889908256880734 random_state 552\n",
      "accuracy of the model 0.7522935779816514 random_state 553\n",
      "accuracy of the model 0.7706422018348624 random_state 554\n",
      "accuracy of the model 0.6972477064220184 random_state 555\n",
      "accuracy of the model 0.7431192660550459 random_state 556\n",
      "accuracy of the model 0.7064220183486238 random_state 557\n",
      "accuracy of the model 0.7339449541284404 random_state 558\n",
      "accuracy of the model 0.7522935779816514 random_state 559\n",
      "accuracy of the model 0.6605504587155964 random_state 560\n",
      "accuracy of the model 0.7247706422018348 random_state 561\n",
      "accuracy of the model 0.7431192660550459 random_state 562\n",
      "accuracy of the model 0.6513761467889908 random_state 563\n",
      "accuracy of the model 0.7155963302752294 random_state 564\n",
      "accuracy of the model 0.7431192660550459 random_state 565\n",
      "accuracy of the model 0.7339449541284404 random_state 566\n",
      "accuracy of the model 0.6880733944954128 random_state 567\n",
      "accuracy of the model 0.8073394495412844 random_state 568\n",
      "accuracy of the model 0.7706422018348624 random_state 569\n",
      "accuracy of the model 0.7431192660550459 random_state 570\n",
      "accuracy of the model 0.6605504587155964 random_state 571\n",
      "accuracy of the model 0.7614678899082569 random_state 572\n",
      "accuracy of the model 0.7706422018348624 random_state 573\n",
      "accuracy of the model 0.7064220183486238 random_state 574\n",
      "accuracy of the model 0.7339449541284404 random_state 575\n",
      "accuracy of the model 0.6880733944954128 random_state 576\n",
      "accuracy of the model 0.7798165137614679 random_state 577\n",
      "accuracy of the model 0.7614678899082569 random_state 578\n",
      "accuracy of the model 0.7431192660550459 random_state 579\n",
      "accuracy of the model 0.7889908256880734 random_state 580\n",
      "accuracy of the model 0.6880733944954128 random_state 581\n",
      "accuracy of the model 0.7431192660550459 random_state 582\n",
      "accuracy of the model 0.7339449541284404 random_state 583\n",
      "accuracy of the model 0.6972477064220184 random_state 584\n",
      "accuracy of the model 0.6972477064220184 random_state 585\n",
      "accuracy of the model 0.7614678899082569 random_state 586\n",
      "accuracy of the model 0.7339449541284404 random_state 587\n",
      "accuracy of the model 0.7155963302752294 random_state 588\n",
      "accuracy of the model 0.7706422018348624 random_state 589\n",
      "accuracy of the model 0.7155963302752294 random_state 590\n",
      "accuracy of the model 0.6697247706422018 random_state 591\n",
      "accuracy of the model 0.7614678899082569 random_state 592\n",
      "accuracy of the model 0.7431192660550459 random_state 593\n",
      "accuracy of the model 0.8165137614678899 random_state 594\n",
      "accuracy of the model 0.6422018348623854 random_state 595\n",
      "accuracy of the model 0.7614678899082569 random_state 596\n",
      "accuracy of the model 0.7522935779816514 random_state 597\n",
      "accuracy of the model 0.7798165137614679 random_state 598\n",
      "accuracy of the model 0.7522935779816514 random_state 599\n",
      "accuracy of the model 0.7339449541284404 random_state 600\n",
      "accuracy of the model 0.6972477064220184 random_state 601\n",
      "accuracy of the model 0.7798165137614679 random_state 602\n",
      "accuracy of the model 0.7339449541284404 random_state 603\n",
      "accuracy of the model 0.6605504587155964 random_state 604\n",
      "accuracy of the model 0.7339449541284404 random_state 605\n",
      "accuracy of the model 0.7339449541284404 random_state 606\n",
      "accuracy of the model 0.7155963302752294 random_state 607\n",
      "accuracy of the model 0.7155963302752294 random_state 608\n",
      "accuracy of the model 0.6880733944954128 random_state 609\n",
      "accuracy of the model 0.7247706422018348 random_state 610\n",
      "accuracy of the model 0.7155963302752294 random_state 611\n",
      "accuracy of the model 0.7247706422018348 random_state 612\n",
      "accuracy of the model 0.7614678899082569 random_state 613\n",
      "accuracy of the model 0.6605504587155964 random_state 614\n",
      "accuracy of the model 0.7614678899082569 random_state 615\n",
      "accuracy of the model 0.7247706422018348 random_state 616\n",
      "accuracy of the model 0.8073394495412844 random_state 617\n",
      "accuracy of the model 0.6972477064220184 random_state 618\n",
      "accuracy of the model 0.7064220183486238 random_state 619\n",
      "accuracy of the model 0.7339449541284404 random_state 620\n",
      "accuracy of the model 0.7155963302752294 random_state 621\n",
      "accuracy of the model 0.7247706422018348 random_state 622\n",
      "accuracy of the model 0.7614678899082569 random_state 623\n",
      "accuracy of the model 0.8256880733944955 random_state 624\n",
      "accuracy of the model 0.7339449541284404 random_state 625\n",
      "accuracy of the model 0.7064220183486238 random_state 626\n",
      "accuracy of the model 0.6697247706422018 random_state 627\n",
      "accuracy of the model 0.7614678899082569 random_state 628\n",
      "accuracy of the model 0.7339449541284404 random_state 629\n",
      "accuracy of the model 0.7522935779816514 random_state 630\n",
      "accuracy of the model 0.7522935779816514 random_state 631\n",
      "accuracy of the model 0.7339449541284404 random_state 632\n",
      "accuracy of the model 0.7155963302752294 random_state 633\n",
      "accuracy of the model 0.7522935779816514 random_state 634\n",
      "accuracy of the model 0.7522935779816514 random_state 635\n",
      "accuracy of the model 0.7889908256880734 random_state 636\n",
      "accuracy of the model 0.7155963302752294 random_state 637\n",
      "accuracy of the model 0.7706422018348624 random_state 638\n",
      "accuracy of the model 0.7155963302752294 random_state 639\n",
      "accuracy of the model 0.7706422018348624 random_state 640\n",
      "accuracy of the model 0.7981651376146789 random_state 641\n",
      "accuracy of the model 0.7522935779816514 random_state 642\n",
      "accuracy of the model 0.7798165137614679 random_state 643\n",
      "accuracy of the model 0.7339449541284404 random_state 644\n",
      "accuracy of the model 0.7614678899082569 random_state 645\n",
      "accuracy of the model 0.7247706422018348 random_state 646\n",
      "accuracy of the model 0.6697247706422018 random_state 647\n",
      "accuracy of the model 0.7798165137614679 random_state 648\n",
      "accuracy of the model 0.8348623853211009 random_state 649\n",
      "accuracy of the model 0.6697247706422018 random_state 650\n",
      "accuracy of the model 0.7064220183486238 random_state 651\n",
      "accuracy of the model 0.6972477064220184 random_state 652\n",
      "accuracy of the model 0.7064220183486238 random_state 653\n",
      "accuracy of the model 0.8256880733944955 random_state 654\n",
      "accuracy of the model 0.6972477064220184 random_state 655\n",
      "accuracy of the model 0.7431192660550459 random_state 656\n",
      "accuracy of the model 0.7614678899082569 random_state 657\n",
      "accuracy of the model 0.6972477064220184 random_state 658\n",
      "accuracy of the model 0.6880733944954128 random_state 659\n",
      "accuracy of the model 0.7614678899082569 random_state 660\n",
      "accuracy of the model 0.7614678899082569 random_state 661\n",
      "accuracy of the model 0.7798165137614679 random_state 662\n",
      "accuracy of the model 0.7339449541284404 random_state 663\n",
      "accuracy of the model 0.7522935779816514 random_state 664\n",
      "accuracy of the model 0.6972477064220184 random_state 665\n",
      "accuracy of the model 0.7522935779816514 random_state 666\n",
      "accuracy of the model 0.6972477064220184 random_state 667\n",
      "accuracy of the model 0.6697247706422018 random_state 668\n",
      "accuracy of the model 0.7614678899082569 random_state 669\n",
      "accuracy of the model 0.6788990825688074 random_state 670\n",
      "accuracy of the model 0.7889908256880734 random_state 671\n",
      "accuracy of the model 0.7798165137614679 random_state 672\n",
      "accuracy of the model 0.7247706422018348 random_state 673\n",
      "accuracy of the model 0.7431192660550459 random_state 674\n",
      "accuracy of the model 0.6880733944954128 random_state 675\n",
      "accuracy of the model 0.7431192660550459 random_state 676\n",
      "accuracy of the model 0.7614678899082569 random_state 677\n",
      "accuracy of the model 0.7431192660550459 random_state 678\n",
      "accuracy of the model 0.7706422018348624 random_state 679\n",
      "accuracy of the model 0.7431192660550459 random_state 680\n",
      "accuracy of the model 0.7431192660550459 random_state 681\n",
      "accuracy of the model 0.7155963302752294 random_state 682\n",
      "accuracy of the model 0.7798165137614679 random_state 683\n",
      "accuracy of the model 0.7064220183486238 random_state 684\n",
      "accuracy of the model 0.7614678899082569 random_state 685\n",
      "accuracy of the model 0.7522935779816514 random_state 686\n",
      "accuracy of the model 0.7522935779816514 random_state 687\n",
      "accuracy of the model 0.7431192660550459 random_state 688\n",
      "accuracy of the model 0.6697247706422018 random_state 689\n",
      "accuracy of the model 0.7064220183486238 random_state 690\n",
      "accuracy of the model 0.7706422018348624 random_state 691\n",
      "accuracy of the model 0.7522935779816514 random_state 692\n",
      "accuracy of the model 0.7614678899082569 random_state 693\n",
      "accuracy of the model 0.7339449541284404 random_state 694\n",
      "accuracy of the model 0.7522935779816514 random_state 695\n",
      "accuracy of the model 0.7431192660550459 random_state 696\n",
      "accuracy of the model 0.7064220183486238 random_state 697\n",
      "accuracy of the model 0.7706422018348624 random_state 698\n",
      "accuracy of the model 0.6880733944954128 random_state 699\n",
      "accuracy of the model 0.7155963302752294 random_state 700\n",
      "accuracy of the model 0.6788990825688074 random_state 701\n",
      "accuracy of the model 0.7064220183486238 random_state 702\n",
      "accuracy of the model 0.6422018348623854 random_state 703\n",
      "accuracy of the model 0.7064220183486238 random_state 704\n",
      "accuracy of the model 0.7339449541284404 random_state 705\n",
      "accuracy of the model 0.7889908256880734 random_state 706\n",
      "accuracy of the model 0.7889908256880734 random_state 707\n",
      "accuracy of the model 0.7614678899082569 random_state 708\n",
      "accuracy of the model 0.7064220183486238 random_state 709\n",
      "accuracy of the model 0.6880733944954128 random_state 710\n",
      "accuracy of the model 0.7889908256880734 random_state 711\n",
      "accuracy of the model 0.7889908256880734 random_state 712\n",
      "accuracy of the model 0.7431192660550459 random_state 713\n",
      "accuracy of the model 0.7064220183486238 random_state 714\n",
      "accuracy of the model 0.7522935779816514 random_state 715\n",
      "accuracy of the model 0.7339449541284404 random_state 716\n",
      "accuracy of the model 0.6605504587155964 random_state 717\n",
      "accuracy of the model 0.7339449541284404 random_state 718\n",
      "accuracy of the model 0.7431192660550459 random_state 719\n",
      "accuracy of the model 0.7614678899082569 random_state 720\n",
      "accuracy of the model 0.8165137614678899 random_state 721\n",
      "accuracy of the model 0.7614678899082569 random_state 722\n",
      "accuracy of the model 0.6788990825688074 random_state 723\n",
      "accuracy of the model 0.6605504587155964 random_state 724\n",
      "accuracy of the model 0.7431192660550459 random_state 725\n",
      "accuracy of the model 0.8256880733944955 random_state 726\n",
      "accuracy of the model 0.7339449541284404 random_state 727\n",
      "accuracy of the model 0.6330275229357798 random_state 728\n",
      "accuracy of the model 0.6605504587155964 random_state 729\n",
      "accuracy of the model 0.7247706422018348 random_state 730\n",
      "accuracy of the model 0.7889908256880734 random_state 731\n",
      "accuracy of the model 0.7798165137614679 random_state 732\n",
      "accuracy of the model 0.7155963302752294 random_state 733\n",
      "accuracy of the model 0.7798165137614679 random_state 734\n",
      "accuracy of the model 0.6422018348623854 random_state 735\n",
      "accuracy of the model 0.6513761467889908 random_state 736\n",
      "accuracy of the model 0.7339449541284404 random_state 737\n",
      "accuracy of the model 0.7339449541284404 random_state 738\n",
      "accuracy of the model 0.6972477064220184 random_state 739\n",
      "accuracy of the model 0.7614678899082569 random_state 740\n",
      "accuracy of the model 0.7247706422018348 random_state 741\n",
      "accuracy of the model 0.6697247706422018 random_state 742\n",
      "accuracy of the model 0.7981651376146789 random_state 743\n",
      "accuracy of the model 0.7981651376146789 random_state 744\n",
      "accuracy of the model 0.8073394495412844 random_state 745\n",
      "accuracy of the model 0.7155963302752294 random_state 746\n",
      "accuracy of the model 0.7522935779816514 random_state 747\n",
      "accuracy of the model 0.7247706422018348 random_state 748\n",
      "accuracy of the model 0.6788990825688074 random_state 749\n",
      "accuracy of the model 0.7339449541284404 random_state 750\n",
      "accuracy of the model 0.7247706422018348 random_state 751\n",
      "accuracy of the model 0.7155963302752294 random_state 752\n",
      "accuracy of the model 0.6697247706422018 random_state 753\n",
      "accuracy of the model 0.7431192660550459 random_state 754\n",
      "accuracy of the model 0.6880733944954128 random_state 755\n",
      "accuracy of the model 0.7431192660550459 random_state 756\n",
      "accuracy of the model 0.7798165137614679 random_state 757\n",
      "accuracy of the model 0.7706422018348624 random_state 758\n",
      "accuracy of the model 0.7706422018348624 random_state 759\n",
      "accuracy of the model 0.7431192660550459 random_state 760\n",
      "accuracy of the model 0.7339449541284404 random_state 761\n",
      "accuracy of the model 0.7706422018348624 random_state 762\n",
      "accuracy of the model 0.6972477064220184 random_state 763\n",
      "accuracy of the model 0.7155963302752294 random_state 764\n",
      "accuracy of the model 0.7706422018348624 random_state 765\n",
      "accuracy of the model 0.7339449541284404 random_state 766\n",
      "accuracy of the model 0.7247706422018348 random_state 767\n",
      "accuracy of the model 0.7706422018348624 random_state 768\n",
      "accuracy of the model 0.7431192660550459 random_state 769\n",
      "accuracy of the model 0.7522935779816514 random_state 770\n",
      "accuracy of the model 0.6330275229357798 random_state 771\n",
      "accuracy of the model 0.7155963302752294 random_state 772\n",
      "accuracy of the model 0.7064220183486238 random_state 773\n",
      "accuracy of the model 0.7614678899082569 random_state 774\n",
      "accuracy of the model 0.7614678899082569 random_state 775\n",
      "accuracy of the model 0.6788990825688074 random_state 776\n",
      "accuracy of the model 0.6788990825688074 random_state 777\n",
      "accuracy of the model 0.7064220183486238 random_state 778\n",
      "accuracy of the model 0.7064220183486238 random_state 779\n",
      "accuracy of the model 0.7431192660550459 random_state 780\n",
      "accuracy of the model 0.7431192660550459 random_state 781\n",
      "accuracy of the model 0.7339449541284404 random_state 782\n",
      "accuracy of the model 0.6697247706422018 random_state 783\n",
      "accuracy of the model 0.7247706422018348 random_state 784\n",
      "accuracy of the model 0.7155963302752294 random_state 785\n",
      "accuracy of the model 0.7614678899082569 random_state 786\n",
      "accuracy of the model 0.6788990825688074 random_state 787\n",
      "accuracy of the model 0.7522935779816514 random_state 788\n",
      "accuracy of the model 0.7706422018348624 random_state 789\n",
      "accuracy of the model 0.7798165137614679 random_state 790\n",
      "accuracy of the model 0.7339449541284404 random_state 791\n",
      "accuracy of the model 0.7889908256880734 random_state 792\n",
      "accuracy of the model 0.7064220183486238 random_state 793\n",
      "accuracy of the model 0.7614678899082569 random_state 794\n",
      "accuracy of the model 0.7155963302752294 random_state 795\n",
      "accuracy of the model 0.7706422018348624 random_state 796\n",
      "accuracy of the model 0.7064220183486238 random_state 797\n",
      "accuracy of the model 0.7431192660550459 random_state 798\n",
      "accuracy of the model 0.7614678899082569 random_state 799\n",
      "accuracy of the model 0.6880733944954128 random_state 800\n",
      "accuracy of the model 0.6788990825688074 random_state 801\n",
      "accuracy of the model 0.7155963302752294 random_state 802\n",
      "accuracy of the model 0.7981651376146789 random_state 803\n",
      "accuracy of the model 0.7614678899082569 random_state 804\n",
      "accuracy of the model 0.6513761467889908 random_state 805\n",
      "accuracy of the model 0.7247706422018348 random_state 806\n",
      "accuracy of the model 0.7064220183486238 random_state 807\n",
      "accuracy of the model 0.7155963302752294 random_state 808\n",
      "accuracy of the model 0.6880733944954128 random_state 809\n",
      "accuracy of the model 0.7247706422018348 random_state 810\n",
      "accuracy of the model 0.7155963302752294 random_state 811\n",
      "accuracy of the model 0.7522935779816514 random_state 812\n",
      "accuracy of the model 0.7706422018348624 random_state 813\n",
      "accuracy of the model 0.7247706422018348 random_state 814\n",
      "accuracy of the model 0.7339449541284404 random_state 815\n",
      "accuracy of the model 0.7798165137614679 random_state 816\n",
      "accuracy of the model 0.7339449541284404 random_state 817\n",
      "accuracy of the model 0.7798165137614679 random_state 818\n",
      "accuracy of the model 0.7522935779816514 random_state 819\n",
      "accuracy of the model 0.6788990825688074 random_state 820\n",
      "accuracy of the model 0.7155963302752294 random_state 821\n",
      "accuracy of the model 0.6788990825688074 random_state 822\n",
      "accuracy of the model 0.7522935779816514 random_state 823\n",
      "accuracy of the model 0.7522935779816514 random_state 824\n",
      "accuracy of the model 0.7614678899082569 random_state 825\n",
      "accuracy of the model 0.6972477064220184 random_state 826\n",
      "accuracy of the model 0.7614678899082569 random_state 827\n",
      "accuracy of the model 0.7522935779816514 random_state 828\n",
      "accuracy of the model 0.8440366972477065 random_state 829\n",
      "accuracy of the model 0.7614678899082569 random_state 830\n",
      "accuracy of the model 0.7339449541284404 random_state 831\n",
      "accuracy of the model 0.6238532110091743 random_state 832\n",
      "accuracy of the model 0.7614678899082569 random_state 833\n",
      "accuracy of the model 0.6788990825688074 random_state 834\n",
      "accuracy of the model 0.7614678899082569 random_state 835\n",
      "accuracy of the model 0.6697247706422018 random_state 836\n",
      "accuracy of the model 0.7064220183486238 random_state 837\n",
      "accuracy of the model 0.7614678899082569 random_state 838\n",
      "accuracy of the model 0.7614678899082569 random_state 839\n",
      "accuracy of the model 0.6788990825688074 random_state 840\n",
      "accuracy of the model 0.7431192660550459 random_state 841\n",
      "accuracy of the model 0.7706422018348624 random_state 842\n",
      "accuracy of the model 0.7064220183486238 random_state 843\n",
      "accuracy of the model 0.7431192660550459 random_state 844\n",
      "accuracy of the model 0.7247706422018348 random_state 845\n",
      "accuracy of the model 0.7889908256880734 random_state 846\n",
      "accuracy of the model 0.7064220183486238 random_state 847\n",
      "accuracy of the model 0.7247706422018348 random_state 848\n",
      "accuracy of the model 0.7981651376146789 random_state 849\n",
      "accuracy of the model 0.7522935779816514 random_state 850\n",
      "accuracy of the model 0.7247706422018348 random_state 851\n",
      "accuracy of the model 0.7522935779816514 random_state 852\n",
      "accuracy of the model 0.5963302752293578 random_state 853\n",
      "accuracy of the model 0.7981651376146789 random_state 854\n",
      "accuracy of the model 0.7522935779816514 random_state 855\n",
      "accuracy of the model 0.6330275229357798 random_state 856\n",
      "accuracy of the model 0.7155963302752294 random_state 857\n",
      "accuracy of the model 0.7981651376146789 random_state 858\n",
      "accuracy of the model 0.7339449541284404 random_state 859\n",
      "accuracy of the model 0.6788990825688074 random_state 860\n",
      "accuracy of the model 0.7522935779816514 random_state 861\n",
      "accuracy of the model 0.7614678899082569 random_state 862\n",
      "accuracy of the model 0.7431192660550459 random_state 863\n",
      "accuracy of the model 0.7247706422018348 random_state 864\n",
      "accuracy of the model 0.7431192660550459 random_state 865\n",
      "accuracy of the model 0.6972477064220184 random_state 866\n",
      "accuracy of the model 0.6697247706422018 random_state 867\n",
      "accuracy of the model 0.6788990825688074 random_state 868\n",
      "accuracy of the model 0.6513761467889908 random_state 869\n",
      "accuracy of the model 0.7339449541284404 random_state 870\n",
      "accuracy of the model 0.7339449541284404 random_state 871\n",
      "accuracy of the model 0.7155963302752294 random_state 872\n",
      "accuracy of the model 0.7431192660550459 random_state 873\n",
      "accuracy of the model 0.6697247706422018 random_state 874\n",
      "accuracy of the model 0.7614678899082569 random_state 875\n",
      "accuracy of the model 0.7431192660550459 random_state 876\n",
      "accuracy of the model 0.7064220183486238 random_state 877\n",
      "accuracy of the model 0.6880733944954128 random_state 878\n",
      "accuracy of the model 0.6788990825688074 random_state 879\n",
      "accuracy of the model 0.7431192660550459 random_state 880\n",
      "accuracy of the model 0.7798165137614679 random_state 881\n",
      "accuracy of the model 0.6880733944954128 random_state 882\n",
      "accuracy of the model 0.7155963302752294 random_state 883\n",
      "accuracy of the model 0.6697247706422018 random_state 884\n",
      "accuracy of the model 0.7247706422018348 random_state 885\n",
      "accuracy of the model 0.6788990825688074 random_state 886\n",
      "accuracy of the model 0.7247706422018348 random_state 887\n",
      "accuracy of the model 0.6697247706422018 random_state 888\n",
      "accuracy of the model 0.6972477064220184 random_state 889\n",
      "accuracy of the model 0.7247706422018348 random_state 890\n",
      "accuracy of the model 0.7889908256880734 random_state 891\n",
      "accuracy of the model 0.7247706422018348 random_state 892\n",
      "accuracy of the model 0.7155963302752294 random_state 893\n",
      "accuracy of the model 0.7522935779816514 random_state 894\n",
      "accuracy of the model 0.7798165137614679 random_state 895\n",
      "accuracy of the model 0.7155963302752294 random_state 896\n",
      "accuracy of the model 0.6972477064220184 random_state 897\n",
      "accuracy of the model 0.7431192660550459 random_state 898\n",
      "accuracy of the model 0.7522935779816514 random_state 899\n",
      "accuracy of the model 0.7614678899082569 random_state 900\n",
      "accuracy of the model 0.6422018348623854 random_state 901\n",
      "accuracy of the model 0.7706422018348624 random_state 902\n",
      "accuracy of the model 0.7706422018348624 random_state 903\n",
      "accuracy of the model 0.7706422018348624 random_state 904\n",
      "accuracy of the model 0.7339449541284404 random_state 905\n",
      "accuracy of the model 0.7889908256880734 random_state 906\n",
      "accuracy of the model 0.7247706422018348 random_state 907\n",
      "accuracy of the model 0.7614678899082569 random_state 908\n",
      "accuracy of the model 0.6697247706422018 random_state 909\n",
      "accuracy of the model 0.6697247706422018 random_state 910\n",
      "accuracy of the model 0.7522935779816514 random_state 911\n",
      "accuracy of the model 0.7064220183486238 random_state 912\n",
      "accuracy of the model 0.7431192660550459 random_state 913\n",
      "accuracy of the model 0.7522935779816514 random_state 914\n",
      "accuracy of the model 0.7339449541284404 random_state 915\n",
      "accuracy of the model 0.6880733944954128 random_state 916\n",
      "accuracy of the model 0.7064220183486238 random_state 917\n",
      "accuracy of the model 0.7706422018348624 random_state 918\n",
      "accuracy of the model 0.6880733944954128 random_state 919\n",
      "accuracy of the model 0.7522935779816514 random_state 920\n",
      "accuracy of the model 0.7064220183486238 random_state 921\n",
      "accuracy of the model 0.7155963302752294 random_state 922\n",
      "accuracy of the model 0.7247706422018348 random_state 923\n",
      "accuracy of the model 0.7064220183486238 random_state 924\n",
      "accuracy of the model 0.6513761467889908 random_state 925\n",
      "accuracy of the model 0.7339449541284404 random_state 926\n",
      "accuracy of the model 0.7889908256880734 random_state 927\n",
      "accuracy of the model 0.7706422018348624 random_state 928\n",
      "accuracy of the model 0.7614678899082569 random_state 929\n",
      "accuracy of the model 0.7155963302752294 random_state 930\n",
      "accuracy of the model 0.7522935779816514 random_state 931\n",
      "accuracy of the model 0.7706422018348624 random_state 932\n",
      "accuracy of the model 0.7339449541284404 random_state 933\n",
      "accuracy of the model 0.7247706422018348 random_state 934\n",
      "accuracy of the model 0.7247706422018348 random_state 935\n",
      "accuracy of the model 0.6972477064220184 random_state 936\n",
      "accuracy of the model 0.6972477064220184 random_state 937\n",
      "accuracy of the model 0.7247706422018348 random_state 938\n",
      "accuracy of the model 0.7155963302752294 random_state 939\n",
      "accuracy of the model 0.7064220183486238 random_state 940\n",
      "accuracy of the model 0.7614678899082569 random_state 941\n",
      "accuracy of the model 0.6880733944954128 random_state 942\n",
      "accuracy of the model 0.7247706422018348 random_state 943\n",
      "accuracy of the model 0.7798165137614679 random_state 944\n",
      "accuracy of the model 0.7247706422018348 random_state 945\n",
      "accuracy of the model 0.6697247706422018 random_state 946\n",
      "accuracy of the model 0.7706422018348624 random_state 947\n",
      "accuracy of the model 0.6605504587155964 random_state 948\n",
      "accuracy of the model 0.7155963302752294 random_state 949\n",
      "accuracy of the model 0.7339449541284404 random_state 950\n",
      "accuracy of the model 0.7247706422018348 random_state 951\n",
      "accuracy of the model 0.7064220183486238 random_state 952\n",
      "accuracy of the model 0.7339449541284404 random_state 953\n",
      "accuracy of the model 0.7339449541284404 random_state 954\n",
      "accuracy of the model 0.7431192660550459 random_state 955\n",
      "accuracy of the model 0.7339449541284404 random_state 956\n",
      "accuracy of the model 0.7155963302752294 random_state 957\n",
      "accuracy of the model 0.7889908256880734 random_state 958\n",
      "accuracy of the model 0.7155963302752294 random_state 959\n",
      "accuracy of the model 0.7155963302752294 random_state 960\n",
      "accuracy of the model 0.6697247706422018 random_state 961\n",
      "accuracy of the model 0.7247706422018348 random_state 962\n",
      "accuracy of the model 0.6330275229357798 random_state 963\n",
      "accuracy of the model 0.7614678899082569 random_state 964\n",
      "accuracy of the model 0.7981651376146789 random_state 965\n",
      "accuracy of the model 0.7247706422018348 random_state 966\n",
      "accuracy of the model 0.7064220183486238 random_state 967\n",
      "accuracy of the model 0.7339449541284404 random_state 968\n",
      "accuracy of the model 0.7431192660550459 random_state 969\n",
      "accuracy of the model 0.6972477064220184 random_state 970\n",
      "accuracy of the model 0.7706422018348624 random_state 971\n",
      "accuracy of the model 0.7247706422018348 random_state 972\n",
      "accuracy of the model 0.7155963302752294 random_state 973\n",
      "accuracy of the model 0.6697247706422018 random_state 974\n",
      "accuracy of the model 0.7431192660550459 random_state 975\n",
      "accuracy of the model 0.7064220183486238 random_state 976\n",
      "accuracy of the model 0.7064220183486238 random_state 977\n",
      "accuracy of the model 0.6788990825688074 random_state 978\n",
      "accuracy of the model 0.6972477064220184 random_state 979\n",
      "accuracy of the model 0.6972477064220184 random_state 980\n",
      "accuracy of the model 0.7706422018348624 random_state 981\n",
      "accuracy of the model 0.6972477064220184 random_state 982\n",
      "accuracy of the model 0.8073394495412844 random_state 983\n",
      "accuracy of the model 0.6055045871559633 random_state 984\n",
      "accuracy of the model 0.6697247706422018 random_state 985\n",
      "accuracy of the model 0.7064220183486238 random_state 986\n",
      "accuracy of the model 0.7706422018348624 random_state 987\n",
      "accuracy of the model 0.7614678899082569 random_state 988\n",
      "accuracy of the model 0.7706422018348624 random_state 989\n",
      "accuracy of the model 0.7522935779816514 random_state 990\n",
      "accuracy of the model 0.7706422018348624 random_state 991\n",
      "accuracy of the model 0.7798165137614679 random_state 992\n",
      "accuracy of the model 0.6697247706422018 random_state 993\n",
      "accuracy of the model 0.7064220183486238 random_state 994\n",
      "accuracy of the model 0.7522935779816514 random_state 995\n",
      "accuracy of the model 0.7614678899082569 random_state 996\n",
      "accuracy of the model 0.7522935779816514 random_state 997\n",
      "accuracy of the model 0.7981651376146789 random_state 998\n",
      "accuracy of the model 0.7247706422018348 random_state 999\n",
      "accuracy of the model 0.7431192660550459 random_state 1000\n",
      "accuracy of the model 0.6788990825688074 random_state 1001\n",
      "accuracy of the model 0.7064220183486238 random_state 1002\n",
      "accuracy of the model 0.7522935779816514 random_state 1003\n",
      "accuracy of the model 0.7339449541284404 random_state 1004\n",
      "accuracy of the model 0.7798165137614679 random_state 1005\n",
      "accuracy of the model 0.6880733944954128 random_state 1006\n",
      "accuracy of the model 0.6513761467889908 random_state 1007\n",
      "accuracy of the model 0.7431192660550459 random_state 1008\n",
      "accuracy of the model 0.6972477064220184 random_state 1009\n",
      "accuracy of the model 0.7522935779816514 random_state 1010\n",
      "accuracy of the model 0.7431192660550459 random_state 1011\n",
      "accuracy of the model 0.7155963302752294 random_state 1012\n",
      "accuracy of the model 0.7247706422018348 random_state 1013\n",
      "accuracy of the model 0.7706422018348624 random_state 1014\n",
      "accuracy of the model 0.7155963302752294 random_state 1015\n",
      "accuracy of the model 0.7339449541284404 random_state 1016\n",
      "accuracy of the model 0.7614678899082569 random_state 1017\n",
      "accuracy of the model 0.7339449541284404 random_state 1018\n",
      "accuracy of the model 0.6788990825688074 random_state 1019\n",
      "accuracy of the model 0.7064220183486238 random_state 1020\n",
      "accuracy of the model 0.7431192660550459 random_state 1021\n",
      "accuracy of the model 0.7706422018348624 random_state 1022\n",
      "accuracy of the model 0.7522935779816514 random_state 1023\n",
      "accuracy of the model 0.8165137614678899 random_state 1024\n",
      "accuracy of the model 0.7706422018348624 random_state 1025\n",
      "accuracy of the model 0.6880733944954128 random_state 1026\n",
      "accuracy of the model 0.7339449541284404 random_state 1027\n",
      "accuracy of the model 0.7155963302752294 random_state 1028\n",
      "accuracy of the model 0.7339449541284404 random_state 1029\n",
      "accuracy of the model 0.7431192660550459 random_state 1030\n",
      "accuracy of the model 0.7339449541284404 random_state 1031\n",
      "accuracy of the model 0.7889908256880734 random_state 1032\n",
      "accuracy of the model 0.7339449541284404 random_state 1033\n",
      "accuracy of the model 0.7431192660550459 random_state 1034\n",
      "accuracy of the model 0.7339449541284404 random_state 1035\n",
      "accuracy of the model 0.7155963302752294 random_state 1036\n",
      "accuracy of the model 0.6788990825688074 random_state 1037\n",
      "accuracy of the model 0.7431192660550459 random_state 1038\n",
      "accuracy of the model 0.7247706422018348 random_state 1039\n",
      "accuracy of the model 0.7247706422018348 random_state 1040\n",
      "accuracy of the model 0.7064220183486238 random_state 1041\n",
      "accuracy of the model 0.7339449541284404 random_state 1042\n",
      "accuracy of the model 0.7155963302752294 random_state 1043\n",
      "accuracy of the model 0.6513761467889908 random_state 1044\n",
      "accuracy of the model 0.6972477064220184 random_state 1045\n",
      "accuracy of the model 0.7614678899082569 random_state 1046\n",
      "accuracy of the model 0.7522935779816514 random_state 1047\n",
      "accuracy of the model 0.6880733944954128 random_state 1048\n",
      "accuracy of the model 0.7247706422018348 random_state 1049\n",
      "accuracy of the model 0.7247706422018348 random_state 1050\n",
      "accuracy of the model 0.7247706422018348 random_state 1051\n",
      "accuracy of the model 0.7431192660550459 random_state 1052\n",
      "accuracy of the model 0.6697247706422018 random_state 1053\n",
      "accuracy of the model 0.7247706422018348 random_state 1054\n",
      "accuracy of the model 0.7339449541284404 random_state 1055\n",
      "accuracy of the model 0.7339449541284404 random_state 1056\n",
      "accuracy of the model 0.6880733944954128 random_state 1057\n",
      "accuracy of the model 0.7247706422018348 random_state 1058\n",
      "accuracy of the model 0.7431192660550459 random_state 1059\n",
      "accuracy of the model 0.8073394495412844 random_state 1060\n",
      "accuracy of the model 0.7431192660550459 random_state 1061\n",
      "accuracy of the model 0.7247706422018348 random_state 1062\n",
      "accuracy of the model 0.7706422018348624 random_state 1063\n",
      "accuracy of the model 0.7431192660550459 random_state 1064\n",
      "accuracy of the model 0.7339449541284404 random_state 1065\n",
      "accuracy of the model 0.7431192660550459 random_state 1066\n",
      "accuracy of the model 0.7339449541284404 random_state 1067\n",
      "accuracy of the model 0.7064220183486238 random_state 1068\n",
      "accuracy of the model 0.7155963302752294 random_state 1069\n",
      "accuracy of the model 0.7981651376146789 random_state 1070\n",
      "accuracy of the model 0.7064220183486238 random_state 1071\n",
      "accuracy of the model 0.7981651376146789 random_state 1072\n",
      "accuracy of the model 0.7614678899082569 random_state 1073\n",
      "accuracy of the model 0.6605504587155964 random_state 1074\n",
      "accuracy of the model 0.7706422018348624 random_state 1075\n",
      "accuracy of the model 0.7614678899082569 random_state 1076\n",
      "accuracy of the model 0.7706422018348624 random_state 1077\n",
      "accuracy of the model 0.6605504587155964 random_state 1078\n",
      "accuracy of the model 0.7247706422018348 random_state 1079\n",
      "accuracy of the model 0.7798165137614679 random_state 1080\n",
      "accuracy of the model 0.6880733944954128 random_state 1081\n",
      "accuracy of the model 0.7614678899082569 random_state 1082\n",
      "accuracy of the model 0.7614678899082569 random_state 1083\n",
      "accuracy of the model 0.7064220183486238 random_state 1084\n",
      "accuracy of the model 0.7522935779816514 random_state 1085\n",
      "accuracy of the model 0.6697247706422018 random_state 1086\n",
      "accuracy of the model 0.7522935779816514 random_state 1087\n",
      "accuracy of the model 0.7706422018348624 random_state 1088\n",
      "accuracy of the model 0.7522935779816514 random_state 1089\n",
      "accuracy of the model 0.7889908256880734 random_state 1090\n",
      "accuracy of the model 0.6697247706422018 random_state 1091\n",
      "accuracy of the model 0.6788990825688074 random_state 1092\n",
      "accuracy of the model 0.6605504587155964 random_state 1093\n",
      "accuracy of the model 0.7981651376146789 random_state 1094\n",
      "accuracy of the model 0.6880733944954128 random_state 1095\n",
      "accuracy of the model 0.7614678899082569 random_state 1096\n",
      "accuracy of the model 0.7431192660550459 random_state 1097\n",
      "accuracy of the model 0.7614678899082569 random_state 1098\n",
      "accuracy of the model 0.7247706422018348 random_state 1099\n",
      "accuracy of the model 0.7798165137614679 random_state 1100\n",
      "accuracy of the model 0.7339449541284404 random_state 1101\n",
      "accuracy of the model 0.7431192660550459 random_state 1102\n",
      "accuracy of the model 0.7798165137614679 random_state 1103\n",
      "accuracy of the model 0.7339449541284404 random_state 1104\n",
      "accuracy of the model 0.7614678899082569 random_state 1105\n",
      "accuracy of the model 0.7614678899082569 random_state 1106\n",
      "accuracy of the model 0.7247706422018348 random_state 1107\n",
      "accuracy of the model 0.6788990825688074 random_state 1108\n",
      "accuracy of the model 0.7431192660550459 random_state 1109\n",
      "accuracy of the model 0.7706422018348624 random_state 1110\n",
      "accuracy of the model 0.7981651376146789 random_state 1111\n",
      "accuracy of the model 0.6605504587155964 random_state 1112\n",
      "accuracy of the model 0.7431192660550459 random_state 1113\n",
      "accuracy of the model 0.7064220183486238 random_state 1114\n",
      "accuracy of the model 0.7247706422018348 random_state 1115\n",
      "accuracy of the model 0.7064220183486238 random_state 1116\n",
      "accuracy of the model 0.7522935779816514 random_state 1117\n",
      "accuracy of the model 0.7706422018348624 random_state 1118\n",
      "accuracy of the model 0.7706422018348624 random_state 1119\n",
      "accuracy of the model 0.6422018348623854 random_state 1120\n",
      "accuracy of the model 0.6972477064220184 random_state 1121\n",
      "accuracy of the model 0.7889908256880734 random_state 1122\n",
      "accuracy of the model 0.7431192660550459 random_state 1123\n",
      "accuracy of the model 0.7339449541284404 random_state 1124\n",
      "accuracy of the model 0.7339449541284404 random_state 1125\n",
      "accuracy of the model 0.7247706422018348 random_state 1126\n",
      "accuracy of the model 0.6330275229357798 random_state 1127\n",
      "accuracy of the model 0.7339449541284404 random_state 1128\n",
      "accuracy of the model 0.7339449541284404 random_state 1129\n",
      "accuracy of the model 0.7247706422018348 random_state 1130\n",
      "accuracy of the model 0.6880733944954128 random_state 1131\n",
      "accuracy of the model 0.6788990825688074 random_state 1132\n",
      "accuracy of the model 0.7247706422018348 random_state 1133\n",
      "accuracy of the model 0.7614678899082569 random_state 1134\n",
      "accuracy of the model 0.7064220183486238 random_state 1135\n",
      "accuracy of the model 0.8073394495412844 random_state 1136\n",
      "accuracy of the model 0.7339449541284404 random_state 1137\n",
      "accuracy of the model 0.7064220183486238 random_state 1138\n",
      "accuracy of the model 0.7155963302752294 random_state 1139\n",
      "accuracy of the model 0.7889908256880734 random_state 1140\n",
      "accuracy of the model 0.7889908256880734 random_state 1141\n",
      "accuracy of the model 0.7981651376146789 random_state 1142\n",
      "accuracy of the model 0.7155963302752294 random_state 1143\n",
      "accuracy of the model 0.7247706422018348 random_state 1144\n",
      "accuracy of the model 0.7522935779816514 random_state 1145\n",
      "accuracy of the model 0.7155963302752294 random_state 1146\n",
      "accuracy of the model 0.7889908256880734 random_state 1147\n",
      "accuracy of the model 0.7339449541284404 random_state 1148\n",
      "accuracy of the model 0.7155963302752294 random_state 1149\n",
      "accuracy of the model 0.7339449541284404 random_state 1150\n",
      "accuracy of the model 0.7614678899082569 random_state 1151\n",
      "accuracy of the model 0.7247706422018348 random_state 1152\n",
      "accuracy of the model 0.7431192660550459 random_state 1153\n",
      "accuracy of the model 0.6788990825688074 random_state 1154\n",
      "accuracy of the model 0.7431192660550459 random_state 1155\n",
      "accuracy of the model 0.7522935779816514 random_state 1156\n",
      "accuracy of the model 0.7155963302752294 random_state 1157\n",
      "accuracy of the model 0.7431192660550459 random_state 1158\n",
      "accuracy of the model 0.7064220183486238 random_state 1159\n",
      "accuracy of the model 0.7522935779816514 random_state 1160\n",
      "accuracy of the model 0.7706422018348624 random_state 1161\n",
      "accuracy of the model 0.6605504587155964 random_state 1162\n",
      "accuracy of the model 0.6788990825688074 random_state 1163\n",
      "accuracy of the model 0.7155963302752294 random_state 1164\n",
      "accuracy of the model 0.7889908256880734 random_state 1165\n",
      "accuracy of the model 0.7247706422018348 random_state 1166\n",
      "accuracy of the model 0.6788990825688074 random_state 1167\n",
      "accuracy of the model 0.7706422018348624 random_state 1168\n",
      "accuracy of the model 0.7431192660550459 random_state 1169\n",
      "accuracy of the model 0.7706422018348624 random_state 1170\n",
      "accuracy of the model 0.7155963302752294 random_state 1171\n",
      "accuracy of the model 0.7522935779816514 random_state 1172\n",
      "accuracy of the model 0.7706422018348624 random_state 1173\n",
      "accuracy of the model 0.7247706422018348 random_state 1174\n",
      "accuracy of the model 0.6880733944954128 random_state 1175\n",
      "accuracy of the model 0.7981651376146789 random_state 1176\n",
      "accuracy of the model 0.7614678899082569 random_state 1177\n",
      "accuracy of the model 0.7614678899082569 random_state 1178\n",
      "accuracy of the model 0.7798165137614679 random_state 1179\n",
      "accuracy of the model 0.7614678899082569 random_state 1180\n",
      "accuracy of the model 0.7247706422018348 random_state 1181\n",
      "accuracy of the model 0.7247706422018348 random_state 1182\n",
      "accuracy of the model 0.7981651376146789 random_state 1183\n",
      "accuracy of the model 0.7064220183486238 random_state 1184\n",
      "accuracy of the model 0.7064220183486238 random_state 1185\n",
      "accuracy of the model 0.7522935779816514 random_state 1186\n",
      "accuracy of the model 0.7614678899082569 random_state 1187\n",
      "accuracy of the model 0.6972477064220184 random_state 1188\n",
      "accuracy of the model 0.7889908256880734 random_state 1189\n",
      "accuracy of the model 0.7247706422018348 random_state 1190\n",
      "accuracy of the model 0.7706422018348624 random_state 1191\n",
      "accuracy of the model 0.7431192660550459 random_state 1192\n",
      "accuracy of the model 0.7889908256880734 random_state 1193\n",
      "accuracy of the model 0.7339449541284404 random_state 1194\n",
      "accuracy of the model 0.7064220183486238 random_state 1195\n",
      "accuracy of the model 0.7247706422018348 random_state 1196\n",
      "accuracy of the model 0.7431192660550459 random_state 1197\n",
      "accuracy of the model 0.6972477064220184 random_state 1198\n",
      "accuracy of the model 0.7339449541284404 random_state 1199\n",
      "accuracy of the model 0.7522935779816514 random_state 1200\n",
      "accuracy of the model 0.6055045871559633 random_state 1201\n",
      "accuracy of the model 0.7522935779816514 random_state 1202\n",
      "accuracy of the model 0.7431192660550459 random_state 1203\n",
      "accuracy of the model 0.6880733944954128 random_state 1204\n",
      "accuracy of the model 0.7339449541284404 random_state 1205\n",
      "accuracy of the model 0.7889908256880734 random_state 1206\n",
      "accuracy of the model 0.7522935779816514 random_state 1207\n",
      "accuracy of the model 0.7522935779816514 random_state 1208\n",
      "accuracy of the model 0.7522935779816514 random_state 1209\n",
      "accuracy of the model 0.8165137614678899 random_state 1210\n",
      "accuracy of the model 0.7431192660550459 random_state 1211\n",
      "accuracy of the model 0.7155963302752294 random_state 1212\n",
      "accuracy of the model 0.7431192660550459 random_state 1213\n",
      "accuracy of the model 0.7522935779816514 random_state 1214\n",
      "accuracy of the model 0.7247706422018348 random_state 1215\n",
      "accuracy of the model 0.7155963302752294 random_state 1216\n",
      "accuracy of the model 0.7431192660550459 random_state 1217\n",
      "accuracy of the model 0.6697247706422018 random_state 1218\n",
      "accuracy of the model 0.8073394495412844 random_state 1219\n",
      "accuracy of the model 0.6513761467889908 random_state 1220\n",
      "accuracy of the model 0.6605504587155964 random_state 1221\n",
      "accuracy of the model 0.7155963302752294 random_state 1222\n",
      "accuracy of the model 0.7431192660550459 random_state 1223\n",
      "accuracy of the model 0.7155963302752294 random_state 1224\n",
      "accuracy of the model 0.7889908256880734 random_state 1225\n",
      "accuracy of the model 0.7706422018348624 random_state 1226\n",
      "accuracy of the model 0.7064220183486238 random_state 1227\n",
      "accuracy of the model 0.7889908256880734 random_state 1228\n",
      "accuracy of the model 0.7798165137614679 random_state 1229\n",
      "accuracy of the model 0.6697247706422018 random_state 1230\n",
      "accuracy of the model 0.7247706422018348 random_state 1231\n",
      "accuracy of the model 0.7155963302752294 random_state 1232\n",
      "accuracy of the model 0.7981651376146789 random_state 1233\n",
      "accuracy of the model 0.7798165137614679 random_state 1234\n",
      "accuracy of the model 0.7798165137614679 random_state 1235\n",
      "accuracy of the model 0.7155963302752294 random_state 1236\n",
      "accuracy of the model 0.7798165137614679 random_state 1237\n",
      "accuracy of the model 0.7431192660550459 random_state 1238\n",
      "accuracy of the model 0.7522935779816514 random_state 1239\n",
      "accuracy of the model 0.7064220183486238 random_state 1240\n",
      "accuracy of the model 0.6880733944954128 random_state 1241\n",
      "accuracy of the model 0.6972477064220184 random_state 1242\n",
      "accuracy of the model 0.7522935779816514 random_state 1243\n",
      "accuracy of the model 0.6972477064220184 random_state 1244\n",
      "accuracy of the model 0.7339449541284404 random_state 1245\n",
      "accuracy of the model 0.7155963302752294 random_state 1246\n",
      "accuracy of the model 0.6605504587155964 random_state 1247\n",
      "accuracy of the model 0.7614678899082569 random_state 1248\n",
      "accuracy of the model 0.7155963302752294 random_state 1249\n",
      "accuracy of the model 0.6880733944954128 random_state 1250\n",
      "accuracy of the model 0.6697247706422018 random_state 1251\n",
      "accuracy of the model 0.6880733944954128 random_state 1252\n",
      "accuracy of the model 0.7339449541284404 random_state 1253\n",
      "accuracy of the model 0.7247706422018348 random_state 1254\n",
      "accuracy of the model 0.7155963302752294 random_state 1255\n",
      "accuracy of the model 0.7155963302752294 random_state 1256\n",
      "accuracy of the model 0.7889908256880734 random_state 1257\n",
      "accuracy of the model 0.7614678899082569 random_state 1258\n",
      "accuracy of the model 0.6422018348623854 random_state 1259\n",
      "accuracy of the model 0.7339449541284404 random_state 1260\n",
      "accuracy of the model 0.6788990825688074 random_state 1261\n",
      "accuracy of the model 0.7247706422018348 random_state 1262\n",
      "accuracy of the model 0.6880733944954128 random_state 1263\n",
      "accuracy of the model 0.6788990825688074 random_state 1264\n",
      "accuracy of the model 0.7522935779816514 random_state 1265\n",
      "accuracy of the model 0.7155963302752294 random_state 1266\n",
      "accuracy of the model 0.7247706422018348 random_state 1267\n",
      "accuracy of the model 0.6972477064220184 random_state 1268\n",
      "accuracy of the model 0.7431192660550459 random_state 1269\n",
      "accuracy of the model 0.6972477064220184 random_state 1270\n",
      "accuracy of the model 0.7247706422018348 random_state 1271\n",
      "accuracy of the model 0.6330275229357798 random_state 1272\n",
      "accuracy of the model 0.6697247706422018 random_state 1273\n",
      "accuracy of the model 0.6880733944954128 random_state 1274\n",
      "accuracy of the model 0.6972477064220184 random_state 1275\n",
      "accuracy of the model 0.7431192660550459 random_state 1276\n",
      "accuracy of the model 0.7614678899082569 random_state 1277\n",
      "accuracy of the model 0.7339449541284404 random_state 1278\n",
      "accuracy of the model 0.7247706422018348 random_state 1279\n",
      "accuracy of the model 0.7431192660550459 random_state 1280\n",
      "accuracy of the model 0.7155963302752294 random_state 1281\n",
      "accuracy of the model 0.7522935779816514 random_state 1282\n",
      "accuracy of the model 0.7614678899082569 random_state 1283\n",
      "accuracy of the model 0.7339449541284404 random_state 1284\n",
      "accuracy of the model 0.7064220183486238 random_state 1285\n",
      "accuracy of the model 0.7522935779816514 random_state 1286\n",
      "accuracy of the model 0.7522935779816514 random_state 1287\n",
      "accuracy of the model 0.7522935779816514 random_state 1288\n",
      "accuracy of the model 0.6605504587155964 random_state 1289\n",
      "accuracy of the model 0.6880733944954128 random_state 1290\n",
      "accuracy of the model 0.6880733944954128 random_state 1291\n",
      "accuracy of the model 0.7431192660550459 random_state 1292\n",
      "accuracy of the model 0.6513761467889908 random_state 1293\n",
      "accuracy of the model 0.7155963302752294 random_state 1294\n",
      "accuracy of the model 0.7155963302752294 random_state 1295\n",
      "accuracy of the model 0.7706422018348624 random_state 1296\n",
      "accuracy of the model 0.6972477064220184 random_state 1297\n",
      "accuracy of the model 0.7522935779816514 random_state 1298\n",
      "accuracy of the model 0.7614678899082569 random_state 1299\n",
      "accuracy of the model 0.7614678899082569 random_state 1300\n",
      "accuracy of the model 0.6880733944954128 random_state 1301\n",
      "accuracy of the model 0.7064220183486238 random_state 1302\n",
      "accuracy of the model 0.6972477064220184 random_state 1303\n",
      "accuracy of the model 0.6788990825688074 random_state 1304\n",
      "accuracy of the model 0.7064220183486238 random_state 1305\n",
      "accuracy of the model 0.7064220183486238 random_state 1306\n",
      "accuracy of the model 0.6880733944954128 random_state 1307\n",
      "accuracy of the model 0.6972477064220184 random_state 1308\n",
      "accuracy of the model 0.7706422018348624 random_state 1309\n",
      "accuracy of the model 0.7155963302752294 random_state 1310\n",
      "accuracy of the model 0.7431192660550459 random_state 1311\n",
      "accuracy of the model 0.7155963302752294 random_state 1312\n",
      "accuracy of the model 0.7706422018348624 random_state 1313\n",
      "accuracy of the model 0.7064220183486238 random_state 1314\n",
      "accuracy of the model 0.7522935779816514 random_state 1315\n",
      "accuracy of the model 0.7155963302752294 random_state 1316\n",
      "accuracy of the model 0.7614678899082569 random_state 1317\n",
      "accuracy of the model 0.7431192660550459 random_state 1318\n",
      "accuracy of the model 0.6330275229357798 random_state 1319\n",
      "accuracy of the model 0.7798165137614679 random_state 1320\n",
      "accuracy of the model 0.7339449541284404 random_state 1321\n",
      "accuracy of the model 0.6146788990825688 random_state 1322\n",
      "accuracy of the model 0.7064220183486238 random_state 1323\n",
      "accuracy of the model 0.7522935779816514 random_state 1324\n",
      "accuracy of the model 0.7247706422018348 random_state 1325\n",
      "accuracy of the model 0.6788990825688074 random_state 1326\n",
      "accuracy of the model 0.6788990825688074 random_state 1327\n",
      "accuracy of the model 0.6972477064220184 random_state 1328\n",
      "accuracy of the model 0.7522935779816514 random_state 1329\n",
      "accuracy of the model 0.7614678899082569 random_state 1330\n",
      "accuracy of the model 0.7155963302752294 random_state 1331\n",
      "accuracy of the model 0.7522935779816514 random_state 1332\n",
      "accuracy of the model 0.7155963302752294 random_state 1333\n",
      "accuracy of the model 0.6972477064220184 random_state 1334\n",
      "accuracy of the model 0.7522935779816514 random_state 1335\n",
      "accuracy of the model 0.7431192660550459 random_state 1336\n",
      "accuracy of the model 0.6605504587155964 random_state 1337\n",
      "accuracy of the model 0.7522935779816514 random_state 1338\n",
      "accuracy of the model 0.7247706422018348 random_state 1339\n",
      "accuracy of the model 0.7339449541284404 random_state 1340\n",
      "accuracy of the model 0.7155963302752294 random_state 1341\n",
      "accuracy of the model 0.7064220183486238 random_state 1342\n",
      "accuracy of the model 0.7522935779816514 random_state 1343\n",
      "accuracy of the model 0.7431192660550459 random_state 1344\n",
      "accuracy of the model 0.7889908256880734 random_state 1345\n",
      "accuracy of the model 0.7155963302752294 random_state 1346\n",
      "accuracy of the model 0.7339449541284404 random_state 1347\n",
      "accuracy of the model 0.7614678899082569 random_state 1348\n",
      "accuracy of the model 0.7431192660550459 random_state 1349\n",
      "accuracy of the model 0.7339449541284404 random_state 1350\n",
      "accuracy of the model 0.7522935779816514 random_state 1351\n",
      "accuracy of the model 0.7339449541284404 random_state 1352\n",
      "accuracy of the model 0.6880733944954128 random_state 1353\n",
      "accuracy of the model 0.7522935779816514 random_state 1354\n",
      "accuracy of the model 0.7339449541284404 random_state 1355\n",
      "accuracy of the model 0.7064220183486238 random_state 1356\n",
      "accuracy of the model 0.7522935779816514 random_state 1357\n",
      "accuracy of the model 0.6697247706422018 random_state 1358\n",
      "accuracy of the model 0.7064220183486238 random_state 1359\n",
      "accuracy of the model 0.7155963302752294 random_state 1360\n",
      "accuracy of the model 0.7614678899082569 random_state 1361\n",
      "accuracy of the model 0.7614678899082569 random_state 1362\n",
      "accuracy of the model 0.7064220183486238 random_state 1363\n",
      "accuracy of the model 0.7064220183486238 random_state 1364\n",
      "accuracy of the model 0.7706422018348624 random_state 1365\n",
      "accuracy of the model 0.7431192660550459 random_state 1366\n",
      "accuracy of the model 0.7798165137614679 random_state 1367\n",
      "accuracy of the model 0.7431192660550459 random_state 1368\n",
      "accuracy of the model 0.7431192660550459 random_state 1369\n",
      "accuracy of the model 0.7339449541284404 random_state 1370\n",
      "accuracy of the model 0.6972477064220184 random_state 1371\n",
      "accuracy of the model 0.6697247706422018 random_state 1372\n",
      "accuracy of the model 0.7522935779816514 random_state 1373\n",
      "accuracy of the model 0.7155963302752294 random_state 1374\n",
      "accuracy of the model 0.7064220183486238 random_state 1375\n",
      "accuracy of the model 0.7064220183486238 random_state 1376\n",
      "accuracy of the model 0.6972477064220184 random_state 1377\n",
      "accuracy of the model 0.6330275229357798 random_state 1378\n",
      "accuracy of the model 0.7431192660550459 random_state 1379\n",
      "accuracy of the model 0.6513761467889908 random_state 1380\n",
      "accuracy of the model 0.7706422018348624 random_state 1381\n",
      "accuracy of the model 0.7522935779816514 random_state 1382\n",
      "accuracy of the model 0.7064220183486238 random_state 1383\n",
      "accuracy of the model 0.7339449541284404 random_state 1384\n",
      "accuracy of the model 0.7798165137614679 random_state 1385\n",
      "accuracy of the model 0.7706422018348624 random_state 1386\n",
      "accuracy of the model 0.7339449541284404 random_state 1387\n",
      "accuracy of the model 0.6605504587155964 random_state 1388\n",
      "accuracy of the model 0.6972477064220184 random_state 1389\n",
      "accuracy of the model 0.7064220183486238 random_state 1390\n",
      "accuracy of the model 0.7614678899082569 random_state 1391\n",
      "accuracy of the model 0.7431192660550459 random_state 1392\n",
      "accuracy of the model 0.7155963302752294 random_state 1393\n",
      "accuracy of the model 0.7889908256880734 random_state 1394\n",
      "accuracy of the model 0.7614678899082569 random_state 1395\n",
      "accuracy of the model 0.7981651376146789 random_state 1396\n",
      "accuracy of the model 0.7431192660550459 random_state 1397\n",
      "accuracy of the model 0.7522935779816514 random_state 1398\n",
      "accuracy of the model 0.7064220183486238 random_state 1399\n",
      "accuracy of the model 0.7431192660550459 random_state 1400\n",
      "accuracy of the model 0.7798165137614679 random_state 1401\n",
      "accuracy of the model 0.7247706422018348 random_state 1402\n",
      "accuracy of the model 0.6697247706422018 random_state 1403\n",
      "accuracy of the model 0.7339449541284404 random_state 1404\n",
      "accuracy of the model 0.6972477064220184 random_state 1405\n",
      "accuracy of the model 0.7798165137614679 random_state 1406\n",
      "accuracy of the model 0.7247706422018348 random_state 1407\n",
      "accuracy of the model 0.7431192660550459 random_state 1408\n",
      "accuracy of the model 0.7339449541284404 random_state 1409\n",
      "accuracy of the model 0.7614678899082569 random_state 1410\n",
      "accuracy of the model 0.7798165137614679 random_state 1411\n",
      "accuracy of the model 0.7155963302752294 random_state 1412\n",
      "accuracy of the model 0.7155963302752294 random_state 1413\n",
      "accuracy of the model 0.6697247706422018 random_state 1414\n",
      "accuracy of the model 0.7064220183486238 random_state 1415\n",
      "accuracy of the model 0.7798165137614679 random_state 1416\n",
      "accuracy of the model 0.7247706422018348 random_state 1417\n",
      "accuracy of the model 0.7798165137614679 random_state 1418\n",
      "accuracy of the model 0.7431192660550459 random_state 1419\n",
      "accuracy of the model 0.7155963302752294 random_state 1420\n",
      "accuracy of the model 0.6788990825688074 random_state 1421\n",
      "accuracy of the model 0.7522935779816514 random_state 1422\n",
      "accuracy of the model 0.7522935779816514 random_state 1423\n",
      "accuracy of the model 0.7522935779816514 random_state 1424\n",
      "accuracy of the model 0.8256880733944955 random_state 1425\n",
      "accuracy of the model 0.7064220183486238 random_state 1426\n",
      "accuracy of the model 0.7339449541284404 random_state 1427\n",
      "accuracy of the model 0.7339449541284404 random_state 1428\n",
      "accuracy of the model 0.6788990825688074 random_state 1429\n",
      "accuracy of the model 0.6697247706422018 random_state 1430\n",
      "accuracy of the model 0.7247706422018348 random_state 1431\n",
      "accuracy of the model 0.7889908256880734 random_state 1432\n",
      "accuracy of the model 0.7431192660550459 random_state 1433\n",
      "accuracy of the model 0.7247706422018348 random_state 1434\n",
      "accuracy of the model 0.7339449541284404 random_state 1435\n",
      "accuracy of the model 0.7155963302752294 random_state 1436\n",
      "accuracy of the model 0.7339449541284404 random_state 1437\n",
      "accuracy of the model 0.7155963302752294 random_state 1438\n",
      "accuracy of the model 0.7522935779816514 random_state 1439\n",
      "accuracy of the model 0.6880733944954128 random_state 1440\n",
      "accuracy of the model 0.7339449541284404 random_state 1441\n",
      "accuracy of the model 0.8348623853211009 random_state 1442\n",
      "accuracy of the model 0.7247706422018348 random_state 1443\n",
      "accuracy of the model 0.7064220183486238 random_state 1444\n",
      "accuracy of the model 0.7798165137614679 random_state 1445\n",
      "accuracy of the model 0.7339449541284404 random_state 1446\n",
      "accuracy of the model 0.7431192660550459 random_state 1447\n",
      "accuracy of the model 0.7247706422018348 random_state 1448\n",
      "accuracy of the model 0.7431192660550459 random_state 1449\n",
      "accuracy of the model 0.7522935779816514 random_state 1450\n",
      "accuracy of the model 0.6972477064220184 random_state 1451\n",
      "accuracy of the model 0.7889908256880734 random_state 1452\n",
      "accuracy of the model 0.7706422018348624 random_state 1453\n",
      "accuracy of the model 0.7431192660550459 random_state 1454\n",
      "accuracy of the model 0.7522935779816514 random_state 1455\n",
      "accuracy of the model 0.7614678899082569 random_state 1456\n",
      "accuracy of the model 0.7064220183486238 random_state 1457\n",
      "accuracy of the model 0.7522935779816514 random_state 1458\n",
      "accuracy of the model 0.7339449541284404 random_state 1459\n",
      "accuracy of the model 0.7339449541284404 random_state 1460\n",
      "accuracy of the model 0.7706422018348624 random_state 1461\n",
      "accuracy of the model 0.7522935779816514 random_state 1462\n",
      "accuracy of the model 0.6788990825688074 random_state 1463\n",
      "accuracy of the model 0.7064220183486238 random_state 1464\n",
      "accuracy of the model 0.7981651376146789 random_state 1465\n",
      "accuracy of the model 0.7889908256880734 random_state 1466\n",
      "accuracy of the model 0.6697247706422018 random_state 1467\n",
      "accuracy of the model 0.7339449541284404 random_state 1468\n",
      "accuracy of the model 0.7064220183486238 random_state 1469\n",
      "accuracy of the model 0.7889908256880734 random_state 1470\n",
      "accuracy of the model 0.7339449541284404 random_state 1471\n",
      "accuracy of the model 0.7155963302752294 random_state 1472\n",
      "accuracy of the model 0.7431192660550459 random_state 1473\n",
      "accuracy of the model 0.7614678899082569 random_state 1474\n",
      "accuracy of the model 0.7614678899082569 random_state 1475\n",
      "accuracy of the model 0.7247706422018348 random_state 1476\n",
      "accuracy of the model 0.7981651376146789 random_state 1477\n",
      "accuracy of the model 0.7339449541284404 random_state 1478\n",
      "accuracy of the model 0.7339449541284404 random_state 1479\n",
      "accuracy of the model 0.7706422018348624 random_state 1480\n",
      "accuracy of the model 0.7155963302752294 random_state 1481\n",
      "accuracy of the model 0.7706422018348624 random_state 1482\n",
      "accuracy of the model 0.7798165137614679 random_state 1483\n",
      "accuracy of the model 0.7064220183486238 random_state 1484\n",
      "accuracy of the model 0.7155963302752294 random_state 1485\n",
      "accuracy of the model 0.7431192660550459 random_state 1486\n",
      "accuracy of the model 0.7339449541284404 random_state 1487\n",
      "accuracy of the model 0.7247706422018348 random_state 1488\n",
      "accuracy of the model 0.7339449541284404 random_state 1489\n",
      "accuracy of the model 0.7522935779816514 random_state 1490\n",
      "accuracy of the model 0.7155963302752294 random_state 1491\n",
      "accuracy of the model 0.7247706422018348 random_state 1492\n",
      "accuracy of the model 0.6972477064220184 random_state 1493\n",
      "accuracy of the model 0.6788990825688074 random_state 1494\n",
      "accuracy of the model 0.7522935779816514 random_state 1495\n",
      "accuracy of the model 0.6972477064220184 random_state 1496\n",
      "accuracy of the model 0.7339449541284404 random_state 1497\n",
      "accuracy of the model 0.7889908256880734 random_state 1498\n",
      "accuracy of the model 0.7339449541284404 random_state 1499\n",
      "accuracy of the model 0.7247706422018348 random_state 1500\n",
      "accuracy of the model 0.7614678899082569 random_state 1501\n",
      "accuracy of the model 0.7339449541284404 random_state 1502\n",
      "accuracy of the model 0.7339449541284404 random_state 1503\n",
      "accuracy of the model 0.7339449541284404 random_state 1504\n",
      "accuracy of the model 0.7889908256880734 random_state 1505\n",
      "accuracy of the model 0.7339449541284404 random_state 1506\n",
      "accuracy of the model 0.7064220183486238 random_state 1507\n",
      "accuracy of the model 0.6697247706422018 random_state 1508\n",
      "accuracy of the model 0.6972477064220184 random_state 1509\n",
      "accuracy of the model 0.7614678899082569 random_state 1510\n",
      "accuracy of the model 0.7064220183486238 random_state 1511\n",
      "accuracy of the model 0.6972477064220184 random_state 1512\n",
      "accuracy of the model 0.6788990825688074 random_state 1513\n",
      "accuracy of the model 0.7155963302752294 random_state 1514\n",
      "accuracy of the model 0.7889908256880734 random_state 1515\n",
      "accuracy of the model 0.7431192660550459 random_state 1516\n",
      "accuracy of the model 0.7522935779816514 random_state 1517\n",
      "accuracy of the model 0.6880733944954128 random_state 1518\n",
      "accuracy of the model 0.7614678899082569 random_state 1519\n",
      "accuracy of the model 0.6605504587155964 random_state 1520\n",
      "accuracy of the model 0.6513761467889908 random_state 1521\n",
      "accuracy of the model 0.7614678899082569 random_state 1522\n",
      "accuracy of the model 0.7431192660550459 random_state 1523\n",
      "accuracy of the model 0.7247706422018348 random_state 1524\n",
      "accuracy of the model 0.7155963302752294 random_state 1525\n",
      "accuracy of the model 0.6422018348623854 random_state 1526\n",
      "accuracy of the model 0.7431192660550459 random_state 1527\n",
      "accuracy of the model 0.7064220183486238 random_state 1528\n",
      "accuracy of the model 0.7431192660550459 random_state 1529\n",
      "accuracy of the model 0.7614678899082569 random_state 1530\n",
      "accuracy of the model 0.7614678899082569 random_state 1531\n",
      "accuracy of the model 0.7339449541284404 random_state 1532\n",
      "accuracy of the model 0.7522935779816514 random_state 1533\n",
      "accuracy of the model 0.6330275229357798 random_state 1534\n",
      "accuracy of the model 0.7339449541284404 random_state 1535\n",
      "accuracy of the model 0.7431192660550459 random_state 1536\n",
      "accuracy of the model 0.6972477064220184 random_state 1537\n",
      "accuracy of the model 0.7614678899082569 random_state 1538\n",
      "accuracy of the model 0.6880733944954128 random_state 1539\n",
      "accuracy of the model 0.7155963302752294 random_state 1540\n",
      "accuracy of the model 0.7798165137614679 random_state 1541\n",
      "accuracy of the model 0.7155963302752294 random_state 1542\n",
      "accuracy of the model 0.7889908256880734 random_state 1543\n",
      "accuracy of the model 0.7339449541284404 random_state 1544\n",
      "accuracy of the model 0.7247706422018348 random_state 1545\n",
      "accuracy of the model 0.7522935779816514 random_state 1546\n",
      "accuracy of the model 0.7798165137614679 random_state 1547\n",
      "accuracy of the model 0.7064220183486238 random_state 1548\n",
      "accuracy of the model 0.7339449541284404 random_state 1549\n",
      "accuracy of the model 0.6972477064220184 random_state 1550\n",
      "accuracy of the model 0.7889908256880734 random_state 1551\n",
      "accuracy of the model 0.7798165137614679 random_state 1552\n",
      "accuracy of the model 0.7247706422018348 random_state 1553\n",
      "accuracy of the model 0.6972477064220184 random_state 1554\n",
      "accuracy of the model 0.6788990825688074 random_state 1555\n",
      "accuracy of the model 0.7431192660550459 random_state 1556\n",
      "accuracy of the model 0.7614678899082569 random_state 1557\n",
      "accuracy of the model 0.7614678899082569 random_state 1558\n",
      "accuracy of the model 0.7339449541284404 random_state 1559\n",
      "accuracy of the model 0.6880733944954128 random_state 1560\n",
      "accuracy of the model 0.7155963302752294 random_state 1561\n",
      "accuracy of the model 0.7064220183486238 random_state 1562\n",
      "accuracy of the model 0.7798165137614679 random_state 1563\n",
      "accuracy of the model 0.6972477064220184 random_state 1564\n",
      "accuracy of the model 0.7339449541284404 random_state 1565\n",
      "accuracy of the model 0.6972477064220184 random_state 1566\n",
      "accuracy of the model 0.7889908256880734 random_state 1567\n",
      "accuracy of the model 0.7522935779816514 random_state 1568\n",
      "accuracy of the model 0.6880733944954128 random_state 1569\n",
      "accuracy of the model 0.7889908256880734 random_state 1570\n",
      "accuracy of the model 0.6972477064220184 random_state 1571\n",
      "accuracy of the model 0.6788990825688074 random_state 1572\n",
      "accuracy of the model 0.7614678899082569 random_state 1573\n",
      "accuracy of the model 0.7339449541284404 random_state 1574\n",
      "accuracy of the model 0.7522935779816514 random_state 1575\n",
      "accuracy of the model 0.7339449541284404 random_state 1576\n",
      "accuracy of the model 0.7431192660550459 random_state 1577\n",
      "accuracy of the model 0.7064220183486238 random_state 1578\n",
      "accuracy of the model 0.7614678899082569 random_state 1579\n",
      "accuracy of the model 0.7614678899082569 random_state 1580\n",
      "accuracy of the model 0.7706422018348624 random_state 1581\n",
      "accuracy of the model 0.8073394495412844 random_state 1582\n",
      "accuracy of the model 0.7155963302752294 random_state 1583\n",
      "accuracy of the model 0.6880733944954128 random_state 1584\n",
      "accuracy of the model 0.6788990825688074 random_state 1585\n",
      "accuracy of the model 0.7431192660550459 random_state 1586\n",
      "accuracy of the model 0.7522935779816514 random_state 1587\n",
      "accuracy of the model 0.7155963302752294 random_state 1588\n",
      "accuracy of the model 0.7431192660550459 random_state 1589\n",
      "accuracy of the model 0.7431192660550459 random_state 1590\n",
      "accuracy of the model 0.7339449541284404 random_state 1591\n",
      "accuracy of the model 0.7155963302752294 random_state 1592\n",
      "accuracy of the model 0.7339449541284404 random_state 1593\n",
      "accuracy of the model 0.6880733944954128 random_state 1594\n",
      "accuracy of the model 0.7064220183486238 random_state 1595\n",
      "accuracy of the model 0.7522935779816514 random_state 1596\n",
      "accuracy of the model 0.6880733944954128 random_state 1597\n",
      "accuracy of the model 0.8256880733944955 random_state 1598\n",
      "accuracy of the model 0.7522935779816514 random_state 1599\n",
      "accuracy of the model 0.7522935779816514 random_state 1600\n",
      "accuracy of the model 0.7522935779816514 random_state 1601\n",
      "accuracy of the model 0.7522935779816514 random_state 1602\n",
      "accuracy of the model 0.8440366972477065 random_state 1603\n",
      "accuracy of the model 0.7339449541284404 random_state 1604\n",
      "accuracy of the model 0.7247706422018348 random_state 1605\n",
      "accuracy of the model 0.7706422018348624 random_state 1606\n",
      "accuracy of the model 0.6605504587155964 random_state 1607\n",
      "accuracy of the model 0.7339449541284404 random_state 1608\n",
      "accuracy of the model 0.7064220183486238 random_state 1609\n",
      "accuracy of the model 0.8073394495412844 random_state 1610\n",
      "accuracy of the model 0.6422018348623854 random_state 1611\n",
      "accuracy of the model 0.7339449541284404 random_state 1612\n",
      "accuracy of the model 0.7706422018348624 random_state 1613\n",
      "accuracy of the model 0.7064220183486238 random_state 1614\n",
      "accuracy of the model 0.7155963302752294 random_state 1615\n",
      "accuracy of the model 0.7247706422018348 random_state 1616\n",
      "accuracy of the model 0.7431192660550459 random_state 1617\n",
      "accuracy of the model 0.7431192660550459 random_state 1618\n",
      "accuracy of the model 0.7247706422018348 random_state 1619\n",
      "accuracy of the model 0.7247706422018348 random_state 1620\n",
      "accuracy of the model 0.7522935779816514 random_state 1621\n",
      "accuracy of the model 0.7064220183486238 random_state 1622\n",
      "accuracy of the model 0.7981651376146789 random_state 1623\n",
      "accuracy of the model 0.7064220183486238 random_state 1624\n",
      "accuracy of the model 0.7798165137614679 random_state 1625\n",
      "accuracy of the model 0.7064220183486238 random_state 1626\n",
      "accuracy of the model 0.6788990825688074 random_state 1627\n",
      "accuracy of the model 0.6972477064220184 random_state 1628\n",
      "accuracy of the model 0.7339449541284404 random_state 1629\n",
      "accuracy of the model 0.7522935779816514 random_state 1630\n",
      "accuracy of the model 0.7522935779816514 random_state 1631\n",
      "accuracy of the model 0.7798165137614679 random_state 1632\n",
      "accuracy of the model 0.7339449541284404 random_state 1633\n",
      "accuracy of the model 0.7431192660550459 random_state 1634\n",
      "accuracy of the model 0.6972477064220184 random_state 1635\n",
      "accuracy of the model 0.7155963302752294 random_state 1636\n",
      "accuracy of the model 0.7247706422018348 random_state 1637\n",
      "accuracy of the model 0.7706422018348624 random_state 1638\n",
      "accuracy of the model 0.7431192660550459 random_state 1639\n",
      "accuracy of the model 0.6972477064220184 random_state 1640\n",
      "accuracy of the model 0.7706422018348624 random_state 1641\n",
      "accuracy of the model 0.7247706422018348 random_state 1642\n",
      "accuracy of the model 0.6788990825688074 random_state 1643\n",
      "accuracy of the model 0.7155963302752294 random_state 1644\n",
      "accuracy of the model 0.7155963302752294 random_state 1645\n",
      "accuracy of the model 0.7155963302752294 random_state 1646\n",
      "accuracy of the model 0.7431192660550459 random_state 1647\n",
      "accuracy of the model 0.7339449541284404 random_state 1648\n",
      "accuracy of the model 0.6788990825688074 random_state 1649\n",
      "accuracy of the model 0.7431192660550459 random_state 1650\n",
      "accuracy of the model 0.7155963302752294 random_state 1651\n",
      "accuracy of the model 0.6880733944954128 random_state 1652\n",
      "accuracy of the model 0.6788990825688074 random_state 1653\n",
      "accuracy of the model 0.7522935779816514 random_state 1654\n",
      "accuracy of the model 0.7064220183486238 random_state 1655\n",
      "accuracy of the model 0.6972477064220184 random_state 1656\n",
      "accuracy of the model 0.6880733944954128 random_state 1657\n",
      "accuracy of the model 0.8073394495412844 random_state 1658\n",
      "accuracy of the model 0.7981651376146789 random_state 1659\n",
      "accuracy of the model 0.7798165137614679 random_state 1660\n",
      "accuracy of the model 0.7614678899082569 random_state 1661\n",
      "accuracy of the model 0.7339449541284404 random_state 1662\n",
      "accuracy of the model 0.7431192660550459 random_state 1663\n",
      "accuracy of the model 0.7155963302752294 random_state 1664\n",
      "accuracy of the model 0.7431192660550459 random_state 1665\n",
      "accuracy of the model 0.7155963302752294 random_state 1666\n",
      "accuracy of the model 0.7798165137614679 random_state 1667\n",
      "accuracy of the model 0.7431192660550459 random_state 1668\n",
      "accuracy of the model 0.6697247706422018 random_state 1669\n",
      "accuracy of the model 0.7339449541284404 random_state 1670\n",
      "accuracy of the model 0.6788990825688074 random_state 1671\n",
      "accuracy of the model 0.7064220183486238 random_state 1672\n",
      "accuracy of the model 0.7247706422018348 random_state 1673\n",
      "accuracy of the model 0.7431192660550459 random_state 1674\n",
      "accuracy of the model 0.7339449541284404 random_state 1675\n",
      "accuracy of the model 0.7247706422018348 random_state 1676\n",
      "accuracy of the model 0.7522935779816514 random_state 1677\n",
      "accuracy of the model 0.6880733944954128 random_state 1678\n",
      "accuracy of the model 0.7431192660550459 random_state 1679\n",
      "accuracy of the model 0.7247706422018348 random_state 1680\n",
      "accuracy of the model 0.6788990825688074 random_state 1681\n",
      "accuracy of the model 0.7155963302752294 random_state 1682\n",
      "accuracy of the model 0.6605504587155964 random_state 1683\n",
      "accuracy of the model 0.7431192660550459 random_state 1684\n",
      "accuracy of the model 0.7706422018348624 random_state 1685\n",
      "accuracy of the model 0.7431192660550459 random_state 1686\n",
      "accuracy of the model 0.7247706422018348 random_state 1687\n",
      "accuracy of the model 0.7064220183486238 random_state 1688\n",
      "accuracy of the model 0.7247706422018348 random_state 1689\n",
      "accuracy of the model 0.7155963302752294 random_state 1690\n",
      "accuracy of the model 0.7431192660550459 random_state 1691\n",
      "accuracy of the model 0.6972477064220184 random_state 1692\n",
      "accuracy of the model 0.7155963302752294 random_state 1693\n",
      "accuracy of the model 0.7614678899082569 random_state 1694\n",
      "accuracy of the model 0.7155963302752294 random_state 1695\n",
      "accuracy of the model 0.7614678899082569 random_state 1696\n",
      "accuracy of the model 0.6880733944954128 random_state 1697\n",
      "accuracy of the model 0.7614678899082569 random_state 1698\n",
      "accuracy of the model 0.7614678899082569 random_state 1699\n",
      "accuracy of the model 0.7706422018348624 random_state 1700\n",
      "accuracy of the model 0.7155963302752294 random_state 1701\n",
      "accuracy of the model 0.7798165137614679 random_state 1702\n",
      "accuracy of the model 0.7431192660550459 random_state 1703\n",
      "accuracy of the model 0.7247706422018348 random_state 1704\n",
      "accuracy of the model 0.7798165137614679 random_state 1705\n",
      "accuracy of the model 0.7155963302752294 random_state 1706\n",
      "accuracy of the model 0.7064220183486238 random_state 1707\n",
      "accuracy of the model 0.7798165137614679 random_state 1708\n",
      "accuracy of the model 0.7798165137614679 random_state 1709\n",
      "accuracy of the model 0.6697247706422018 random_state 1710\n",
      "accuracy of the model 0.6605504587155964 random_state 1711\n",
      "accuracy of the model 0.7155963302752294 random_state 1712\n",
      "accuracy of the model 0.7431192660550459 random_state 1713\n",
      "accuracy of the model 0.7155963302752294 random_state 1714\n",
      "accuracy of the model 0.7614678899082569 random_state 1715\n",
      "accuracy of the model 0.7614678899082569 random_state 1716\n",
      "accuracy of the model 0.6238532110091743 random_state 1717\n",
      "accuracy of the model 0.6422018348623854 random_state 1718\n",
      "accuracy of the model 0.7614678899082569 random_state 1719\n",
      "accuracy of the model 0.7522935779816514 random_state 1720\n",
      "accuracy of the model 0.6330275229357798 random_state 1721\n",
      "accuracy of the model 0.7798165137614679 random_state 1722\n",
      "accuracy of the model 0.6880733944954128 random_state 1723\n",
      "accuracy of the model 0.7155963302752294 random_state 1724\n",
      "accuracy of the model 0.7706422018348624 random_state 1725\n",
      "accuracy of the model 0.7614678899082569 random_state 1726\n",
      "accuracy of the model 0.7064220183486238 random_state 1727\n",
      "accuracy of the model 0.6972477064220184 random_state 1728\n",
      "accuracy of the model 0.6697247706422018 random_state 1729\n",
      "accuracy of the model 0.7155963302752294 random_state 1730\n",
      "accuracy of the model 0.7614678899082569 random_state 1731\n",
      "accuracy of the model 0.7431192660550459 random_state 1732\n",
      "accuracy of the model 0.6605504587155964 random_state 1733\n",
      "accuracy of the model 0.8165137614678899 random_state 1734\n",
      "accuracy of the model 0.7064220183486238 random_state 1735\n",
      "accuracy of the model 0.6880733944954128 random_state 1736\n",
      "accuracy of the model 0.6972477064220184 random_state 1737\n",
      "accuracy of the model 0.7155963302752294 random_state 1738\n",
      "accuracy of the model 0.7339449541284404 random_state 1739\n",
      "accuracy of the model 0.7247706422018348 random_state 1740\n",
      "accuracy of the model 0.6788990825688074 random_state 1741\n",
      "accuracy of the model 0.7155963302752294 random_state 1742\n",
      "accuracy of the model 0.7247706422018348 random_state 1743\n",
      "accuracy of the model 0.7339449541284404 random_state 1744\n",
      "accuracy of the model 0.7064220183486238 random_state 1745\n",
      "accuracy of the model 0.7064220183486238 random_state 1746\n",
      "accuracy of the model 0.7247706422018348 random_state 1747\n",
      "accuracy of the model 0.7155963302752294 random_state 1748\n",
      "accuracy of the model 0.7431192660550459 random_state 1749\n",
      "accuracy of the model 0.7614678899082569 random_state 1750\n",
      "accuracy of the model 0.6880733944954128 random_state 1751\n",
      "accuracy of the model 0.6697247706422018 random_state 1752\n",
      "accuracy of the model 0.7431192660550459 random_state 1753\n",
      "accuracy of the model 0.7339449541284404 random_state 1754\n",
      "accuracy of the model 0.7064220183486238 random_state 1755\n",
      "accuracy of the model 0.7155963302752294 random_state 1756\n",
      "accuracy of the model 0.7981651376146789 random_state 1757\n",
      "accuracy of the model 0.7431192660550459 random_state 1758\n",
      "accuracy of the model 0.6605504587155964 random_state 1759\n",
      "accuracy of the model 0.7706422018348624 random_state 1760\n",
      "accuracy of the model 0.7339449541284404 random_state 1761\n",
      "accuracy of the model 0.7155963302752294 random_state 1762\n",
      "accuracy of the model 0.7614678899082569 random_state 1763\n",
      "accuracy of the model 0.7522935779816514 random_state 1764\n",
      "accuracy of the model 0.6788990825688074 random_state 1765\n",
      "accuracy of the model 0.6697247706422018 random_state 1766\n",
      "accuracy of the model 0.7614678899082569 random_state 1767\n",
      "accuracy of the model 0.7706422018348624 random_state 1768\n",
      "accuracy of the model 0.7064220183486238 random_state 1769\n",
      "accuracy of the model 0.7522935779816514 random_state 1770\n",
      "accuracy of the model 0.6880733944954128 random_state 1771\n",
      "accuracy of the model 0.6972477064220184 random_state 1772\n",
      "accuracy of the model 0.7339449541284404 random_state 1773\n",
      "accuracy of the model 0.7522935779816514 random_state 1774\n",
      "accuracy of the model 0.7798165137614679 random_state 1775\n",
      "accuracy of the model 0.7522935779816514 random_state 1776\n",
      "accuracy of the model 0.7981651376146789 random_state 1777\n",
      "accuracy of the model 0.6330275229357798 random_state 1778\n",
      "accuracy of the model 0.7706422018348624 random_state 1779\n",
      "accuracy of the model 0.7431192660550459 random_state 1780\n",
      "accuracy of the model 0.7339449541284404 random_state 1781\n",
      "accuracy of the model 0.7522935779816514 random_state 1782\n",
      "accuracy of the model 0.7155963302752294 random_state 1783\n",
      "accuracy of the model 0.7339449541284404 random_state 1784\n",
      "accuracy of the model 0.6972477064220184 random_state 1785\n",
      "accuracy of the model 0.7798165137614679 random_state 1786\n",
      "accuracy of the model 0.6972477064220184 random_state 1787\n",
      "accuracy of the model 0.7706422018348624 random_state 1788\n",
      "accuracy of the model 0.6422018348623854 random_state 1789\n",
      "accuracy of the model 0.7339449541284404 random_state 1790\n",
      "accuracy of the model 0.7431192660550459 random_state 1791\n",
      "accuracy of the model 0.7064220183486238 random_state 1792\n",
      "accuracy of the model 0.6880733944954128 random_state 1793\n",
      "accuracy of the model 0.6880733944954128 random_state 1794\n",
      "accuracy of the model 0.7247706422018348 random_state 1795\n",
      "accuracy of the model 0.7155963302752294 random_state 1796\n",
      "accuracy of the model 0.7339449541284404 random_state 1797\n",
      "accuracy of the model 0.7155963302752294 random_state 1798\n",
      "accuracy of the model 0.7155963302752294 random_state 1799\n",
      "accuracy of the model 0.7798165137614679 random_state 1800\n",
      "accuracy of the model 0.7889908256880734 random_state 1801\n",
      "accuracy of the model 0.6788990825688074 random_state 1802\n",
      "accuracy of the model 0.7981651376146789 random_state 1803\n",
      "accuracy of the model 0.7064220183486238 random_state 1804\n",
      "accuracy of the model 0.7522935779816514 random_state 1805\n",
      "accuracy of the model 0.7064220183486238 random_state 1806\n",
      "accuracy of the model 0.7155963302752294 random_state 1807\n",
      "accuracy of the model 0.7339449541284404 random_state 1808\n",
      "accuracy of the model 0.7614678899082569 random_state 1809\n",
      "accuracy of the model 0.7155963302752294 random_state 1810\n",
      "accuracy of the model 0.7522935779816514 random_state 1811\n",
      "accuracy of the model 0.7339449541284404 random_state 1812\n",
      "accuracy of the model 0.7155963302752294 random_state 1813\n",
      "accuracy of the model 0.7247706422018348 random_state 1814\n",
      "accuracy of the model 0.6697247706422018 random_state 1815\n",
      "accuracy of the model 0.6880733944954128 random_state 1816\n",
      "accuracy of the model 0.6788990825688074 random_state 1817\n",
      "accuracy of the model 0.7522935779816514 random_state 1818\n",
      "accuracy of the model 0.7155963302752294 random_state 1819\n",
      "accuracy of the model 0.7431192660550459 random_state 1820\n",
      "accuracy of the model 0.7155963302752294 random_state 1821\n",
      "accuracy of the model 0.7706422018348624 random_state 1822\n",
      "accuracy of the model 0.7431192660550459 random_state 1823\n",
      "accuracy of the model 0.7522935779816514 random_state 1824\n",
      "accuracy of the model 0.7247706422018348 random_state 1825\n",
      "accuracy of the model 0.7247706422018348 random_state 1826\n",
      "accuracy of the model 0.7339449541284404 random_state 1827\n",
      "accuracy of the model 0.7981651376146789 random_state 1828\n",
      "accuracy of the model 0.7798165137614679 random_state 1829\n",
      "accuracy of the model 0.7064220183486238 random_state 1830\n",
      "accuracy of the model 0.6330275229357798 random_state 1831\n",
      "accuracy of the model 0.7064220183486238 random_state 1832\n",
      "accuracy of the model 0.7706422018348624 random_state 1833\n",
      "accuracy of the model 0.6605504587155964 random_state 1834\n",
      "accuracy of the model 0.7522935779816514 random_state 1835\n",
      "accuracy of the model 0.7706422018348624 random_state 1836\n",
      "accuracy of the model 0.7339449541284404 random_state 1837\n",
      "accuracy of the model 0.7889908256880734 random_state 1838\n",
      "accuracy of the model 0.7431192660550459 random_state 1839\n",
      "accuracy of the model 0.7155963302752294 random_state 1840\n",
      "accuracy of the model 0.6513761467889908 random_state 1841\n",
      "accuracy of the model 0.7247706422018348 random_state 1842\n",
      "accuracy of the model 0.7155963302752294 random_state 1843\n",
      "accuracy of the model 0.7155963302752294 random_state 1844\n",
      "accuracy of the model 0.7614678899082569 random_state 1845\n",
      "accuracy of the model 0.6880733944954128 random_state 1846\n",
      "accuracy of the model 0.7706422018348624 random_state 1847\n",
      "accuracy of the model 0.7706422018348624 random_state 1848\n",
      "accuracy of the model 0.6972477064220184 random_state 1849\n",
      "accuracy of the model 0.7431192660550459 random_state 1850\n",
      "accuracy of the model 0.7247706422018348 random_state 1851\n",
      "accuracy of the model 0.7981651376146789 random_state 1852\n",
      "accuracy of the model 0.7431192660550459 random_state 1853\n",
      "accuracy of the model 0.7247706422018348 random_state 1854\n",
      "accuracy of the model 0.7155963302752294 random_state 1855\n",
      "accuracy of the model 0.7247706422018348 random_state 1856\n",
      "accuracy of the model 0.7339449541284404 random_state 1857\n",
      "accuracy of the model 0.7247706422018348 random_state 1858\n",
      "accuracy of the model 0.6972477064220184 random_state 1859\n",
      "accuracy of the model 0.7431192660550459 random_state 1860\n",
      "accuracy of the model 0.6697247706422018 random_state 1861\n",
      "accuracy of the model 0.7339449541284404 random_state 1862\n",
      "accuracy of the model 0.6972477064220184 random_state 1863\n",
      "accuracy of the model 0.7706422018348624 random_state 1864\n",
      "accuracy of the model 0.7339449541284404 random_state 1865\n",
      "accuracy of the model 0.7706422018348624 random_state 1866\n",
      "accuracy of the model 0.8073394495412844 random_state 1867\n",
      "accuracy of the model 0.7522935779816514 random_state 1868\n",
      "accuracy of the model 0.6788990825688074 random_state 1869\n",
      "accuracy of the model 0.7155963302752294 random_state 1870\n",
      "accuracy of the model 0.7522935779816514 random_state 1871\n",
      "accuracy of the model 0.7247706422018348 random_state 1872\n",
      "accuracy of the model 0.7339449541284404 random_state 1873\n",
      "accuracy of the model 0.8165137614678899 random_state 1874\n",
      "accuracy of the model 0.7247706422018348 random_state 1875\n",
      "accuracy of the model 0.6880733944954128 random_state 1876\n",
      "accuracy of the model 0.6972477064220184 random_state 1877\n",
      "accuracy of the model 0.7064220183486238 random_state 1878\n",
      "accuracy of the model 0.6972477064220184 random_state 1879\n",
      "accuracy of the model 0.7706422018348624 random_state 1880\n",
      "accuracy of the model 0.6880733944954128 random_state 1881\n",
      "accuracy of the model 0.6788990825688074 random_state 1882\n",
      "accuracy of the model 0.6972477064220184 random_state 1883\n",
      "accuracy of the model 0.7339449541284404 random_state 1884\n",
      "accuracy of the model 0.7247706422018348 random_state 1885\n",
      "accuracy of the model 0.7614678899082569 random_state 1886\n",
      "accuracy of the model 0.6422018348623854 random_state 1887\n",
      "accuracy of the model 0.7889908256880734 random_state 1888\n",
      "accuracy of the model 0.7614678899082569 random_state 1889\n",
      "accuracy of the model 0.6513761467889908 random_state 1890\n",
      "accuracy of the model 0.7339449541284404 random_state 1891\n",
      "accuracy of the model 0.7431192660550459 random_state 1892\n",
      "accuracy of the model 0.6972477064220184 random_state 1893\n",
      "accuracy of the model 0.7155963302752294 random_state 1894\n",
      "accuracy of the model 0.7247706422018348 random_state 1895\n",
      "accuracy of the model 0.7889908256880734 random_state 1896\n",
      "accuracy of the model 0.6605504587155964 random_state 1897\n",
      "accuracy of the model 0.7431192660550459 random_state 1898\n",
      "accuracy of the model 0.7889908256880734 random_state 1899\n",
      "accuracy of the model 0.7614678899082569 random_state 1900\n",
      "accuracy of the model 0.6422018348623854 random_state 1901\n",
      "accuracy of the model 0.7247706422018348 random_state 1902\n",
      "accuracy of the model 0.7889908256880734 random_state 1903\n",
      "accuracy of the model 0.6697247706422018 random_state 1904\n",
      "accuracy of the model 0.7155963302752294 random_state 1905\n",
      "accuracy of the model 0.7981651376146789 random_state 1906\n",
      "accuracy of the model 0.7064220183486238 random_state 1907\n",
      "accuracy of the model 0.7431192660550459 random_state 1908\n",
      "accuracy of the model 0.7247706422018348 random_state 1909\n",
      "accuracy of the model 0.6697247706422018 random_state 1910\n",
      "accuracy of the model 0.7339449541284404 random_state 1911\n",
      "accuracy of the model 0.7155963302752294 random_state 1912\n",
      "accuracy of the model 0.6697247706422018 random_state 1913\n",
      "accuracy of the model 0.7981651376146789 random_state 1914\n",
      "accuracy of the model 0.6697247706422018 random_state 1915\n",
      "accuracy of the model 0.6972477064220184 random_state 1916\n",
      "accuracy of the model 0.7155963302752294 random_state 1917\n",
      "accuracy of the model 0.7155963302752294 random_state 1918\n",
      "accuracy of the model 0.7614678899082569 random_state 1919\n",
      "accuracy of the model 0.6880733944954128 random_state 1920\n",
      "accuracy of the model 0.6513761467889908 random_state 1921\n",
      "accuracy of the model 0.7155963302752294 random_state 1922\n",
      "accuracy of the model 0.7706422018348624 random_state 1923\n",
      "accuracy of the model 0.7155963302752294 random_state 1924\n",
      "accuracy of the model 0.7614678899082569 random_state 1925\n",
      "accuracy of the model 0.7064220183486238 random_state 1926\n",
      "accuracy of the model 0.7614678899082569 random_state 1927\n",
      "accuracy of the model 0.6788990825688074 random_state 1928\n",
      "accuracy of the model 0.7339449541284404 random_state 1929\n",
      "accuracy of the model 0.7431192660550459 random_state 1930\n",
      "accuracy of the model 0.7798165137614679 random_state 1931\n",
      "accuracy of the model 0.7614678899082569 random_state 1932\n",
      "accuracy of the model 0.7522935779816514 random_state 1933\n",
      "accuracy of the model 0.6697247706422018 random_state 1934\n",
      "accuracy of the model 0.8256880733944955 random_state 1935\n",
      "accuracy of the model 0.7339449541284404 random_state 1936\n",
      "accuracy of the model 0.7339449541284404 random_state 1937\n",
      "accuracy of the model 0.7247706422018348 random_state 1938\n",
      "accuracy of the model 0.7706422018348624 random_state 1939\n",
      "accuracy of the model 0.7339449541284404 random_state 1940\n",
      "accuracy of the model 0.7155963302752294 random_state 1941\n",
      "accuracy of the model 0.7706422018348624 random_state 1942\n",
      "accuracy of the model 0.7064220183486238 random_state 1943\n",
      "accuracy of the model 0.6697247706422018 random_state 1944\n",
      "accuracy of the model 0.7706422018348624 random_state 1945\n",
      "accuracy of the model 0.7431192660550459 random_state 1946\n",
      "accuracy of the model 0.7339449541284404 random_state 1947\n",
      "accuracy of the model 0.7155963302752294 random_state 1948\n",
      "accuracy of the model 0.7339449541284404 random_state 1949\n",
      "accuracy of the model 0.7064220183486238 random_state 1950\n",
      "accuracy of the model 0.7339449541284404 random_state 1951\n",
      "accuracy of the model 0.7522935779816514 random_state 1952\n",
      "accuracy of the model 0.7522935779816514 random_state 1953\n",
      "accuracy of the model 0.7431192660550459 random_state 1954\n",
      "accuracy of the model 0.7614678899082569 random_state 1955\n",
      "accuracy of the model 0.7981651376146789 random_state 1956\n",
      "accuracy of the model 0.6972477064220184 random_state 1957\n",
      "accuracy of the model 0.7706422018348624 random_state 1958\n",
      "accuracy of the model 0.7706422018348624 random_state 1959\n",
      "accuracy of the model 0.7431192660550459 random_state 1960\n",
      "accuracy of the model 0.7614678899082569 random_state 1961\n",
      "accuracy of the model 0.6880733944954128 random_state 1962\n",
      "accuracy of the model 0.7889908256880734 random_state 1963\n",
      "accuracy of the model 0.7981651376146789 random_state 1964\n",
      "accuracy of the model 0.7798165137614679 random_state 1965\n",
      "accuracy of the model 0.7155963302752294 random_state 1966\n",
      "accuracy of the model 0.6880733944954128 random_state 1967\n",
      "accuracy of the model 0.7522935779816514 random_state 1968\n",
      "accuracy of the model 0.7522935779816514 random_state 1969\n",
      "accuracy of the model 0.7706422018348624 random_state 1970\n",
      "accuracy of the model 0.7247706422018348 random_state 1971\n",
      "accuracy of the model 0.6972477064220184 random_state 1972\n",
      "accuracy of the model 0.6605504587155964 random_state 1973\n",
      "accuracy of the model 0.6788990825688074 random_state 1974\n",
      "accuracy of the model 0.7064220183486238 random_state 1975\n",
      "accuracy of the model 0.6880733944954128 random_state 1976\n",
      "accuracy of the model 0.7339449541284404 random_state 1977\n",
      "accuracy of the model 0.7064220183486238 random_state 1978\n",
      "accuracy of the model 0.7798165137614679 random_state 1979\n",
      "accuracy of the model 0.6605504587155964 random_state 1980\n",
      "accuracy of the model 0.7339449541284404 random_state 1981\n",
      "accuracy of the model 0.7155963302752294 random_state 1982\n",
      "accuracy of the model 0.7431192660550459 random_state 1983\n",
      "accuracy of the model 0.7798165137614679 random_state 1984\n",
      "accuracy of the model 0.7614678899082569 random_state 1985\n",
      "accuracy of the model 0.6972477064220184 random_state 1986\n",
      "accuracy of the model 0.7247706422018348 random_state 1987\n",
      "accuracy of the model 0.7522935779816514 random_state 1988\n",
      "accuracy of the model 0.7614678899082569 random_state 1989\n",
      "accuracy of the model 0.7706422018348624 random_state 1990\n",
      "accuracy of the model 0.7339449541284404 random_state 1991\n",
      "accuracy of the model 0.7706422018348624 random_state 1992\n",
      "accuracy of the model 0.6972477064220184 random_state 1993\n",
      "accuracy of the model 0.7798165137614679 random_state 1994\n",
      "accuracy of the model 0.7339449541284404 random_state 1995\n",
      "accuracy of the model 0.6880733944954128 random_state 1996\n",
      "accuracy of the model 0.7889908256880734 random_state 1997\n",
      "accuracy of the model 0.7706422018348624 random_state 1998\n",
      "accuracy of the model 0.6422018348623854 random_state 1999\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,2000):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    pred=lr.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "714545b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8623853211009175 in random state 494\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e9adf4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.6788990825688074 random_state 1\n",
      "accuracy of the optimum model 0.6788990825688074 random_state 1\n",
      "accuracy of the model 0.7522935779816514 random_state 2\n",
      "accuracy of the optimum model 0.7522935779816514 random_state 2\n",
      "accuracy of the model 0.6880733944954128 random_state 3\n",
      "accuracy of the model 0.6788990825688074 random_state 4\n",
      "accuracy of the model 0.6238532110091743 random_state 5\n",
      "accuracy of the model 0.7339449541284404 random_state 6\n",
      "accuracy of the model 0.7064220183486238 random_state 7\n",
      "accuracy of the model 0.7889908256880734 random_state 8\n",
      "accuracy of the optimum model 0.7889908256880734 random_state 8\n",
      "accuracy of the model 0.6788990825688074 random_state 9\n",
      "accuracy of the model 0.6422018348623854 random_state 10\n",
      "accuracy of the model 0.7614678899082569 random_state 11\n",
      "accuracy of the model 0.6880733944954128 random_state 12\n",
      "accuracy of the model 0.7064220183486238 random_state 13\n",
      "accuracy of the model 0.6055045871559633 random_state 14\n",
      "accuracy of the model 0.7155963302752294 random_state 15\n",
      "accuracy of the model 0.6880733944954128 random_state 16\n",
      "accuracy of the model 0.7247706422018348 random_state 17\n",
      "accuracy of the model 0.6605504587155964 random_state 18\n",
      "accuracy of the model 0.7155963302752294 random_state 19\n",
      "accuracy of the model 0.7706422018348624 random_state 20\n",
      "accuracy of the model 0.7614678899082569 random_state 21\n",
      "accuracy of the model 0.7522935779816514 random_state 22\n",
      "accuracy of the model 0.6330275229357798 random_state 23\n",
      "accuracy of the model 0.7155963302752294 random_state 24\n",
      "accuracy of the model 0.6788990825688074 random_state 25\n",
      "accuracy of the model 0.7155963302752294 random_state 26\n",
      "accuracy of the model 0.7339449541284404 random_state 27\n",
      "accuracy of the model 0.7155963302752294 random_state 28\n",
      "accuracy of the model 0.6788990825688074 random_state 29\n",
      "accuracy of the model 0.7431192660550459 random_state 30\n",
      "accuracy of the model 0.7339449541284404 random_state 31\n",
      "accuracy of the model 0.7614678899082569 random_state 32\n",
      "accuracy of the model 0.7247706422018348 random_state 33\n",
      "accuracy of the model 0.6972477064220184 random_state 34\n",
      "accuracy of the model 0.7064220183486238 random_state 35\n",
      "accuracy of the model 0.6697247706422018 random_state 36\n",
      "accuracy of the model 0.7247706422018348 random_state 37\n",
      "accuracy of the model 0.7155963302752294 random_state 38\n",
      "accuracy of the model 0.6422018348623854 random_state 39\n",
      "accuracy of the model 0.6330275229357798 random_state 40\n",
      "accuracy of the model 0.7706422018348624 random_state 41\n",
      "accuracy of the model 0.7522935779816514 random_state 42\n",
      "accuracy of the model 0.7798165137614679 random_state 43\n",
      "accuracy of the model 0.6422018348623854 random_state 44\n",
      "accuracy of the model 0.7064220183486238 random_state 45\n",
      "accuracy of the model 0.6972477064220184 random_state 46\n",
      "accuracy of the model 0.6605504587155964 random_state 47\n",
      "accuracy of the model 0.6513761467889908 random_state 48\n",
      "accuracy of the model 0.7064220183486238 random_state 49\n",
      "accuracy of the model 0.6697247706422018 random_state 50\n",
      "accuracy of the model 0.7155963302752294 random_state 51\n",
      "accuracy of the model 0.6788990825688074 random_state 52\n",
      "accuracy of the model 0.7431192660550459 random_state 53\n",
      "accuracy of the model 0.7247706422018348 random_state 54\n",
      "accuracy of the model 0.7614678899082569 random_state 55\n",
      "accuracy of the model 0.7339449541284404 random_state 56\n",
      "accuracy of the model 0.6972477064220184 random_state 57\n",
      "accuracy of the model 0.7339449541284404 random_state 58\n",
      "accuracy of the model 0.6972477064220184 random_state 59\n",
      "accuracy of the model 0.7522935779816514 random_state 60\n",
      "accuracy of the model 0.7339449541284404 random_state 61\n",
      "accuracy of the model 0.7247706422018348 random_state 62\n",
      "accuracy of the model 0.6605504587155964 random_state 63\n",
      "accuracy of the model 0.7889908256880734 random_state 64\n",
      "accuracy of the model 0.7431192660550459 random_state 65\n",
      "accuracy of the model 0.6972477064220184 random_state 66\n",
      "accuracy of the model 0.6788990825688074 random_state 67\n",
      "accuracy of the model 0.7247706422018348 random_state 68\n",
      "accuracy of the model 0.7155963302752294 random_state 69\n",
      "accuracy of the model 0.7798165137614679 random_state 70\n",
      "accuracy of the model 0.7798165137614679 random_state 71\n",
      "accuracy of the model 0.6513761467889908 random_state 72\n",
      "accuracy of the model 0.6697247706422018 random_state 73\n",
      "accuracy of the model 0.6788990825688074 random_state 74\n",
      "accuracy of the model 0.6513761467889908 random_state 75\n",
      "accuracy of the model 0.7431192660550459 random_state 76\n",
      "accuracy of the model 0.7155963302752294 random_state 77\n",
      "accuracy of the model 0.6972477064220184 random_state 78\n",
      "accuracy of the model 0.6605504587155964 random_state 79\n",
      "accuracy of the model 0.6513761467889908 random_state 80\n",
      "accuracy of the model 0.7522935779816514 random_state 81\n",
      "accuracy of the model 0.7155963302752294 random_state 82\n",
      "accuracy of the model 0.6880733944954128 random_state 83\n",
      "accuracy of the model 0.7522935779816514 random_state 84\n",
      "accuracy of the model 0.7155963302752294 random_state 85\n",
      "accuracy of the model 0.6513761467889908 random_state 86\n",
      "accuracy of the model 0.7155963302752294 random_state 87\n",
      "accuracy of the model 0.7339449541284404 random_state 88\n",
      "accuracy of the model 0.6513761467889908 random_state 89\n",
      "accuracy of the model 0.7247706422018348 random_state 90\n",
      "accuracy of the model 0.7431192660550459 random_state 91\n",
      "accuracy of the model 0.6880733944954128 random_state 92\n",
      "accuracy of the model 0.7522935779816514 random_state 93\n",
      "accuracy of the model 0.7064220183486238 random_state 94\n",
      "accuracy of the model 0.7798165137614679 random_state 95\n",
      "accuracy of the model 0.6788990825688074 random_state 96\n",
      "accuracy of the model 0.6880733944954128 random_state 97\n",
      "accuracy of the model 0.6788990825688074 random_state 98\n",
      "accuracy of the model 0.6972477064220184 random_state 99\n",
      "accuracy of the model 0.6697247706422018 random_state 100\n",
      "accuracy of the model 0.7339449541284404 random_state 101\n",
      "accuracy of the model 0.7339449541284404 random_state 102\n",
      "accuracy of the model 0.6972477064220184 random_state 103\n",
      "accuracy of the model 0.7247706422018348 random_state 104\n",
      "accuracy of the model 0.7431192660550459 random_state 105\n",
      "accuracy of the model 0.7522935779816514 random_state 106\n",
      "accuracy of the model 0.6972477064220184 random_state 107\n",
      "accuracy of the model 0.7339449541284404 random_state 108\n",
      "accuracy of the model 0.7431192660550459 random_state 109\n",
      "accuracy of the model 0.7522935779816514 random_state 110\n",
      "accuracy of the model 0.7522935779816514 random_state 111\n",
      "accuracy of the model 0.6055045871559633 random_state 112\n",
      "accuracy of the model 0.7064220183486238 random_state 113\n",
      "accuracy of the model 0.6788990825688074 random_state 114\n",
      "accuracy of the model 0.7155963302752294 random_state 115\n",
      "accuracy of the model 0.7339449541284404 random_state 116\n",
      "accuracy of the model 0.6238532110091743 random_state 117\n",
      "accuracy of the model 0.6972477064220184 random_state 118\n",
      "accuracy of the model 0.6788990825688074 random_state 119\n",
      "accuracy of the model 0.7522935779816514 random_state 120\n",
      "accuracy of the model 0.6788990825688074 random_state 121\n",
      "accuracy of the model 0.7522935779816514 random_state 122\n",
      "accuracy of the model 0.7247706422018348 random_state 123\n",
      "accuracy of the model 0.7339449541284404 random_state 124\n",
      "accuracy of the model 0.6972477064220184 random_state 125\n",
      "accuracy of the model 0.7339449541284404 random_state 126\n",
      "accuracy of the model 0.6880733944954128 random_state 127\n",
      "accuracy of the model 0.7981651376146789 random_state 128\n",
      "accuracy of the optimum model 0.7981651376146789 random_state 128\n",
      "accuracy of the model 0.6880733944954128 random_state 129\n",
      "accuracy of the model 0.6972477064220184 random_state 130\n",
      "accuracy of the model 0.7247706422018348 random_state 131\n",
      "accuracy of the model 0.6697247706422018 random_state 132\n",
      "accuracy of the model 0.6697247706422018 random_state 133\n",
      "accuracy of the model 0.7247706422018348 random_state 134\n",
      "accuracy of the model 0.6880733944954128 random_state 135\n",
      "accuracy of the model 0.7064220183486238 random_state 136\n",
      "accuracy of the model 0.6146788990825688 random_state 137\n",
      "accuracy of the model 0.7064220183486238 random_state 138\n",
      "accuracy of the model 0.7614678899082569 random_state 139\n",
      "accuracy of the model 0.7155963302752294 random_state 140\n",
      "accuracy of the model 0.7339449541284404 random_state 141\n",
      "accuracy of the model 0.6972477064220184 random_state 142\n",
      "accuracy of the model 0.7155963302752294 random_state 143\n",
      "accuracy of the model 0.7522935779816514 random_state 144\n",
      "accuracy of the model 0.7431192660550459 random_state 145\n",
      "accuracy of the model 0.5963302752293578 random_state 146\n",
      "accuracy of the model 0.7064220183486238 random_state 147\n",
      "accuracy of the model 0.7155963302752294 random_state 148\n",
      "accuracy of the model 0.7064220183486238 random_state 149\n",
      "accuracy of the model 0.6788990825688074 random_state 150\n",
      "accuracy of the model 0.7064220183486238 random_state 151\n",
      "accuracy of the model 0.6972477064220184 random_state 152\n",
      "accuracy of the model 0.6972477064220184 random_state 153\n",
      "accuracy of the model 0.7247706422018348 random_state 154\n",
      "accuracy of the model 0.7431192660550459 random_state 155\n",
      "accuracy of the model 0.7064220183486238 random_state 156\n",
      "accuracy of the model 0.7522935779816514 random_state 157\n",
      "accuracy of the model 0.7155963302752294 random_state 158\n",
      "accuracy of the model 0.6697247706422018 random_state 159\n",
      "accuracy of the model 0.6880733944954128 random_state 160\n",
      "accuracy of the model 0.7889908256880734 random_state 161\n",
      "accuracy of the model 0.6972477064220184 random_state 162\n",
      "accuracy of the model 0.7155963302752294 random_state 163\n",
      "accuracy of the model 0.6330275229357798 random_state 164\n",
      "accuracy of the model 0.6605504587155964 random_state 165\n",
      "accuracy of the model 0.7614678899082569 random_state 166\n",
      "accuracy of the model 0.6697247706422018 random_state 167\n",
      "accuracy of the model 0.7431192660550459 random_state 168\n",
      "accuracy of the model 0.6605504587155964 random_state 169\n",
      "accuracy of the model 0.6330275229357798 random_state 170\n",
      "accuracy of the model 0.7155963302752294 random_state 171\n",
      "accuracy of the model 0.7064220183486238 random_state 172\n",
      "accuracy of the model 0.7339449541284404 random_state 173\n",
      "accuracy of the model 0.6972477064220184 random_state 174\n",
      "accuracy of the model 0.7247706422018348 random_state 175\n",
      "accuracy of the model 0.6788990825688074 random_state 176\n",
      "accuracy of the model 0.7522935779816514 random_state 177\n",
      "accuracy of the model 0.7522935779816514 random_state 178\n",
      "accuracy of the model 0.7247706422018348 random_state 179\n",
      "accuracy of the model 0.7339449541284404 random_state 180\n",
      "accuracy of the model 0.6880733944954128 random_state 181\n",
      "accuracy of the model 0.6605504587155964 random_state 182\n",
      "accuracy of the model 0.7522935779816514 random_state 183\n",
      "accuracy of the model 0.7339449541284404 random_state 184\n",
      "accuracy of the model 0.7155963302752294 random_state 185\n",
      "accuracy of the model 0.6972477064220184 random_state 186\n",
      "accuracy of the model 0.7247706422018348 random_state 187\n",
      "accuracy of the model 0.7431192660550459 random_state 188\n",
      "accuracy of the model 0.6972477064220184 random_state 189\n",
      "accuracy of the model 0.7431192660550459 random_state 190\n",
      "accuracy of the model 0.7339449541284404 random_state 191\n",
      "accuracy of the model 0.7522935779816514 random_state 192\n",
      "accuracy of the model 0.6972477064220184 random_state 193\n",
      "accuracy of the model 0.6880733944954128 random_state 194\n",
      "accuracy of the model 0.7064220183486238 random_state 195\n",
      "accuracy of the model 0.7339449541284404 random_state 196\n",
      "accuracy of the model 0.7155963302752294 random_state 197\n",
      "accuracy of the model 0.6146788990825688 random_state 198\n",
      "accuracy of the model 0.6422018348623854 random_state 199\n",
      "accuracy of the model 0.7339449541284404 random_state 200\n",
      "accuracy of the model 0.6972477064220184 random_state 201\n",
      "accuracy of the model 0.7247706422018348 random_state 202\n",
      "accuracy of the model 0.7889908256880734 random_state 203\n",
      "accuracy of the model 0.7431192660550459 random_state 204\n",
      "accuracy of the model 0.7064220183486238 random_state 205\n",
      "accuracy of the model 0.6880733944954128 random_state 206\n",
      "accuracy of the model 0.6972477064220184 random_state 207\n",
      "accuracy of the model 0.6422018348623854 random_state 208\n",
      "accuracy of the model 0.7798165137614679 random_state 209\n",
      "accuracy of the model 0.6880733944954128 random_state 210\n",
      "accuracy of the model 0.6788990825688074 random_state 211\n",
      "accuracy of the model 0.7614678899082569 random_state 212\n",
      "accuracy of the model 0.7064220183486238 random_state 213\n",
      "accuracy of the model 0.7064220183486238 random_state 214\n",
      "accuracy of the model 0.7798165137614679 random_state 215\n",
      "accuracy of the model 0.6880733944954128 random_state 216\n",
      "accuracy of the model 0.7522935779816514 random_state 217\n",
      "accuracy of the model 0.7614678899082569 random_state 218\n",
      "accuracy of the model 0.6605504587155964 random_state 219\n",
      "accuracy of the model 0.6972477064220184 random_state 220\n",
      "accuracy of the model 0.7339449541284404 random_state 221\n",
      "accuracy of the model 0.6697247706422018 random_state 222\n",
      "accuracy of the model 0.6972477064220184 random_state 223\n",
      "accuracy of the model 0.8165137614678899 random_state 224\n",
      "accuracy of the optimum model 0.8165137614678899 random_state 224\n",
      "accuracy of the model 0.7155963302752294 random_state 225\n",
      "accuracy of the model 0.7522935779816514 random_state 226\n",
      "accuracy of the model 0.7064220183486238 random_state 227\n",
      "accuracy of the model 0.6972477064220184 random_state 228\n",
      "accuracy of the model 0.7889908256880734 random_state 229\n",
      "accuracy of the model 0.6605504587155964 random_state 230\n",
      "accuracy of the model 0.6972477064220184 random_state 231\n",
      "accuracy of the model 0.7064220183486238 random_state 232\n",
      "accuracy of the model 0.6697247706422018 random_state 233\n",
      "accuracy of the model 0.7339449541284404 random_state 234\n",
      "accuracy of the model 0.7339449541284404 random_state 235\n",
      "accuracy of the model 0.7247706422018348 random_state 236\n",
      "accuracy of the model 0.7706422018348624 random_state 237\n",
      "accuracy of the model 0.6788990825688074 random_state 238\n",
      "accuracy of the model 0.6513761467889908 random_state 239\n",
      "accuracy of the model 0.7247706422018348 random_state 240\n",
      "accuracy of the model 0.7614678899082569 random_state 241\n",
      "accuracy of the model 0.6605504587155964 random_state 242\n",
      "accuracy of the model 0.7064220183486238 random_state 243\n",
      "accuracy of the model 0.6880733944954128 random_state 244\n",
      "accuracy of the model 0.6972477064220184 random_state 245\n",
      "accuracy of the model 0.6972477064220184 random_state 246\n",
      "accuracy of the model 0.6880733944954128 random_state 247\n",
      "accuracy of the model 0.7339449541284404 random_state 248\n",
      "accuracy of the model 0.6697247706422018 random_state 249\n",
      "accuracy of the model 0.7431192660550459 random_state 250\n",
      "accuracy of the model 0.7247706422018348 random_state 251\n",
      "accuracy of the model 0.6880733944954128 random_state 252\n",
      "accuracy of the model 0.7522935779816514 random_state 253\n",
      "accuracy of the model 0.7522935779816514 random_state 254\n",
      "accuracy of the model 0.6422018348623854 random_state 255\n",
      "accuracy of the model 0.7614678899082569 random_state 256\n",
      "accuracy of the model 0.6238532110091743 random_state 257\n",
      "accuracy of the model 0.7247706422018348 random_state 258\n",
      "accuracy of the model 0.6972477064220184 random_state 259\n",
      "accuracy of the model 0.7064220183486238 random_state 260\n",
      "accuracy of the model 0.7431192660550459 random_state 261\n",
      "accuracy of the model 0.7247706422018348 random_state 262\n",
      "accuracy of the model 0.6972477064220184 random_state 263\n",
      "accuracy of the model 0.7339449541284404 random_state 264\n",
      "accuracy of the model 0.6880733944954128 random_state 265\n",
      "accuracy of the model 0.7339449541284404 random_state 266\n",
      "accuracy of the model 0.6788990825688074 random_state 267\n",
      "accuracy of the model 0.6972477064220184 random_state 268\n",
      "accuracy of the model 0.7247706422018348 random_state 269\n",
      "accuracy of the model 0.7522935779816514 random_state 270\n",
      "accuracy of the model 0.7981651376146789 random_state 271\n",
      "accuracy of the model 0.6697247706422018 random_state 272\n",
      "accuracy of the model 0.6697247706422018 random_state 273\n",
      "accuracy of the model 0.6788990825688074 random_state 274\n",
      "accuracy of the model 0.7155963302752294 random_state 275\n",
      "accuracy of the model 0.7247706422018348 random_state 276\n",
      "accuracy of the model 0.7614678899082569 random_state 277\n",
      "accuracy of the model 0.7155963302752294 random_state 278\n",
      "accuracy of the model 0.6972477064220184 random_state 279\n",
      "accuracy of the model 0.7064220183486238 random_state 280\n",
      "accuracy of the model 0.6513761467889908 random_state 281\n",
      "accuracy of the model 0.7247706422018348 random_state 282\n",
      "accuracy of the model 0.6972477064220184 random_state 283\n",
      "accuracy of the model 0.6972477064220184 random_state 284\n",
      "accuracy of the model 0.7155963302752294 random_state 285\n",
      "accuracy of the model 0.7339449541284404 random_state 286\n",
      "accuracy of the model 0.6788990825688074 random_state 287\n",
      "accuracy of the model 0.6788990825688074 random_state 288\n",
      "accuracy of the model 0.7064220183486238 random_state 289\n",
      "accuracy of the model 0.6972477064220184 random_state 290\n",
      "accuracy of the model 0.7339449541284404 random_state 291\n",
      "accuracy of the model 0.6880733944954128 random_state 292\n",
      "accuracy of the model 0.7431192660550459 random_state 293\n",
      "accuracy of the model 0.6788990825688074 random_state 294\n",
      "accuracy of the model 0.6880733944954128 random_state 295\n",
      "accuracy of the model 0.7247706422018348 random_state 296\n",
      "accuracy of the model 0.7064220183486238 random_state 297\n",
      "accuracy of the model 0.6422018348623854 random_state 298\n",
      "accuracy of the model 0.6880733944954128 random_state 299\n",
      "accuracy of the model 0.7614678899082569 random_state 300\n",
      "accuracy of the model 0.6788990825688074 random_state 301\n",
      "accuracy of the model 0.6513761467889908 random_state 302\n",
      "accuracy of the model 0.7706422018348624 random_state 303\n",
      "accuracy of the model 0.7431192660550459 random_state 304\n",
      "accuracy of the model 0.7522935779816514 random_state 305\n",
      "accuracy of the model 0.7155963302752294 random_state 306\n",
      "accuracy of the model 0.6788990825688074 random_state 307\n",
      "accuracy of the model 0.6972477064220184 random_state 308\n",
      "accuracy of the model 0.7064220183486238 random_state 309\n",
      "accuracy of the model 0.7247706422018348 random_state 310\n",
      "accuracy of the model 0.7614678899082569 random_state 311\n",
      "accuracy of the model 0.6605504587155964 random_state 312\n",
      "accuracy of the model 0.6880733944954128 random_state 313\n",
      "accuracy of the model 0.7339449541284404 random_state 314\n",
      "accuracy of the model 0.7155963302752294 random_state 315\n",
      "accuracy of the model 0.6880733944954128 random_state 316\n",
      "accuracy of the model 0.6513761467889908 random_state 317\n",
      "accuracy of the model 0.6697247706422018 random_state 318\n",
      "accuracy of the model 0.6330275229357798 random_state 319\n",
      "accuracy of the model 0.7339449541284404 random_state 320\n",
      "accuracy of the model 0.7339449541284404 random_state 321\n",
      "accuracy of the model 0.7798165137614679 random_state 322\n",
      "accuracy of the model 0.7064220183486238 random_state 323\n",
      "accuracy of the model 0.6697247706422018 random_state 324\n",
      "accuracy of the model 0.7431192660550459 random_state 325\n",
      "accuracy of the model 0.6788990825688074 random_state 326\n",
      "accuracy of the model 0.6697247706422018 random_state 327\n",
      "accuracy of the model 0.7798165137614679 random_state 328\n",
      "accuracy of the model 0.7064220183486238 random_state 329\n",
      "accuracy of the model 0.7339449541284404 random_state 330\n",
      "accuracy of the model 0.7339449541284404 random_state 331\n",
      "accuracy of the model 0.6880733944954128 random_state 332\n",
      "accuracy of the model 0.7064220183486238 random_state 333\n",
      "accuracy of the model 0.7522935779816514 random_state 334\n",
      "accuracy of the model 0.6972477064220184 random_state 335\n",
      "accuracy of the model 0.7522935779816514 random_state 336\n",
      "accuracy of the model 0.7339449541284404 random_state 337\n",
      "accuracy of the model 0.7431192660550459 random_state 338\n",
      "accuracy of the model 0.6880733944954128 random_state 339\n",
      "accuracy of the model 0.7431192660550459 random_state 340\n",
      "accuracy of the model 0.7247706422018348 random_state 341\n",
      "accuracy of the model 0.6422018348623854 random_state 342\n",
      "accuracy of the model 0.7155963302752294 random_state 343\n",
      "accuracy of the model 0.6880733944954128 random_state 344\n",
      "accuracy of the model 0.7155963302752294 random_state 345\n",
      "accuracy of the model 0.7798165137614679 random_state 346\n",
      "accuracy of the model 0.7155963302752294 random_state 347\n",
      "accuracy of the model 0.6972477064220184 random_state 348\n",
      "accuracy of the model 0.6972477064220184 random_state 349\n",
      "accuracy of the model 0.6513761467889908 random_state 350\n",
      "accuracy of the model 0.7889908256880734 random_state 351\n",
      "accuracy of the model 0.7247706422018348 random_state 352\n",
      "accuracy of the model 0.6697247706422018 random_state 353\n",
      "accuracy of the model 0.7064220183486238 random_state 354\n",
      "accuracy of the model 0.7431192660550459 random_state 355\n",
      "accuracy of the model 0.7064220183486238 random_state 356\n",
      "accuracy of the model 0.7431192660550459 random_state 357\n",
      "accuracy of the model 0.7522935779816514 random_state 358\n",
      "accuracy of the model 0.6972477064220184 random_state 359\n",
      "accuracy of the model 0.6697247706422018 random_state 360\n",
      "accuracy of the model 0.6880733944954128 random_state 361\n",
      "accuracy of the model 0.6697247706422018 random_state 362\n",
      "accuracy of the model 0.6880733944954128 random_state 363\n",
      "accuracy of the model 0.7064220183486238 random_state 364\n",
      "accuracy of the model 0.7522935779816514 random_state 365\n",
      "accuracy of the model 0.6788990825688074 random_state 366\n",
      "accuracy of the model 0.7339449541284404 random_state 367\n",
      "accuracy of the model 0.7706422018348624 random_state 368\n",
      "accuracy of the model 0.7064220183486238 random_state 369\n",
      "accuracy of the model 0.7155963302752294 random_state 370\n",
      "accuracy of the model 0.6330275229357798 random_state 371\n",
      "accuracy of the model 0.7431192660550459 random_state 372\n",
      "accuracy of the model 0.7339449541284404 random_state 373\n",
      "accuracy of the model 0.6972477064220184 random_state 374\n",
      "accuracy of the model 0.7706422018348624 random_state 375\n",
      "accuracy of the model 0.7247706422018348 random_state 376\n",
      "accuracy of the model 0.7431192660550459 random_state 377\n",
      "accuracy of the model 0.6605504587155964 random_state 378\n",
      "accuracy of the model 0.7247706422018348 random_state 379\n",
      "accuracy of the model 0.7522935779816514 random_state 380\n",
      "accuracy of the model 0.7155963302752294 random_state 381\n",
      "accuracy of the model 0.7064220183486238 random_state 382\n",
      "accuracy of the model 0.6697247706422018 random_state 383\n",
      "accuracy of the model 0.6788990825688074 random_state 384\n",
      "accuracy of the model 0.6513761467889908 random_state 385\n",
      "accuracy of the model 0.7339449541284404 random_state 386\n",
      "accuracy of the model 0.7064220183486238 random_state 387\n",
      "accuracy of the model 0.6422018348623854 random_state 388\n",
      "accuracy of the model 0.7064220183486238 random_state 389\n",
      "accuracy of the model 0.7339449541284404 random_state 390\n",
      "accuracy of the model 0.7889908256880734 random_state 391\n",
      "accuracy of the model 0.6788990825688074 random_state 392\n",
      "accuracy of the model 0.7339449541284404 random_state 393\n",
      "accuracy of the model 0.6972477064220184 random_state 394\n",
      "accuracy of the model 0.6788990825688074 random_state 395\n",
      "accuracy of the model 0.7798165137614679 random_state 396\n",
      "accuracy of the model 0.6972477064220184 random_state 397\n",
      "accuracy of the model 0.7064220183486238 random_state 398\n",
      "accuracy of the model 0.6972477064220184 random_state 399\n",
      "accuracy of the model 0.7064220183486238 random_state 400\n",
      "accuracy of the model 0.6972477064220184 random_state 401\n",
      "accuracy of the model 0.7339449541284404 random_state 402\n",
      "accuracy of the model 0.6697247706422018 random_state 403\n",
      "accuracy of the model 0.6972477064220184 random_state 404\n",
      "accuracy of the model 0.6972477064220184 random_state 405\n",
      "accuracy of the model 0.7522935779816514 random_state 406\n",
      "accuracy of the model 0.7522935779816514 random_state 407\n",
      "accuracy of the model 0.6330275229357798 random_state 408\n",
      "accuracy of the model 0.6788990825688074 random_state 409\n",
      "accuracy of the model 0.6972477064220184 random_state 410\n",
      "accuracy of the model 0.7155963302752294 random_state 411\n",
      "accuracy of the model 0.7155963302752294 random_state 412\n",
      "accuracy of the model 0.6972477064220184 random_state 413\n",
      "accuracy of the model 0.6880733944954128 random_state 414\n",
      "accuracy of the model 0.7522935779816514 random_state 415\n",
      "accuracy of the model 0.7155963302752294 random_state 416\n",
      "accuracy of the model 0.7247706422018348 random_state 417\n",
      "accuracy of the model 0.7614678899082569 random_state 418\n",
      "accuracy of the model 0.6513761467889908 random_state 419\n",
      "accuracy of the model 0.7339449541284404 random_state 420\n",
      "accuracy of the model 0.6972477064220184 random_state 421\n",
      "accuracy of the model 0.7614678899082569 random_state 422\n",
      "accuracy of the model 0.7247706422018348 random_state 423\n",
      "accuracy of the model 0.7155963302752294 random_state 424\n",
      "accuracy of the model 0.7706422018348624 random_state 425\n",
      "accuracy of the model 0.5963302752293578 random_state 426\n",
      "accuracy of the model 0.7155963302752294 random_state 427\n",
      "accuracy of the model 0.6880733944954128 random_state 428\n",
      "accuracy of the model 0.7431192660550459 random_state 429\n",
      "accuracy of the model 0.6788990825688074 random_state 430\n",
      "accuracy of the model 0.7889908256880734 random_state 431\n",
      "accuracy of the model 0.7522935779816514 random_state 432\n",
      "accuracy of the model 0.6880733944954128 random_state 433\n",
      "accuracy of the model 0.6972477064220184 random_state 434\n",
      "accuracy of the model 0.7064220183486238 random_state 435\n",
      "accuracy of the model 0.6330275229357798 random_state 436\n",
      "accuracy of the model 0.7064220183486238 random_state 437\n",
      "accuracy of the model 0.6605504587155964 random_state 438\n",
      "accuracy of the model 0.6513761467889908 random_state 439\n",
      "accuracy of the model 0.7247706422018348 random_state 440\n",
      "accuracy of the model 0.7431192660550459 random_state 441\n",
      "accuracy of the model 0.7155963302752294 random_state 442\n",
      "accuracy of the model 0.6697247706422018 random_state 443\n",
      "accuracy of the model 0.6697247706422018 random_state 444\n",
      "accuracy of the model 0.6972477064220184 random_state 445\n",
      "accuracy of the model 0.6605504587155964 random_state 446\n",
      "accuracy of the model 0.7614678899082569 random_state 447\n",
      "accuracy of the model 0.7247706422018348 random_state 448\n",
      "accuracy of the model 0.6788990825688074 random_state 449\n",
      "accuracy of the model 0.7522935779816514 random_state 450\n",
      "accuracy of the model 0.6972477064220184 random_state 451\n",
      "accuracy of the model 0.6605504587155964 random_state 452\n",
      "accuracy of the model 0.8073394495412844 random_state 453\n",
      "accuracy of the model 0.7339449541284404 random_state 454\n",
      "accuracy of the model 0.6330275229357798 random_state 455\n",
      "accuracy of the model 0.7064220183486238 random_state 456\n",
      "accuracy of the model 0.5871559633027523 random_state 457\n",
      "accuracy of the model 0.6330275229357798 random_state 458\n",
      "accuracy of the model 0.6972477064220184 random_state 459\n",
      "accuracy of the model 0.7155963302752294 random_state 460\n",
      "accuracy of the model 0.7155963302752294 random_state 461\n",
      "accuracy of the model 0.6880733944954128 random_state 462\n",
      "accuracy of the model 0.6605504587155964 random_state 463\n",
      "accuracy of the model 0.7064220183486238 random_state 464\n",
      "accuracy of the model 0.7431192660550459 random_state 465\n",
      "accuracy of the model 0.6880733944954128 random_state 466\n",
      "accuracy of the model 0.7064220183486238 random_state 467\n",
      "accuracy of the model 0.7064220183486238 random_state 468\n",
      "accuracy of the model 0.7247706422018348 random_state 469\n",
      "accuracy of the model 0.7064220183486238 random_state 470\n",
      "accuracy of the model 0.7339449541284404 random_state 471\n",
      "accuracy of the model 0.6880733944954128 random_state 472\n",
      "accuracy of the model 0.7431192660550459 random_state 473\n",
      "accuracy of the model 0.7064220183486238 random_state 474\n",
      "accuracy of the model 0.7522935779816514 random_state 475\n",
      "accuracy of the model 0.7798165137614679 random_state 476\n",
      "accuracy of the model 0.6972477064220184 random_state 477\n",
      "accuracy of the model 0.7614678899082569 random_state 478\n",
      "accuracy of the model 0.6880733944954128 random_state 479\n",
      "accuracy of the model 0.5779816513761468 random_state 480\n",
      "accuracy of the model 0.6880733944954128 random_state 481\n",
      "accuracy of the model 0.6605504587155964 random_state 482\n",
      "accuracy of the model 0.6513761467889908 random_state 483\n",
      "accuracy of the model 0.7155963302752294 random_state 484\n",
      "accuracy of the model 0.7247706422018348 random_state 485\n",
      "accuracy of the model 0.7064220183486238 random_state 486\n",
      "accuracy of the model 0.7339449541284404 random_state 487\n",
      "accuracy of the model 0.7431192660550459 random_state 488\n",
      "accuracy of the model 0.6880733944954128 random_state 489\n",
      "accuracy of the model 0.7247706422018348 random_state 490\n",
      "accuracy of the model 0.7798165137614679 random_state 491\n",
      "accuracy of the model 0.7798165137614679 random_state 492\n",
      "accuracy of the model 0.6880733944954128 random_state 493\n",
      "accuracy of the model 0.7614678899082569 random_state 494\n",
      "accuracy of the model 0.6238532110091743 random_state 495\n",
      "accuracy of the model 0.7706422018348624 random_state 496\n",
      "accuracy of the model 0.6788990825688074 random_state 497\n",
      "accuracy of the model 0.7155963302752294 random_state 498\n",
      "accuracy of the model 0.7614678899082569 random_state 499\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,500):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    kn=KNeighborsClassifier()\n",
    "    kn.fit(x_train, y_train)\n",
    "    pred=kn.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba867d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8165137614678899 in random state 224\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d45a4c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.6330275229357798 random_state 1\n",
      "accuracy of the optimum model 0.6330275229357798 random_state 1\n",
      "accuracy of the model 0.7339449541284404 random_state 2\n",
      "accuracy of the optimum model 0.7339449541284404 random_state 2\n",
      "accuracy of the model 0.7064220183486238 random_state 3\n",
      "accuracy of the model 0.6972477064220184 random_state 4\n",
      "accuracy of the model 0.7339449541284404 random_state 5\n",
      "accuracy of the model 0.7522935779816514 random_state 6\n",
      "accuracy of the optimum model 0.7522935779816514 random_state 6\n",
      "accuracy of the model 0.7339449541284404 random_state 7\n",
      "accuracy of the model 0.6880733944954128 random_state 8\n",
      "accuracy of the model 0.6605504587155964 random_state 9\n",
      "accuracy of the model 0.6880733944954128 random_state 10\n",
      "accuracy of the model 0.6697247706422018 random_state 11\n",
      "accuracy of the model 0.7155963302752294 random_state 12\n",
      "accuracy of the model 0.7247706422018348 random_state 13\n",
      "accuracy of the model 0.6788990825688074 random_state 14\n",
      "accuracy of the model 0.7064220183486238 random_state 15\n",
      "accuracy of the model 0.6972477064220184 random_state 16\n",
      "accuracy of the model 0.6880733944954128 random_state 17\n",
      "accuracy of the model 0.7064220183486238 random_state 18\n",
      "accuracy of the model 0.6513761467889908 random_state 19\n",
      "accuracy of the model 0.6697247706422018 random_state 20\n",
      "accuracy of the model 0.7614678899082569 random_state 21\n",
      "accuracy of the optimum model 0.7614678899082569 random_state 21\n",
      "accuracy of the model 0.7339449541284404 random_state 22\n",
      "accuracy of the model 0.6972477064220184 random_state 23\n",
      "accuracy of the model 0.7431192660550459 random_state 24\n",
      "accuracy of the model 0.6880733944954128 random_state 25\n",
      "accuracy of the model 0.7431192660550459 random_state 26\n",
      "accuracy of the model 0.7247706422018348 random_state 27\n",
      "accuracy of the model 0.7339449541284404 random_state 28\n",
      "accuracy of the model 0.7064220183486238 random_state 29\n",
      "accuracy of the model 0.7339449541284404 random_state 30\n",
      "accuracy of the model 0.6513761467889908 random_state 31\n",
      "accuracy of the model 0.6788990825688074 random_state 32\n",
      "accuracy of the model 0.6972477064220184 random_state 33\n",
      "accuracy of the model 0.7614678899082569 random_state 34\n",
      "accuracy of the model 0.6972477064220184 random_state 35\n",
      "accuracy of the model 0.7614678899082569 random_state 36\n",
      "accuracy of the model 0.6605504587155964 random_state 37\n",
      "accuracy of the model 0.7064220183486238 random_state 38\n",
      "accuracy of the model 0.7339449541284404 random_state 39\n",
      "accuracy of the model 0.7064220183486238 random_state 40\n",
      "accuracy of the model 0.7614678899082569 random_state 41\n",
      "accuracy of the model 0.6880733944954128 random_state 42\n",
      "accuracy of the model 0.7706422018348624 random_state 43\n",
      "accuracy of the optimum model 0.7706422018348624 random_state 43\n",
      "accuracy of the model 0.6513761467889908 random_state 44\n",
      "accuracy of the model 0.5963302752293578 random_state 45\n",
      "accuracy of the model 0.6788990825688074 random_state 46\n",
      "accuracy of the model 0.7155963302752294 random_state 47\n",
      "accuracy of the model 0.7339449541284404 random_state 48\n",
      "accuracy of the model 0.6605504587155964 random_state 49\n",
      "accuracy of the model 0.7155963302752294 random_state 50\n",
      "accuracy of the model 0.7431192660550459 random_state 51\n",
      "accuracy of the model 0.6880733944954128 random_state 52\n",
      "accuracy of the model 0.6788990825688074 random_state 53\n",
      "accuracy of the model 0.7155963302752294 random_state 54\n",
      "accuracy of the model 0.7064220183486238 random_state 55\n",
      "accuracy of the model 0.7064220183486238 random_state 56\n",
      "accuracy of the model 0.6605504587155964 random_state 57\n",
      "accuracy of the model 0.7889908256880734 random_state 58\n",
      "accuracy of the optimum model 0.7889908256880734 random_state 58\n",
      "accuracy of the model 0.7247706422018348 random_state 59\n",
      "accuracy of the model 0.7522935779816514 random_state 60\n",
      "accuracy of the model 0.7339449541284404 random_state 61\n",
      "accuracy of the model 0.6513761467889908 random_state 62\n",
      "accuracy of the model 0.7064220183486238 random_state 63\n",
      "accuracy of the model 0.6605504587155964 random_state 64\n",
      "accuracy of the model 0.7339449541284404 random_state 65\n",
      "accuracy of the model 0.6605504587155964 random_state 66\n",
      "accuracy of the model 0.6788990825688074 random_state 67\n",
      "accuracy of the model 0.7155963302752294 random_state 68\n",
      "accuracy of the model 0.6972477064220184 random_state 69\n",
      "accuracy of the model 0.7064220183486238 random_state 70\n",
      "accuracy of the model 0.6880733944954128 random_state 71\n",
      "accuracy of the model 0.5963302752293578 random_state 72\n",
      "accuracy of the model 0.7064220183486238 random_state 73\n",
      "accuracy of the model 0.6972477064220184 random_state 74\n",
      "accuracy of the model 0.7064220183486238 random_state 75\n",
      "accuracy of the model 0.6972477064220184 random_state 76\n",
      "accuracy of the model 0.6513761467889908 random_state 77\n",
      "accuracy of the model 0.7155963302752294 random_state 78\n",
      "accuracy of the model 0.5871559633027523 random_state 79\n",
      "accuracy of the model 0.6330275229357798 random_state 80\n",
      "accuracy of the model 0.7431192660550459 random_state 81\n",
      "accuracy of the model 0.6422018348623854 random_state 82\n",
      "accuracy of the model 0.6788990825688074 random_state 83\n",
      "accuracy of the model 0.7064220183486238 random_state 84\n",
      "accuracy of the model 0.6880733944954128 random_state 85\n",
      "accuracy of the model 0.7155963302752294 random_state 86\n",
      "accuracy of the model 0.6605504587155964 random_state 87\n",
      "accuracy of the model 0.6422018348623854 random_state 88\n",
      "accuracy of the model 0.6788990825688074 random_state 89\n",
      "accuracy of the model 0.7339449541284404 random_state 90\n",
      "accuracy of the model 0.7431192660550459 random_state 91\n",
      "accuracy of the model 0.5779816513761468 random_state 92\n",
      "accuracy of the model 0.7155963302752294 random_state 93\n",
      "accuracy of the model 0.6513761467889908 random_state 94\n",
      "accuracy of the model 0.7431192660550459 random_state 95\n",
      "accuracy of the model 0.6880733944954128 random_state 96\n",
      "accuracy of the model 0.6513761467889908 random_state 97\n",
      "accuracy of the model 0.6972477064220184 random_state 98\n",
      "accuracy of the model 0.6330275229357798 random_state 99\n",
      "accuracy of the model 0.6605504587155964 random_state 100\n",
      "accuracy of the model 0.6880733944954128 random_state 101\n",
      "accuracy of the model 0.6605504587155964 random_state 102\n",
      "accuracy of the model 0.6697247706422018 random_state 103\n",
      "accuracy of the model 0.6880733944954128 random_state 104\n",
      "accuracy of the model 0.7155963302752294 random_state 105\n",
      "accuracy of the model 0.7431192660550459 random_state 106\n",
      "accuracy of the model 0.6788990825688074 random_state 107\n",
      "accuracy of the model 0.7706422018348624 random_state 108\n",
      "accuracy of the model 0.6422018348623854 random_state 109\n",
      "accuracy of the model 0.7522935779816514 random_state 110\n",
      "accuracy of the model 0.7431192660550459 random_state 111\n",
      "accuracy of the model 0.6880733944954128 random_state 112\n",
      "accuracy of the model 0.7798165137614679 random_state 113\n",
      "accuracy of the model 0.6238532110091743 random_state 114\n",
      "accuracy of the model 0.7522935779816514 random_state 115\n",
      "accuracy of the model 0.7889908256880734 random_state 116\n",
      "accuracy of the model 0.7064220183486238 random_state 117\n",
      "accuracy of the model 0.7798165137614679 random_state 118\n",
      "accuracy of the model 0.6513761467889908 random_state 119\n",
      "accuracy of the model 0.7247706422018348 random_state 120\n",
      "accuracy of the model 0.6605504587155964 random_state 121\n",
      "accuracy of the model 0.6422018348623854 random_state 122\n",
      "accuracy of the model 0.6238532110091743 random_state 123\n",
      "accuracy of the model 0.7339449541284404 random_state 124\n",
      "accuracy of the model 0.6697247706422018 random_state 125\n",
      "accuracy of the model 0.6697247706422018 random_state 126\n",
      "accuracy of the model 0.7155963302752294 random_state 127\n",
      "accuracy of the model 0.7614678899082569 random_state 128\n",
      "accuracy of the model 0.6972477064220184 random_state 129\n",
      "accuracy of the model 0.6972477064220184 random_state 130\n",
      "accuracy of the model 0.6972477064220184 random_state 131\n",
      "accuracy of the model 0.6880733944954128 random_state 132\n",
      "accuracy of the model 0.7614678899082569 random_state 133\n",
      "accuracy of the model 0.7155963302752294 random_state 134\n",
      "accuracy of the model 0.7522935779816514 random_state 135\n",
      "accuracy of the model 0.7522935779816514 random_state 136\n",
      "accuracy of the model 0.5963302752293578 random_state 137\n",
      "accuracy of the model 0.7155963302752294 random_state 138\n",
      "accuracy of the model 0.7614678899082569 random_state 139\n",
      "accuracy of the model 0.7522935779816514 random_state 140\n",
      "accuracy of the model 0.7155963302752294 random_state 141\n",
      "accuracy of the model 0.7339449541284404 random_state 142\n",
      "accuracy of the model 0.6972477064220184 random_state 143\n",
      "accuracy of the model 0.7064220183486238 random_state 144\n",
      "accuracy of the model 0.5871559633027523 random_state 145\n",
      "accuracy of the model 0.6422018348623854 random_state 146\n",
      "accuracy of the model 0.7981651376146789 random_state 147\n",
      "accuracy of the optimum model 0.7981651376146789 random_state 147\n",
      "accuracy of the model 0.6697247706422018 random_state 148\n",
      "accuracy of the model 0.6788990825688074 random_state 149\n",
      "accuracy of the model 0.6422018348623854 random_state 150\n",
      "accuracy of the model 0.7247706422018348 random_state 151\n",
      "accuracy of the model 0.7064220183486238 random_state 152\n",
      "accuracy of the model 0.7064220183486238 random_state 153\n",
      "accuracy of the model 0.6697247706422018 random_state 154\n",
      "accuracy of the model 0.7431192660550459 random_state 155\n",
      "accuracy of the model 0.7155963302752294 random_state 156\n",
      "accuracy of the model 0.7706422018348624 random_state 157\n",
      "accuracy of the model 0.6513761467889908 random_state 158\n",
      "accuracy of the model 0.6605504587155964 random_state 159\n",
      "accuracy of the model 0.7522935779816514 random_state 160\n",
      "accuracy of the model 0.7798165137614679 random_state 161\n",
      "accuracy of the model 0.6697247706422018 random_state 162\n",
      "accuracy of the model 0.7339449541284404 random_state 163\n",
      "accuracy of the model 0.7064220183486238 random_state 164\n",
      "accuracy of the model 0.7339449541284404 random_state 165\n",
      "accuracy of the model 0.7798165137614679 random_state 166\n",
      "accuracy of the model 0.6146788990825688 random_state 167\n",
      "accuracy of the model 0.7064220183486238 random_state 168\n",
      "accuracy of the model 0.6972477064220184 random_state 169\n",
      "accuracy of the model 0.7064220183486238 random_state 170\n",
      "accuracy of the model 0.7522935779816514 random_state 171\n",
      "accuracy of the model 0.6880733944954128 random_state 172\n",
      "accuracy of the model 0.6788990825688074 random_state 173\n",
      "accuracy of the model 0.6972477064220184 random_state 174\n",
      "accuracy of the model 0.7339449541284404 random_state 175\n",
      "accuracy of the model 0.7614678899082569 random_state 176\n",
      "accuracy of the model 0.6697247706422018 random_state 177\n",
      "accuracy of the model 0.7064220183486238 random_state 178\n",
      "accuracy of the model 0.6788990825688074 random_state 179\n",
      "accuracy of the model 0.6972477064220184 random_state 180\n",
      "accuracy of the model 0.7064220183486238 random_state 181\n",
      "accuracy of the model 0.7155963302752294 random_state 182\n",
      "accuracy of the model 0.7614678899082569 random_state 183\n",
      "accuracy of the model 0.5688073394495413 random_state 184\n",
      "accuracy of the model 0.7431192660550459 random_state 185\n",
      "accuracy of the model 0.7431192660550459 random_state 186\n",
      "accuracy of the model 0.7155963302752294 random_state 187\n",
      "accuracy of the model 0.7706422018348624 random_state 188\n",
      "accuracy of the model 0.7522935779816514 random_state 189\n",
      "accuracy of the model 0.6880733944954128 random_state 190\n",
      "accuracy of the model 0.7339449541284404 random_state 191\n",
      "accuracy of the model 0.7247706422018348 random_state 192\n",
      "accuracy of the model 0.6513761467889908 random_state 193\n",
      "accuracy of the model 0.6788990825688074 random_state 194\n",
      "accuracy of the model 0.7431192660550459 random_state 195\n",
      "accuracy of the model 0.7247706422018348 random_state 196\n",
      "accuracy of the model 0.6788990825688074 random_state 197\n",
      "accuracy of the model 0.6330275229357798 random_state 198\n",
      "accuracy of the model 0.6697247706422018 random_state 199\n",
      "accuracy of the model 0.6880733944954128 random_state 200\n",
      "accuracy of the model 0.7339449541284404 random_state 201\n",
      "accuracy of the model 0.7339449541284404 random_state 202\n",
      "accuracy of the model 0.7431192660550459 random_state 203\n",
      "accuracy of the model 0.8165137614678899 random_state 204\n",
      "accuracy of the optimum model 0.8165137614678899 random_state 204\n",
      "accuracy of the model 0.7155963302752294 random_state 205\n",
      "accuracy of the model 0.6422018348623854 random_state 206\n",
      "accuracy of the model 0.8073394495412844 random_state 207\n",
      "accuracy of the model 0.6697247706422018 random_state 208\n",
      "accuracy of the model 0.7614678899082569 random_state 209\n",
      "accuracy of the model 0.7431192660550459 random_state 210\n",
      "accuracy of the model 0.6605504587155964 random_state 211\n",
      "accuracy of the model 0.6605504587155964 random_state 212\n",
      "accuracy of the model 0.6422018348623854 random_state 213\n",
      "accuracy of the model 0.7064220183486238 random_state 214\n",
      "accuracy of the model 0.6972477064220184 random_state 215\n",
      "accuracy of the model 0.7064220183486238 random_state 216\n",
      "accuracy of the model 0.6880733944954128 random_state 217\n",
      "accuracy of the model 0.7706422018348624 random_state 218\n",
      "accuracy of the model 0.6513761467889908 random_state 219\n",
      "accuracy of the model 0.6788990825688074 random_state 220\n",
      "accuracy of the model 0.6605504587155964 random_state 221\n",
      "accuracy of the model 0.7155963302752294 random_state 222\n",
      "accuracy of the model 0.7155963302752294 random_state 223\n",
      "accuracy of the model 0.7339449541284404 random_state 224\n",
      "accuracy of the model 0.5871559633027523 random_state 225\n",
      "accuracy of the model 0.8073394495412844 random_state 226\n",
      "accuracy of the model 0.7155963302752294 random_state 227\n",
      "accuracy of the model 0.6146788990825688 random_state 228\n",
      "accuracy of the model 0.6330275229357798 random_state 229\n",
      "accuracy of the model 0.7155963302752294 random_state 230\n",
      "accuracy of the model 0.6788990825688074 random_state 231\n",
      "accuracy of the model 0.6972477064220184 random_state 232\n",
      "accuracy of the model 0.7339449541284404 random_state 233\n",
      "accuracy of the model 0.6972477064220184 random_state 234\n",
      "accuracy of the model 0.6605504587155964 random_state 235\n",
      "accuracy of the model 0.7064220183486238 random_state 236\n",
      "accuracy of the model 0.6788990825688074 random_state 237\n",
      "accuracy of the model 0.7339449541284404 random_state 238\n",
      "accuracy of the model 0.6972477064220184 random_state 239\n",
      "accuracy of the model 0.7614678899082569 random_state 240\n",
      "accuracy of the model 0.6880733944954128 random_state 241\n",
      "accuracy of the model 0.7247706422018348 random_state 242\n",
      "accuracy of the model 0.7155963302752294 random_state 243\n",
      "accuracy of the model 0.7155963302752294 random_state 244\n",
      "accuracy of the model 0.6697247706422018 random_state 245\n",
      "accuracy of the model 0.7247706422018348 random_state 246\n",
      "accuracy of the model 0.7064220183486238 random_state 247\n",
      "accuracy of the model 0.7064220183486238 random_state 248\n",
      "accuracy of the model 0.7247706422018348 random_state 249\n",
      "accuracy of the model 0.7431192660550459 random_state 250\n",
      "accuracy of the model 0.7522935779816514 random_state 251\n",
      "accuracy of the model 0.5688073394495413 random_state 252\n",
      "accuracy of the model 0.7155963302752294 random_state 253\n",
      "accuracy of the model 0.7247706422018348 random_state 254\n",
      "accuracy of the model 0.7522935779816514 random_state 255\n",
      "accuracy of the model 0.7247706422018348 random_state 256\n",
      "accuracy of the model 0.6697247706422018 random_state 257\n",
      "accuracy of the model 0.6697247706422018 random_state 258\n",
      "accuracy of the model 0.7522935779816514 random_state 259\n",
      "accuracy of the model 0.6972477064220184 random_state 260\n",
      "accuracy of the model 0.6880733944954128 random_state 261\n",
      "accuracy of the model 0.7339449541284404 random_state 262\n",
      "accuracy of the model 0.7339449541284404 random_state 263\n",
      "accuracy of the model 0.7889908256880734 random_state 264\n",
      "accuracy of the model 0.6972477064220184 random_state 265\n",
      "accuracy of the model 0.6880733944954128 random_state 266\n",
      "accuracy of the model 0.6697247706422018 random_state 267\n",
      "accuracy of the model 0.6605504587155964 random_state 268\n",
      "accuracy of the model 0.6422018348623854 random_state 269\n",
      "accuracy of the model 0.7064220183486238 random_state 270\n",
      "accuracy of the model 0.7522935779816514 random_state 271\n",
      "accuracy of the model 0.6605504587155964 random_state 272\n",
      "accuracy of the model 0.7247706422018348 random_state 273\n",
      "accuracy of the model 0.6605504587155964 random_state 274\n",
      "accuracy of the model 0.7522935779816514 random_state 275\n",
      "accuracy of the model 0.6513761467889908 random_state 276\n",
      "accuracy of the model 0.7064220183486238 random_state 277\n",
      "accuracy of the model 0.7064220183486238 random_state 278\n",
      "accuracy of the model 0.6788990825688074 random_state 279\n",
      "accuracy of the model 0.7155963302752294 random_state 280\n",
      "accuracy of the model 0.6697247706422018 random_state 281\n",
      "accuracy of the model 0.6605504587155964 random_state 282\n",
      "accuracy of the model 0.7339449541284404 random_state 283\n",
      "accuracy of the model 0.6697247706422018 random_state 284\n",
      "accuracy of the model 0.7798165137614679 random_state 285\n",
      "accuracy of the model 0.7247706422018348 random_state 286\n",
      "accuracy of the model 0.6146788990825688 random_state 287\n",
      "accuracy of the model 0.7155963302752294 random_state 288\n",
      "accuracy of the model 0.7247706422018348 random_state 289\n",
      "accuracy of the model 0.6330275229357798 random_state 290\n",
      "accuracy of the model 0.7339449541284404 random_state 291\n",
      "accuracy of the model 0.7064220183486238 random_state 292\n",
      "accuracy of the model 0.7522935779816514 random_state 293\n",
      "accuracy of the model 0.7155963302752294 random_state 294\n",
      "accuracy of the model 0.6513761467889908 random_state 295\n",
      "accuracy of the model 0.6788990825688074 random_state 296\n",
      "accuracy of the model 0.7339449541284404 random_state 297\n",
      "accuracy of the model 0.6788990825688074 random_state 298\n",
      "accuracy of the model 0.6697247706422018 random_state 299\n",
      "accuracy of the model 0.6605504587155964 random_state 300\n",
      "accuracy of the model 0.6238532110091743 random_state 301\n",
      "accuracy of the model 0.6605504587155964 random_state 302\n",
      "accuracy of the model 0.7155963302752294 random_state 303\n",
      "accuracy of the model 0.6697247706422018 random_state 304\n",
      "accuracy of the model 0.7431192660550459 random_state 305\n",
      "accuracy of the model 0.6788990825688074 random_state 306\n",
      "accuracy of the model 0.6055045871559633 random_state 307\n",
      "accuracy of the model 0.6422018348623854 random_state 308\n",
      "accuracy of the model 0.6972477064220184 random_state 309\n",
      "accuracy of the model 0.6422018348623854 random_state 310\n",
      "accuracy of the model 0.7155963302752294 random_state 311\n",
      "accuracy of the model 0.6972477064220184 random_state 312\n",
      "accuracy of the model 0.6605504587155964 random_state 313\n",
      "accuracy of the model 0.6697247706422018 random_state 314\n",
      "accuracy of the model 0.7522935779816514 random_state 315\n",
      "accuracy of the model 0.6330275229357798 random_state 316\n",
      "accuracy of the model 0.6422018348623854 random_state 317\n",
      "accuracy of the model 0.6238532110091743 random_state 318\n",
      "accuracy of the model 0.6972477064220184 random_state 319\n",
      "accuracy of the model 0.7064220183486238 random_state 320\n",
      "accuracy of the model 0.7522935779816514 random_state 321\n",
      "accuracy of the model 0.6788990825688074 random_state 322\n",
      "accuracy of the model 0.6697247706422018 random_state 323\n",
      "accuracy of the model 0.6788990825688074 random_state 324\n",
      "accuracy of the model 0.7431192660550459 random_state 325\n",
      "accuracy of the model 0.6788990825688074 random_state 326\n",
      "accuracy of the model 0.6697247706422018 random_state 327\n",
      "accuracy of the model 0.6788990825688074 random_state 328\n",
      "accuracy of the model 0.6972477064220184 random_state 329\n",
      "accuracy of the model 0.6605504587155964 random_state 330\n",
      "accuracy of the model 0.7155963302752294 random_state 331\n",
      "accuracy of the model 0.6880733944954128 random_state 332\n",
      "accuracy of the model 0.7339449541284404 random_state 333\n",
      "accuracy of the model 0.7798165137614679 random_state 334\n",
      "accuracy of the model 0.7064220183486238 random_state 335\n",
      "accuracy of the model 0.6972477064220184 random_state 336\n",
      "accuracy of the model 0.7798165137614679 random_state 337\n",
      "accuracy of the model 0.7522935779816514 random_state 338\n",
      "accuracy of the model 0.7247706422018348 random_state 339\n",
      "accuracy of the model 0.7798165137614679 random_state 340\n",
      "accuracy of the model 0.6697247706422018 random_state 341\n",
      "accuracy of the model 0.6880733944954128 random_state 342\n",
      "accuracy of the model 0.7431192660550459 random_state 343\n",
      "accuracy of the model 0.5779816513761468 random_state 344\n",
      "accuracy of the model 0.7155963302752294 random_state 345\n",
      "accuracy of the model 0.7431192660550459 random_state 346\n",
      "accuracy of the model 0.7155963302752294 random_state 347\n",
      "accuracy of the model 0.6513761467889908 random_state 348\n",
      "accuracy of the model 0.7431192660550459 random_state 349\n",
      "accuracy of the model 0.6146788990825688 random_state 350\n",
      "accuracy of the model 0.7247706422018348 random_state 351\n",
      "accuracy of the model 0.6330275229357798 random_state 352\n",
      "accuracy of the model 0.6697247706422018 random_state 353\n",
      "accuracy of the model 0.6972477064220184 random_state 354\n",
      "accuracy of the model 0.6605504587155964 random_state 355\n",
      "accuracy of the model 0.6972477064220184 random_state 356\n",
      "accuracy of the model 0.7155963302752294 random_state 357\n",
      "accuracy of the model 0.7431192660550459 random_state 358\n",
      "accuracy of the model 0.6880733944954128 random_state 359\n",
      "accuracy of the model 0.6972477064220184 random_state 360\n",
      "accuracy of the model 0.6880733944954128 random_state 361\n",
      "accuracy of the model 0.7155963302752294 random_state 362\n",
      "accuracy of the model 0.7339449541284404 random_state 363\n",
      "accuracy of the model 0.6972477064220184 random_state 364\n",
      "accuracy of the model 0.7064220183486238 random_state 365\n",
      "accuracy of the model 0.7155963302752294 random_state 366\n",
      "accuracy of the model 0.7614678899082569 random_state 367\n",
      "accuracy of the model 0.7155963302752294 random_state 368\n",
      "accuracy of the model 0.6605504587155964 random_state 369\n",
      "accuracy of the model 0.7247706422018348 random_state 370\n",
      "accuracy of the model 0.6330275229357798 random_state 371\n",
      "accuracy of the model 0.6513761467889908 random_state 372\n",
      "accuracy of the model 0.7339449541284404 random_state 373\n",
      "accuracy of the model 0.6880733944954128 random_state 374\n",
      "accuracy of the model 0.6788990825688074 random_state 375\n",
      "accuracy of the model 0.6788990825688074 random_state 376\n",
      "accuracy of the model 0.7522935779816514 random_state 377\n",
      "accuracy of the model 0.6972477064220184 random_state 378\n",
      "accuracy of the model 0.6605504587155964 random_state 379\n",
      "accuracy of the model 0.7889908256880734 random_state 380\n",
      "accuracy of the model 0.6972477064220184 random_state 381\n",
      "accuracy of the model 0.6788990825688074 random_state 382\n",
      "accuracy of the model 0.7339449541284404 random_state 383\n",
      "accuracy of the model 0.7064220183486238 random_state 384\n",
      "accuracy of the model 0.6972477064220184 random_state 385\n",
      "accuracy of the model 0.6972477064220184 random_state 386\n",
      "accuracy of the model 0.6238532110091743 random_state 387\n",
      "accuracy of the model 0.6972477064220184 random_state 388\n",
      "accuracy of the model 0.7247706422018348 random_state 389\n",
      "accuracy of the model 0.7431192660550459 random_state 390\n",
      "accuracy of the model 0.7155963302752294 random_state 391\n",
      "accuracy of the model 0.6605504587155964 random_state 392\n",
      "accuracy of the model 0.6513761467889908 random_state 393\n",
      "accuracy of the model 0.6788990825688074 random_state 394\n",
      "accuracy of the model 0.6238532110091743 random_state 395\n",
      "accuracy of the model 0.7155963302752294 random_state 396\n",
      "accuracy of the model 0.6972477064220184 random_state 397\n",
      "accuracy of the model 0.7614678899082569 random_state 398\n",
      "accuracy of the model 0.7064220183486238 random_state 399\n",
      "accuracy of the model 0.7339449541284404 random_state 400\n",
      "accuracy of the model 0.6055045871559633 random_state 401\n",
      "accuracy of the model 0.7614678899082569 random_state 402\n",
      "accuracy of the model 0.6238532110091743 random_state 403\n",
      "accuracy of the model 0.6880733944954128 random_state 404\n",
      "accuracy of the model 0.6972477064220184 random_state 405\n",
      "accuracy of the model 0.7155963302752294 random_state 406\n",
      "accuracy of the model 0.7155963302752294 random_state 407\n",
      "accuracy of the model 0.6605504587155964 random_state 408\n",
      "accuracy of the model 0.6697247706422018 random_state 409\n",
      "accuracy of the model 0.7155963302752294 random_state 410\n",
      "accuracy of the model 0.6513761467889908 random_state 411\n",
      "accuracy of the model 0.6697247706422018 random_state 412\n",
      "accuracy of the model 0.6972477064220184 random_state 413\n",
      "accuracy of the model 0.7614678899082569 random_state 414\n",
      "accuracy of the model 0.7155963302752294 random_state 415\n",
      "accuracy of the model 0.7614678899082569 random_state 416\n",
      "accuracy of the model 0.7706422018348624 random_state 417\n",
      "accuracy of the model 0.6697247706422018 random_state 418\n",
      "accuracy of the model 0.7064220183486238 random_state 419\n",
      "accuracy of the model 0.6422018348623854 random_state 420\n",
      "accuracy of the model 0.6788990825688074 random_state 421\n",
      "accuracy of the model 0.7339449541284404 random_state 422\n",
      "accuracy of the model 0.7522935779816514 random_state 423\n",
      "accuracy of the model 0.7064220183486238 random_state 424\n",
      "accuracy of the model 0.7064220183486238 random_state 425\n",
      "accuracy of the model 0.6972477064220184 random_state 426\n",
      "accuracy of the model 0.6238532110091743 random_state 427\n",
      "accuracy of the model 0.7247706422018348 random_state 428\n",
      "accuracy of the model 0.7339449541284404 random_state 429\n",
      "accuracy of the model 0.7339449541284404 random_state 430\n",
      "accuracy of the model 0.6880733944954128 random_state 431\n",
      "accuracy of the model 0.6880733944954128 random_state 432\n",
      "accuracy of the model 0.6880733944954128 random_state 433\n",
      "accuracy of the model 0.7339449541284404 random_state 434\n",
      "accuracy of the model 0.7155963302752294 random_state 435\n",
      "accuracy of the model 0.6605504587155964 random_state 436\n",
      "accuracy of the model 0.6880733944954128 random_state 437\n",
      "accuracy of the model 0.7614678899082569 random_state 438\n",
      "accuracy of the model 0.6972477064220184 random_state 439\n",
      "accuracy of the model 0.6972477064220184 random_state 440\n",
      "accuracy of the model 0.7522935779816514 random_state 441\n",
      "accuracy of the model 0.6972477064220184 random_state 442\n",
      "accuracy of the model 0.6605504587155964 random_state 443\n",
      "accuracy of the model 0.6880733944954128 random_state 444\n",
      "accuracy of the model 0.6605504587155964 random_state 445\n",
      "accuracy of the model 0.6513761467889908 random_state 446\n",
      "accuracy of the model 0.6697247706422018 random_state 447\n",
      "accuracy of the model 0.6972477064220184 random_state 448\n",
      "accuracy of the model 0.6605504587155964 random_state 449\n",
      "accuracy of the model 0.6513761467889908 random_state 450\n",
      "accuracy of the model 0.6880733944954128 random_state 451\n",
      "accuracy of the model 0.7339449541284404 random_state 452\n",
      "accuracy of the model 0.7522935779816514 random_state 453\n",
      "accuracy of the model 0.6880733944954128 random_state 454\n",
      "accuracy of the model 0.6788990825688074 random_state 455\n",
      "accuracy of the model 0.6605504587155964 random_state 456\n",
      "accuracy of the model 0.6513761467889908 random_state 457\n",
      "accuracy of the model 0.6697247706422018 random_state 458\n",
      "accuracy of the model 0.7614678899082569 random_state 459\n",
      "accuracy of the model 0.6972477064220184 random_state 460\n",
      "accuracy of the model 0.6513761467889908 random_state 461\n",
      "accuracy of the model 0.6605504587155964 random_state 462\n",
      "accuracy of the model 0.6697247706422018 random_state 463\n",
      "accuracy of the model 0.6697247706422018 random_state 464\n",
      "accuracy of the model 0.6972477064220184 random_state 465\n",
      "accuracy of the model 0.7339449541284404 random_state 466\n",
      "accuracy of the model 0.6880733944954128 random_state 467\n",
      "accuracy of the model 0.6238532110091743 random_state 468\n",
      "accuracy of the model 0.7522935779816514 random_state 469\n",
      "accuracy of the model 0.7522935779816514 random_state 470\n",
      "accuracy of the model 0.6146788990825688 random_state 471\n",
      "accuracy of the model 0.7431192660550459 random_state 472\n",
      "accuracy of the model 0.7614678899082569 random_state 473\n",
      "accuracy of the model 0.6605504587155964 random_state 474\n",
      "accuracy of the model 0.6880733944954128 random_state 475\n",
      "accuracy of the model 0.7431192660550459 random_state 476\n",
      "accuracy of the model 0.6422018348623854 random_state 477\n",
      "accuracy of the model 0.6605504587155964 random_state 478\n",
      "accuracy of the model 0.6697247706422018 random_state 479\n",
      "accuracy of the model 0.6788990825688074 random_state 480\n",
      "accuracy of the model 0.7155963302752294 random_state 481\n",
      "accuracy of the model 0.7247706422018348 random_state 482\n",
      "accuracy of the model 0.6880733944954128 random_state 483\n",
      "accuracy of the model 0.6880733944954128 random_state 484\n",
      "accuracy of the model 0.6513761467889908 random_state 485\n",
      "accuracy of the model 0.6972477064220184 random_state 486\n",
      "accuracy of the model 0.7706422018348624 random_state 487\n",
      "accuracy of the model 0.7247706422018348 random_state 488\n",
      "accuracy of the model 0.6605504587155964 random_state 489\n",
      "accuracy of the model 0.7522935779816514 random_state 490\n",
      "accuracy of the model 0.7339449541284404 random_state 491\n",
      "accuracy of the model 0.6513761467889908 random_state 492\n",
      "accuracy of the model 0.7706422018348624 random_state 493\n",
      "accuracy of the model 0.7522935779816514 random_state 494\n",
      "accuracy of the model 0.6697247706422018 random_state 495\n",
      "accuracy of the model 0.6972477064220184 random_state 496\n",
      "accuracy of the model 0.7155963302752294 random_state 497\n",
      "accuracy of the model 0.6697247706422018 random_state 498\n",
      "accuracy of the model 0.6330275229357798 random_state 499\n",
      "accuracy of the model 0.6788990825688074 random_state 500\n",
      "accuracy of the model 0.7798165137614679 random_state 501\n",
      "accuracy of the model 0.6146788990825688 random_state 502\n",
      "accuracy of the model 0.6146788990825688 random_state 503\n",
      "accuracy of the model 0.6972477064220184 random_state 504\n",
      "accuracy of the model 0.7155963302752294 random_state 505\n",
      "accuracy of the model 0.7798165137614679 random_state 506\n",
      "accuracy of the model 0.7889908256880734 random_state 507\n",
      "accuracy of the model 0.7247706422018348 random_state 508\n",
      "accuracy of the model 0.6697247706422018 random_state 509\n",
      "accuracy of the model 0.7339449541284404 random_state 510\n",
      "accuracy of the model 0.7614678899082569 random_state 511\n",
      "accuracy of the model 0.6605504587155964 random_state 512\n",
      "accuracy of the model 0.6330275229357798 random_state 513\n",
      "accuracy of the model 0.7798165137614679 random_state 514\n",
      "accuracy of the model 0.6513761467889908 random_state 515\n",
      "accuracy of the model 0.7614678899082569 random_state 516\n",
      "accuracy of the model 0.7798165137614679 random_state 517\n",
      "accuracy of the model 0.7706422018348624 random_state 518\n",
      "accuracy of the model 0.6605504587155964 random_state 519\n",
      "accuracy of the model 0.6788990825688074 random_state 520\n",
      "accuracy of the model 0.6972477064220184 random_state 521\n",
      "accuracy of the model 0.6605504587155964 random_state 522\n",
      "accuracy of the model 0.6880733944954128 random_state 523\n",
      "accuracy of the model 0.7339449541284404 random_state 524\n",
      "accuracy of the model 0.6605504587155964 random_state 525\n",
      "accuracy of the model 0.6972477064220184 random_state 526\n",
      "accuracy of the model 0.6422018348623854 random_state 527\n",
      "accuracy of the model 0.6880733944954128 random_state 528\n",
      "accuracy of the model 0.6972477064220184 random_state 529\n",
      "accuracy of the model 0.6697247706422018 random_state 530\n",
      "accuracy of the model 0.6605504587155964 random_state 531\n",
      "accuracy of the model 0.7614678899082569 random_state 532\n",
      "accuracy of the model 0.7614678899082569 random_state 533\n",
      "accuracy of the model 0.6972477064220184 random_state 534\n",
      "accuracy of the model 0.6605504587155964 random_state 535\n",
      "accuracy of the model 0.7431192660550459 random_state 536\n",
      "accuracy of the model 0.7339449541284404 random_state 537\n",
      "accuracy of the model 0.6697247706422018 random_state 538\n",
      "accuracy of the model 0.6697247706422018 random_state 539\n",
      "accuracy of the model 0.6146788990825688 random_state 540\n",
      "accuracy of the model 0.7431192660550459 random_state 541\n",
      "accuracy of the model 0.6055045871559633 random_state 542\n",
      "accuracy of the model 0.7155963302752294 random_state 543\n",
      "accuracy of the model 0.6788990825688074 random_state 544\n",
      "accuracy of the model 0.6880733944954128 random_state 545\n",
      "accuracy of the model 0.5963302752293578 random_state 546\n",
      "accuracy of the model 0.6697247706422018 random_state 547\n",
      "accuracy of the model 0.7706422018348624 random_state 548\n",
      "accuracy of the model 0.7431192660550459 random_state 549\n",
      "accuracy of the model 0.6880733944954128 random_state 550\n",
      "accuracy of the model 0.7064220183486238 random_state 551\n",
      "accuracy of the model 0.7431192660550459 random_state 552\n",
      "accuracy of the model 0.7064220183486238 random_state 553\n",
      "accuracy of the model 0.6972477064220184 random_state 554\n",
      "accuracy of the model 0.6972477064220184 random_state 555\n",
      "accuracy of the model 0.7155963302752294 random_state 556\n",
      "accuracy of the model 0.6880733944954128 random_state 557\n",
      "accuracy of the model 0.7339449541284404 random_state 558\n",
      "accuracy of the model 0.6972477064220184 random_state 559\n",
      "accuracy of the model 0.7339449541284404 random_state 560\n",
      "accuracy of the model 0.6697247706422018 random_state 561\n",
      "accuracy of the model 0.6880733944954128 random_state 562\n",
      "accuracy of the model 0.6422018348623854 random_state 563\n",
      "accuracy of the model 0.7889908256880734 random_state 564\n",
      "accuracy of the model 0.6422018348623854 random_state 565\n",
      "accuracy of the model 0.6972477064220184 random_state 566\n",
      "accuracy of the model 0.6788990825688074 random_state 567\n",
      "accuracy of the model 0.7339449541284404 random_state 568\n",
      "accuracy of the model 0.7247706422018348 random_state 569\n",
      "accuracy of the model 0.6605504587155964 random_state 570\n",
      "accuracy of the model 0.7247706422018348 random_state 571\n",
      "accuracy of the model 0.6697247706422018 random_state 572\n",
      "accuracy of the model 0.7522935779816514 random_state 573\n",
      "accuracy of the model 0.6788990825688074 random_state 574\n",
      "accuracy of the model 0.7155963302752294 random_state 575\n",
      "accuracy of the model 0.7522935779816514 random_state 576\n",
      "accuracy of the model 0.7614678899082569 random_state 577\n",
      "accuracy of the model 0.7247706422018348 random_state 578\n",
      "accuracy of the model 0.7889908256880734 random_state 579\n",
      "accuracy of the model 0.7798165137614679 random_state 580\n",
      "accuracy of the model 0.7064220183486238 random_state 581\n",
      "accuracy of the model 0.7064220183486238 random_state 582\n",
      "accuracy of the model 0.6788990825688074 random_state 583\n",
      "accuracy of the model 0.6055045871559633 random_state 584\n",
      "accuracy of the model 0.6513761467889908 random_state 585\n",
      "accuracy of the model 0.6880733944954128 random_state 586\n",
      "accuracy of the model 0.7339449541284404 random_state 587\n",
      "accuracy of the model 0.7064220183486238 random_state 588\n",
      "accuracy of the model 0.6422018348623854 random_state 589\n",
      "accuracy of the model 0.7064220183486238 random_state 590\n",
      "accuracy of the model 0.6697247706422018 random_state 591\n",
      "accuracy of the model 0.6972477064220184 random_state 592\n",
      "accuracy of the model 0.7339449541284404 random_state 593\n",
      "accuracy of the model 0.7889908256880734 random_state 594\n",
      "accuracy of the model 0.7064220183486238 random_state 595\n",
      "accuracy of the model 0.7614678899082569 random_state 596\n",
      "accuracy of the model 0.6972477064220184 random_state 597\n",
      "accuracy of the model 0.7614678899082569 random_state 598\n",
      "accuracy of the model 0.6330275229357798 random_state 599\n",
      "accuracy of the model 0.6605504587155964 random_state 600\n",
      "accuracy of the model 0.7431192660550459 random_state 601\n",
      "accuracy of the model 0.6513761467889908 random_state 602\n",
      "accuracy of the model 0.7064220183486238 random_state 603\n",
      "accuracy of the model 0.6788990825688074 random_state 604\n",
      "accuracy of the model 0.6605504587155964 random_state 605\n",
      "accuracy of the model 0.7522935779816514 random_state 606\n",
      "accuracy of the model 0.7064220183486238 random_state 607\n",
      "accuracy of the model 0.6330275229357798 random_state 608\n",
      "accuracy of the model 0.6605504587155964 random_state 609\n",
      "accuracy of the model 0.7155963302752294 random_state 610\n",
      "accuracy of the model 0.7431192660550459 random_state 611\n",
      "accuracy of the model 0.7522935779816514 random_state 612\n",
      "accuracy of the model 0.7522935779816514 random_state 613\n",
      "accuracy of the model 0.6697247706422018 random_state 614\n",
      "accuracy of the model 0.7064220183486238 random_state 615\n",
      "accuracy of the model 0.6880733944954128 random_state 616\n",
      "accuracy of the model 0.7064220183486238 random_state 617\n",
      "accuracy of the model 0.7064220183486238 random_state 618\n",
      "accuracy of the model 0.6788990825688074 random_state 619\n",
      "accuracy of the model 0.7155963302752294 random_state 620\n",
      "accuracy of the model 0.7155963302752294 random_state 621\n",
      "accuracy of the model 0.7155963302752294 random_state 622\n",
      "accuracy of the model 0.6697247706422018 random_state 623\n",
      "accuracy of the model 0.6697247706422018 random_state 624\n",
      "accuracy of the model 0.7339449541284404 random_state 625\n",
      "accuracy of the model 0.6605504587155964 random_state 626\n",
      "accuracy of the model 0.7155963302752294 random_state 627\n",
      "accuracy of the model 0.7431192660550459 random_state 628\n",
      "accuracy of the model 0.6697247706422018 random_state 629\n",
      "accuracy of the model 0.6605504587155964 random_state 630\n",
      "accuracy of the model 0.6972477064220184 random_state 631\n",
      "accuracy of the model 0.6697247706422018 random_state 632\n",
      "accuracy of the model 0.7247706422018348 random_state 633\n",
      "accuracy of the model 0.6605504587155964 random_state 634\n",
      "accuracy of the model 0.6880733944954128 random_state 635\n",
      "accuracy of the model 0.6330275229357798 random_state 636\n",
      "accuracy of the model 0.7064220183486238 random_state 637\n",
      "accuracy of the model 0.8073394495412844 random_state 638\n",
      "accuracy of the model 0.6605504587155964 random_state 639\n",
      "accuracy of the model 0.6330275229357798 random_state 640\n",
      "accuracy of the model 0.7431192660550459 random_state 641\n",
      "accuracy of the model 0.6788990825688074 random_state 642\n",
      "accuracy of the model 0.7064220183486238 random_state 643\n",
      "accuracy of the model 0.7339449541284404 random_state 644\n",
      "accuracy of the model 0.6146788990825688 random_state 645\n",
      "accuracy of the model 0.7247706422018348 random_state 646\n",
      "accuracy of the model 0.6880733944954128 random_state 647\n",
      "accuracy of the model 0.6697247706422018 random_state 648\n",
      "accuracy of the model 0.7522935779816514 random_state 649\n",
      "accuracy of the model 0.7064220183486238 random_state 650\n",
      "accuracy of the model 0.6880733944954128 random_state 651\n",
      "accuracy of the model 0.6697247706422018 random_state 652\n",
      "accuracy of the model 0.7155963302752294 random_state 653\n",
      "accuracy of the model 0.7064220183486238 random_state 654\n",
      "accuracy of the model 0.7247706422018348 random_state 655\n",
      "accuracy of the model 0.6880733944954128 random_state 656\n",
      "accuracy of the model 0.7155963302752294 random_state 657\n",
      "accuracy of the model 0.6880733944954128 random_state 658\n",
      "accuracy of the model 0.6238532110091743 random_state 659\n",
      "accuracy of the model 0.6697247706422018 random_state 660\n",
      "accuracy of the model 0.7522935779816514 random_state 661\n",
      "accuracy of the model 0.7706422018348624 random_state 662\n",
      "accuracy of the model 0.7339449541284404 random_state 663\n",
      "accuracy of the model 0.7706422018348624 random_state 664\n",
      "accuracy of the model 0.7247706422018348 random_state 665\n",
      "accuracy of the model 0.6880733944954128 random_state 666\n",
      "accuracy of the model 0.7064220183486238 random_state 667\n",
      "accuracy of the model 0.6880733944954128 random_state 668\n",
      "accuracy of the model 0.7431192660550459 random_state 669\n",
      "accuracy of the model 0.6697247706422018 random_state 670\n",
      "accuracy of the model 0.7247706422018348 random_state 671\n",
      "accuracy of the model 0.6972477064220184 random_state 672\n",
      "accuracy of the model 0.6422018348623854 random_state 673\n",
      "accuracy of the model 0.7155963302752294 random_state 674\n",
      "accuracy of the model 0.7339449541284404 random_state 675\n",
      "accuracy of the model 0.6788990825688074 random_state 676\n",
      "accuracy of the model 0.7064220183486238 random_state 677\n",
      "accuracy of the model 0.6880733944954128 random_state 678\n",
      "accuracy of the model 0.7614678899082569 random_state 679\n",
      "accuracy of the model 0.6146788990825688 random_state 680\n",
      "accuracy of the model 0.7522935779816514 random_state 681\n",
      "accuracy of the model 0.7614678899082569 random_state 682\n",
      "accuracy of the model 0.6880733944954128 random_state 683\n",
      "accuracy of the model 0.6788990825688074 random_state 684\n",
      "accuracy of the model 0.5779816513761468 random_state 685\n",
      "accuracy of the model 0.7431192660550459 random_state 686\n",
      "accuracy of the model 0.6788990825688074 random_state 687\n",
      "accuracy of the model 0.7614678899082569 random_state 688\n",
      "accuracy of the model 0.6788990825688074 random_state 689\n",
      "accuracy of the model 0.7064220183486238 random_state 690\n",
      "accuracy of the model 0.6972477064220184 random_state 691\n",
      "accuracy of the model 0.7155963302752294 random_state 692\n",
      "accuracy of the model 0.6788990825688074 random_state 693\n",
      "accuracy of the model 0.6605504587155964 random_state 694\n",
      "accuracy of the model 0.6697247706422018 random_state 695\n",
      "accuracy of the model 0.6513761467889908 random_state 696\n",
      "accuracy of the model 0.6697247706422018 random_state 697\n",
      "accuracy of the model 0.7614678899082569 random_state 698\n",
      "accuracy of the model 0.7339449541284404 random_state 699\n",
      "accuracy of the model 0.7431192660550459 random_state 700\n",
      "accuracy of the model 0.6972477064220184 random_state 701\n",
      "accuracy of the model 0.7981651376146789 random_state 702\n",
      "accuracy of the model 0.7247706422018348 random_state 703\n",
      "accuracy of the model 0.7798165137614679 random_state 704\n",
      "accuracy of the model 0.6697247706422018 random_state 705\n",
      "accuracy of the model 0.6972477064220184 random_state 706\n",
      "accuracy of the model 0.6697247706422018 random_state 707\n",
      "accuracy of the model 0.7522935779816514 random_state 708\n",
      "accuracy of the model 0.6697247706422018 random_state 709\n",
      "accuracy of the model 0.6788990825688074 random_state 710\n",
      "accuracy of the model 0.7522935779816514 random_state 711\n",
      "accuracy of the model 0.7247706422018348 random_state 712\n",
      "accuracy of the model 0.7431192660550459 random_state 713\n",
      "accuracy of the model 0.7247706422018348 random_state 714\n",
      "accuracy of the model 0.7247706422018348 random_state 715\n",
      "accuracy of the model 0.6972477064220184 random_state 716\n",
      "accuracy of the model 0.6697247706422018 random_state 717\n",
      "accuracy of the model 0.7155963302752294 random_state 718\n",
      "accuracy of the model 0.6605504587155964 random_state 719\n",
      "accuracy of the model 0.5963302752293578 random_state 720\n",
      "accuracy of the model 0.7064220183486238 random_state 721\n",
      "accuracy of the model 0.7889908256880734 random_state 722\n",
      "accuracy of the model 0.6605504587155964 random_state 723\n",
      "accuracy of the model 0.6880733944954128 random_state 724\n",
      "accuracy of the model 0.6330275229357798 random_state 725\n",
      "accuracy of the model 0.7614678899082569 random_state 726\n",
      "accuracy of the model 0.6972477064220184 random_state 727\n",
      "accuracy of the model 0.6146788990825688 random_state 728\n",
      "accuracy of the model 0.6788990825688074 random_state 729\n",
      "accuracy of the model 0.7064220183486238 random_state 730\n",
      "accuracy of the model 0.7064220183486238 random_state 731\n",
      "accuracy of the model 0.7522935779816514 random_state 732\n",
      "accuracy of the model 0.7339449541284404 random_state 733\n",
      "accuracy of the model 0.6422018348623854 random_state 734\n",
      "accuracy of the model 0.6697247706422018 random_state 735\n",
      "accuracy of the model 0.7064220183486238 random_state 736\n",
      "accuracy of the model 0.7339449541284404 random_state 737\n",
      "accuracy of the model 0.7522935779816514 random_state 738\n",
      "accuracy of the model 0.7522935779816514 random_state 739\n",
      "accuracy of the model 0.6972477064220184 random_state 740\n",
      "accuracy of the model 0.6972477064220184 random_state 741\n",
      "accuracy of the model 0.7247706422018348 random_state 742\n",
      "accuracy of the model 0.7798165137614679 random_state 743\n",
      "accuracy of the model 0.7706422018348624 random_state 744\n",
      "accuracy of the model 0.6422018348623854 random_state 745\n",
      "accuracy of the model 0.6513761467889908 random_state 746\n",
      "accuracy of the model 0.7339449541284404 random_state 747\n",
      "accuracy of the model 0.6788990825688074 random_state 748\n",
      "accuracy of the model 0.7064220183486238 random_state 749\n",
      "accuracy of the model 0.7064220183486238 random_state 750\n",
      "accuracy of the model 0.6880733944954128 random_state 751\n",
      "accuracy of the model 0.7155963302752294 random_state 752\n",
      "accuracy of the model 0.6605504587155964 random_state 753\n",
      "accuracy of the model 0.6605504587155964 random_state 754\n",
      "accuracy of the model 0.6697247706422018 random_state 755\n",
      "accuracy of the model 0.7614678899082569 random_state 756\n",
      "accuracy of the model 0.7706422018348624 random_state 757\n",
      "accuracy of the model 0.7064220183486238 random_state 758\n",
      "accuracy of the model 0.7155963302752294 random_state 759\n",
      "accuracy of the model 0.7155963302752294 random_state 760\n",
      "accuracy of the model 0.7247706422018348 random_state 761\n",
      "accuracy of the model 0.7155963302752294 random_state 762\n",
      "accuracy of the model 0.7064220183486238 random_state 763\n",
      "accuracy of the model 0.7247706422018348 random_state 764\n",
      "accuracy of the model 0.6697247706422018 random_state 765\n",
      "accuracy of the model 0.7522935779816514 random_state 766\n",
      "accuracy of the model 0.6605504587155964 random_state 767\n",
      "accuracy of the model 0.6330275229357798 random_state 768\n",
      "accuracy of the model 0.7614678899082569 random_state 769\n",
      "accuracy of the model 0.7431192660550459 random_state 770\n",
      "accuracy of the model 0.6330275229357798 random_state 771\n",
      "accuracy of the model 0.7431192660550459 random_state 772\n",
      "accuracy of the model 0.7706422018348624 random_state 773\n",
      "accuracy of the model 0.6880733944954128 random_state 774\n",
      "accuracy of the model 0.7155963302752294 random_state 775\n",
      "accuracy of the model 0.6697247706422018 random_state 776\n",
      "accuracy of the model 0.7247706422018348 random_state 777\n",
      "accuracy of the model 0.7155963302752294 random_state 778\n",
      "accuracy of the model 0.7339449541284404 random_state 779\n",
      "accuracy of the model 0.7706422018348624 random_state 780\n",
      "accuracy of the model 0.6146788990825688 random_state 781\n",
      "accuracy of the model 0.6972477064220184 random_state 782\n",
      "accuracy of the model 0.6972477064220184 random_state 783\n",
      "accuracy of the model 0.6880733944954128 random_state 784\n",
      "accuracy of the model 0.6972477064220184 random_state 785\n",
      "accuracy of the model 0.6238532110091743 random_state 786\n",
      "accuracy of the model 0.6880733944954128 random_state 787\n",
      "accuracy of the model 0.7247706422018348 random_state 788\n",
      "accuracy of the model 0.7064220183486238 random_state 789\n",
      "accuracy of the model 0.6697247706422018 random_state 790\n",
      "accuracy of the model 0.7798165137614679 random_state 791\n",
      "accuracy of the model 0.6697247706422018 random_state 792\n",
      "accuracy of the model 0.6880733944954128 random_state 793\n",
      "accuracy of the model 0.6880733944954128 random_state 794\n",
      "accuracy of the model 0.6972477064220184 random_state 795\n",
      "accuracy of the model 0.6972477064220184 random_state 796\n",
      "accuracy of the model 0.7706422018348624 random_state 797\n",
      "accuracy of the model 0.6880733944954128 random_state 798\n",
      "accuracy of the model 0.6972477064220184 random_state 799\n",
      "accuracy of the model 0.7431192660550459 random_state 800\n",
      "accuracy of the model 0.6972477064220184 random_state 801\n",
      "accuracy of the model 0.7431192660550459 random_state 802\n",
      "accuracy of the model 0.6972477064220184 random_state 803\n",
      "accuracy of the model 0.6972477064220184 random_state 804\n",
      "accuracy of the model 0.6972477064220184 random_state 805\n",
      "accuracy of the model 0.5688073394495413 random_state 806\n",
      "accuracy of the model 0.7155963302752294 random_state 807\n",
      "accuracy of the model 0.7155963302752294 random_state 808\n",
      "accuracy of the model 0.6605504587155964 random_state 809\n",
      "accuracy of the model 0.7339449541284404 random_state 810\n",
      "accuracy of the model 0.6146788990825688 random_state 811\n",
      "accuracy of the model 0.7339449541284404 random_state 812\n",
      "accuracy of the model 0.7798165137614679 random_state 813\n",
      "accuracy of the model 0.7889908256880734 random_state 814\n",
      "accuracy of the model 0.7155963302752294 random_state 815\n",
      "accuracy of the model 0.6513761467889908 random_state 816\n",
      "accuracy of the model 0.6972477064220184 random_state 817\n",
      "accuracy of the model 0.6788990825688074 random_state 818\n",
      "accuracy of the model 0.6880733944954128 random_state 819\n",
      "accuracy of the model 0.6422018348623854 random_state 820\n",
      "accuracy of the model 0.7064220183486238 random_state 821\n",
      "accuracy of the model 0.6697247706422018 random_state 822\n",
      "accuracy of the model 0.6605504587155964 random_state 823\n",
      "accuracy of the model 0.6697247706422018 random_state 824\n",
      "accuracy of the model 0.7798165137614679 random_state 825\n",
      "accuracy of the model 0.6605504587155964 random_state 826\n",
      "accuracy of the model 0.6880733944954128 random_state 827\n",
      "accuracy of the model 0.8073394495412844 random_state 828\n",
      "accuracy of the model 0.7798165137614679 random_state 829\n",
      "accuracy of the model 0.6697247706422018 random_state 830\n",
      "accuracy of the model 0.6972477064220184 random_state 831\n",
      "accuracy of the model 0.6330275229357798 random_state 832\n",
      "accuracy of the model 0.7339449541284404 random_state 833\n",
      "accuracy of the model 0.6605504587155964 random_state 834\n",
      "accuracy of the model 0.6605504587155964 random_state 835\n",
      "accuracy of the model 0.6880733944954128 random_state 836\n",
      "accuracy of the model 0.6788990825688074 random_state 837\n",
      "accuracy of the model 0.6972477064220184 random_state 838\n",
      "accuracy of the model 0.6788990825688074 random_state 839\n",
      "accuracy of the model 0.6697247706422018 random_state 840\n",
      "accuracy of the model 0.6422018348623854 random_state 841\n",
      "accuracy of the model 0.6513761467889908 random_state 842\n",
      "accuracy of the model 0.7064220183486238 random_state 843\n",
      "accuracy of the model 0.7339449541284404 random_state 844\n",
      "accuracy of the model 0.6605504587155964 random_state 845\n",
      "accuracy of the model 0.7247706422018348 random_state 846\n",
      "accuracy of the model 0.7339449541284404 random_state 847\n",
      "accuracy of the model 0.6788990825688074 random_state 848\n",
      "accuracy of the model 0.6697247706422018 random_state 849\n",
      "accuracy of the model 0.7431192660550459 random_state 850\n",
      "accuracy of the model 0.6972477064220184 random_state 851\n",
      "accuracy of the model 0.6238532110091743 random_state 852\n",
      "accuracy of the model 0.6146788990825688 random_state 853\n",
      "accuracy of the model 0.6788990825688074 random_state 854\n",
      "accuracy of the model 0.6697247706422018 random_state 855\n",
      "accuracy of the model 0.7155963302752294 random_state 856\n",
      "accuracy of the model 0.7064220183486238 random_state 857\n",
      "accuracy of the model 0.7339449541284404 random_state 858\n",
      "accuracy of the model 0.6972477064220184 random_state 859\n",
      "accuracy of the model 0.7155963302752294 random_state 860\n",
      "accuracy of the model 0.6972477064220184 random_state 861\n",
      "accuracy of the model 0.7064220183486238 random_state 862\n",
      "accuracy of the model 0.7247706422018348 random_state 863\n",
      "accuracy of the model 0.7339449541284404 random_state 864\n",
      "accuracy of the model 0.6697247706422018 random_state 865\n",
      "accuracy of the model 0.7522935779816514 random_state 866\n",
      "accuracy of the model 0.6880733944954128 random_state 867\n",
      "accuracy of the model 0.7064220183486238 random_state 868\n",
      "accuracy of the model 0.6146788990825688 random_state 869\n",
      "accuracy of the model 0.7798165137614679 random_state 870\n",
      "accuracy of the model 0.7064220183486238 random_state 871\n",
      "accuracy of the model 0.6697247706422018 random_state 872\n",
      "accuracy of the model 0.7339449541284404 random_state 873\n",
      "accuracy of the model 0.7155963302752294 random_state 874\n",
      "accuracy of the model 0.7522935779816514 random_state 875\n",
      "accuracy of the model 0.7798165137614679 random_state 876\n",
      "accuracy of the model 0.7064220183486238 random_state 877\n",
      "accuracy of the model 0.7247706422018348 random_state 878\n",
      "accuracy of the model 0.6422018348623854 random_state 879\n",
      "accuracy of the model 0.7522935779816514 random_state 880\n",
      "accuracy of the model 0.7614678899082569 random_state 881\n",
      "accuracy of the model 0.7064220183486238 random_state 882\n",
      "accuracy of the model 0.7339449541284404 random_state 883\n",
      "accuracy of the model 0.7339449541284404 random_state 884\n",
      "accuracy of the model 0.7155963302752294 random_state 885\n",
      "accuracy of the model 0.6697247706422018 random_state 886\n",
      "accuracy of the model 0.7155963302752294 random_state 887\n",
      "accuracy of the model 0.7155963302752294 random_state 888\n",
      "accuracy of the model 0.6880733944954128 random_state 889\n",
      "accuracy of the model 0.6972477064220184 random_state 890\n",
      "accuracy of the model 0.6880733944954128 random_state 891\n",
      "accuracy of the model 0.7155963302752294 random_state 892\n",
      "accuracy of the model 0.6330275229357798 random_state 893\n",
      "accuracy of the model 0.7431192660550459 random_state 894\n",
      "accuracy of the model 0.7522935779816514 random_state 895\n",
      "accuracy of the model 0.6330275229357798 random_state 896\n",
      "accuracy of the model 0.7339449541284404 random_state 897\n",
      "accuracy of the model 0.6422018348623854 random_state 898\n",
      "accuracy of the model 0.7614678899082569 random_state 899\n",
      "accuracy of the model 0.7339449541284404 random_state 900\n",
      "accuracy of the model 0.6330275229357798 random_state 901\n",
      "accuracy of the model 0.7155963302752294 random_state 902\n",
      "accuracy of the model 0.7339449541284404 random_state 903\n",
      "accuracy of the model 0.7706422018348624 random_state 904\n",
      "accuracy of the model 0.6880733944954128 random_state 905\n",
      "accuracy of the model 0.7798165137614679 random_state 906\n",
      "accuracy of the model 0.6880733944954128 random_state 907\n",
      "accuracy of the model 0.7155963302752294 random_state 908\n",
      "accuracy of the model 0.7155963302752294 random_state 909\n",
      "accuracy of the model 0.6880733944954128 random_state 910\n",
      "accuracy of the model 0.6605504587155964 random_state 911\n",
      "accuracy of the model 0.6788990825688074 random_state 912\n",
      "accuracy of the model 0.6422018348623854 random_state 913\n",
      "accuracy of the model 0.6055045871559633 random_state 914\n",
      "accuracy of the model 0.7431192660550459 random_state 915\n",
      "accuracy of the model 0.6697247706422018 random_state 916\n",
      "accuracy of the model 0.7155963302752294 random_state 917\n",
      "accuracy of the model 0.6605504587155964 random_state 918\n",
      "accuracy of the model 0.7339449541284404 random_state 919\n",
      "accuracy of the model 0.7522935779816514 random_state 920\n",
      "accuracy of the model 0.6605504587155964 random_state 921\n",
      "accuracy of the model 0.7339449541284404 random_state 922\n",
      "accuracy of the model 0.6697247706422018 random_state 923\n",
      "accuracy of the model 0.7431192660550459 random_state 924\n",
      "accuracy of the model 0.7064220183486238 random_state 925\n",
      "accuracy of the model 0.7339449541284404 random_state 926\n",
      "accuracy of the model 0.6605504587155964 random_state 927\n",
      "accuracy of the model 0.7614678899082569 random_state 928\n",
      "accuracy of the model 0.7706422018348624 random_state 929\n",
      "accuracy of the model 0.7064220183486238 random_state 930\n",
      "accuracy of the model 0.6513761467889908 random_state 931\n",
      "accuracy of the model 0.6972477064220184 random_state 932\n",
      "accuracy of the model 0.6422018348623854 random_state 933\n",
      "accuracy of the model 0.6697247706422018 random_state 934\n",
      "accuracy of the model 0.6880733944954128 random_state 935\n",
      "accuracy of the model 0.7339449541284404 random_state 936\n",
      "accuracy of the model 0.6422018348623854 random_state 937\n",
      "accuracy of the model 0.7431192660550459 random_state 938\n",
      "accuracy of the model 0.8256880733944955 random_state 939\n",
      "accuracy of the optimum model 0.8256880733944955 random_state 939\n",
      "accuracy of the model 0.6605504587155964 random_state 940\n",
      "accuracy of the model 0.6788990825688074 random_state 941\n",
      "accuracy of the model 0.7247706422018348 random_state 942\n",
      "accuracy of the model 0.7706422018348624 random_state 943\n",
      "accuracy of the model 0.6055045871559633 random_state 944\n",
      "accuracy of the model 0.6513761467889908 random_state 945\n",
      "accuracy of the model 0.6605504587155964 random_state 946\n",
      "accuracy of the model 0.7247706422018348 random_state 947\n",
      "accuracy of the model 0.6880733944954128 random_state 948\n",
      "accuracy of the model 0.6788990825688074 random_state 949\n",
      "accuracy of the model 0.7064220183486238 random_state 950\n",
      "accuracy of the model 0.6880733944954128 random_state 951\n",
      "accuracy of the model 0.6788990825688074 random_state 952\n",
      "accuracy of the model 0.6880733944954128 random_state 953\n",
      "accuracy of the model 0.6605504587155964 random_state 954\n",
      "accuracy of the model 0.6605504587155964 random_state 955\n",
      "accuracy of the model 0.6146788990825688 random_state 956\n",
      "accuracy of the model 0.7064220183486238 random_state 957\n",
      "accuracy of the model 0.7431192660550459 random_state 958\n",
      "accuracy of the model 0.7247706422018348 random_state 959\n",
      "accuracy of the model 0.6972477064220184 random_state 960\n",
      "accuracy of the model 0.6513761467889908 random_state 961\n",
      "accuracy of the model 0.5596330275229358 random_state 962\n",
      "accuracy of the model 0.6330275229357798 random_state 963\n",
      "accuracy of the model 0.7064220183486238 random_state 964\n",
      "accuracy of the model 0.6880733944954128 random_state 965\n",
      "accuracy of the model 0.7064220183486238 random_state 966\n",
      "accuracy of the model 0.6513761467889908 random_state 967\n",
      "accuracy of the model 0.6788990825688074 random_state 968\n",
      "accuracy of the model 0.7339449541284404 random_state 969\n",
      "accuracy of the model 0.7431192660550459 random_state 970\n",
      "accuracy of the model 0.7247706422018348 random_state 971\n",
      "accuracy of the model 0.7339449541284404 random_state 972\n",
      "accuracy of the model 0.6513761467889908 random_state 973\n",
      "accuracy of the model 0.6880733944954128 random_state 974\n",
      "accuracy of the model 0.6880733944954128 random_state 975\n",
      "accuracy of the model 0.6513761467889908 random_state 976\n",
      "accuracy of the model 0.6788990825688074 random_state 977\n",
      "accuracy of the model 0.7155963302752294 random_state 978\n",
      "accuracy of the model 0.6605504587155964 random_state 979\n",
      "accuracy of the model 0.6788990825688074 random_state 980\n",
      "accuracy of the model 0.6330275229357798 random_state 981\n",
      "accuracy of the model 0.7339449541284404 random_state 982\n",
      "accuracy of the model 0.7247706422018348 random_state 983\n",
      "accuracy of the model 0.7522935779816514 random_state 984\n",
      "accuracy of the model 0.6238532110091743 random_state 985\n",
      "accuracy of the model 0.6330275229357798 random_state 986\n",
      "accuracy of the model 0.7064220183486238 random_state 987\n",
      "accuracy of the model 0.6788990825688074 random_state 988\n",
      "accuracy of the model 0.6788990825688074 random_state 989\n",
      "accuracy of the model 0.8165137614678899 random_state 990\n",
      "accuracy of the model 0.6880733944954128 random_state 991\n",
      "accuracy of the model 0.6880733944954128 random_state 992\n",
      "accuracy of the model 0.6880733944954128 random_state 993\n",
      "accuracy of the model 0.6697247706422018 random_state 994\n",
      "accuracy of the model 0.7247706422018348 random_state 995\n",
      "accuracy of the model 0.7247706422018348 random_state 996\n",
      "accuracy of the model 0.7339449541284404 random_state 997\n",
      "accuracy of the model 0.6697247706422018 random_state 998\n",
      "accuracy of the model 0.7247706422018348 random_state 999\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,1000):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    de=DecisionTreeClassifier()\n",
    "    de.fit(x_train, y_train)\n",
    "    pred=de.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95a17f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8256880733944955 in random state 939\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da40fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 1\n",
      "accuracy of the optimum model 0.7155963302752294 random_state 1\n",
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 2\n",
      "accuracy of the optimum model 0.7247706422018348 random_state 2\n",
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 3\n",
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 4\n",
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 5\n",
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 6\n",
      "accuracy of the optimum model 0.7889908256880734 random_state 6\n",
      "[19:51:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 7\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 8\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 9\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 10\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 11\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 12\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 13\n",
      "[19:51:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 14\n",
      "[19:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 15\n",
      "[19:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 16\n",
      "[19:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 17\n",
      "[19:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 18\n",
      "[19:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 19\n",
      "[19:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 20\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 21\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 22\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 23\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 24\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 25\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 26\n",
      "[19:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 27\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 28\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 29\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 30\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 31\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 32\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 33\n",
      "[19:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 34\n",
      "[19:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 35\n",
      "[19:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 36\n",
      "[19:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 37\n",
      "[19:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 38\n",
      "[19:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 39\n",
      "[19:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 40\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 41\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 42\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 43\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 44\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 45\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 46\n",
      "[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 47\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 48\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 49\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 50\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 51\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 52\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 53\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 54\n",
      "[19:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 55\n",
      "[19:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 56\n",
      "[19:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 57\n",
      "[19:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 58\n",
      "[19:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 59\n",
      "[19:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 60\n",
      "[19:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 61\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 62\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 63\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 64\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 65\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 66\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 67\n",
      "[19:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 68\n",
      "[19:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 69\n",
      "[19:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 70\n",
      "[19:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 71\n",
      "[19:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 72\n",
      "[19:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 73\n",
      "[19:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 74\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 75\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 76\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 77\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 78\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 79\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 80\n",
      "[19:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 81\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 82\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 83\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 84\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 85\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 86\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 87\n",
      "[19:51:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 88\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 89\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 90\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 91\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 92\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 93\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 94\n",
      "[19:51:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 95\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 96\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 97\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 98\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 99\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 100\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 101\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 102\n",
      "[19:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 103\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 104\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 105\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 106\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 107\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 108\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 109\n",
      "[19:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 110\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 111\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 112\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 113\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 114\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 115\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 116\n",
      "[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6146788990825688 random_state 117\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 118\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 119\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 120\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 121\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 122\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 123\n",
      "[19:51:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 124\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 125\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 126\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 127\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.8073394495412844 random_state 128\n",
      "accuracy of the optimum model 0.8073394495412844 random_state 128\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 129\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 130\n",
      "[19:51:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 131\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 132\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 133\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 134\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 135\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 136\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 137\n",
      "[19:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 138\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 139\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 140\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 141\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 142\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 143\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 144\n",
      "[19:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 145\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 146\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 147\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 148\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 149\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 150\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 151\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 152\n",
      "[19:51:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 153\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 154\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 155\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 156\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 157\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 158\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 159\n",
      "[19:51:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 160\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 161\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 162\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 163\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 164\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 165\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 166\n",
      "[19:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 167\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 168\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 169\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 170\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 171\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 172\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 173\n",
      "[19:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 174\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 175\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 176\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 177\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 178\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 179\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 180\n",
      "[19:51:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 181\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 182\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 183\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 184\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 185\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 186\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 187\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 188\n",
      "[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 189\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 190\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 191\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 192\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 193\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 194\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 195\n",
      "[19:51:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 196\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 197\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 198\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 199\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 200\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 201\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 202\n",
      "[19:51:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 203\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 204\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 205\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 206\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 207\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 208\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 209\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 210\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 211\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 212\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 213\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 214\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 215\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 216\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 217\n",
      "[19:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 218\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 219\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 220\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 221\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 222\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 223\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 224\n",
      "[19:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 225\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 226\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 227\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 228\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 229\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 230\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 231\n",
      "[19:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 232\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 233\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 234\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 235\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 236\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 237\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 238\n",
      "[19:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 239\n",
      "[19:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 240\n",
      "[19:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.8073394495412844 random_state 241\n",
      "[19:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6146788990825688 random_state 242\n",
      "[19:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 243\n",
      "[19:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 244\n",
      "[19:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 245\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 246\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 247\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 248\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 249\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 250\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 251\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 252\n",
      "[19:51:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 253\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 254\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 255\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 256\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 257\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 258\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 259\n",
      "[19:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 260\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 261\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 262\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 263\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 264\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 265\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 266\n",
      "[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 267\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 268\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 269\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 270\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 271\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 272\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 273\n",
      "[19:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 274\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 275\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 276\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 277\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 278\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 279\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 280\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 281\n",
      "[19:51:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 282\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 283\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 284\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 285\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 286\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 287\n",
      "[19:51:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 288\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 289\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 290\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 291\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 292\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 293\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 294\n",
      "[19:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 295\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 296\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 297\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 298\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 299\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 300\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 301\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 302\n",
      "[19:52:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 303\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 304\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 305\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 306\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 307\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 308\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 309\n",
      "[19:52:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 310\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 311\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 312\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 313\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 314\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 315\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 316\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 317\n",
      "[19:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 318\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 319\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 320\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 321\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 322\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 323\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 324\n",
      "[19:52:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 325\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 326\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 327\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 328\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 329\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 330\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 331\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 332\n",
      "[19:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 333\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 334\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 335\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 336\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 337\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 338\n",
      "[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 339\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 340\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 341\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 342\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 343\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 344\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 345\n",
      "[19:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 346\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 347\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 348\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 349\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 350\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 351\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 352\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 353\n",
      "[19:52:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 354\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 355\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 356\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 357\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 358\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 359\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 360\n",
      "[19:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 361\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 362\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 363\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 364\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 365\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 366\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 367\n",
      "[19:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 368\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 369\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 370\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 371\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 372\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 373\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 374\n",
      "[19:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 375\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 376\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 377\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 378\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 379\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 380\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 381\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 382\n",
      "[19:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 383\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 384\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 385\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 386\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 387\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 388\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 389\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 390\n",
      "[19:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 391\n",
      "[19:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 392\n",
      "[19:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 393\n",
      "[19:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 394\n",
      "[19:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 395\n",
      "[19:52:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 396\n",
      "[19:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 397\n",
      "[19:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 398\n",
      "[19:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 399\n",
      "[19:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 400\n",
      "[19:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 401\n",
      "[19:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 402\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 403\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 404\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 405\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 406\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 407\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6146788990825688 random_state 408\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 409\n",
      "[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 410\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 411\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 412\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 413\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 414\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 415\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 416\n",
      "[19:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 417\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 418\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 419\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 420\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 421\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 422\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 423\n",
      "[19:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 424\n",
      "[19:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 425\n",
      "[19:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 426\n",
      "[19:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 427\n",
      "[19:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 428\n",
      "[19:52:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 429\n",
      "[19:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 430\n",
      "[19:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 431\n",
      "[19:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 432\n",
      "[19:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 433\n",
      "[19:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 434\n",
      "[19:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 435\n",
      "[19:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 436\n",
      "[19:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 437\n",
      "[19:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 438\n",
      "[19:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 439\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 440\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 441\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 442\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 443\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 444\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 445\n",
      "[19:52:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 446\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 447\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 448\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 449\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 450\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 451\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 452\n",
      "[19:52:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 453\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 454\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 455\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 456\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 457\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 458\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 459\n",
      "[19:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 460\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 461\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 462\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 463\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 464\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 465\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 466\n",
      "[19:52:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 467\n",
      "[19:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 468\n",
      "[19:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 469\n",
      "[19:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 470\n",
      "[19:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 471\n",
      "[19:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 472\n",
      "[19:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 473\n",
      "[19:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 474\n",
      "[19:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 475\n",
      "[19:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 476\n",
      "[19:52:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 477\n",
      "[19:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 478\n",
      "[19:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 479\n",
      "[19:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.5963302752293578 random_state 480\n",
      "[19:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 481\n",
      "[19:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 482\n",
      "[19:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 483\n",
      "[19:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 484\n",
      "[19:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 485\n",
      "[19:52:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 486\n",
      "[19:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 487\n",
      "[19:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 488\n",
      "[19:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 489\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 490\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 491\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 492\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 493\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.8165137614678899 random_state 494\n",
      "accuracy of the optimum model 0.8165137614678899 random_state 494\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 495\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 496\n",
      "[19:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 497\n",
      "[19:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 498\n",
      "[19:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 499\n",
      "[19:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 500\n",
      "[19:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 501\n",
      "[19:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 502\n",
      "[19:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 503\n",
      "[19:52:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 504\n",
      "[19:52:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 505\n",
      "[19:52:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 506\n",
      "[19:52:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 507\n",
      "[19:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 508\n",
      "[19:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 509\n",
      "[19:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 510\n",
      "[19:52:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 511\n",
      "[19:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 512\n",
      "[19:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 513\n",
      "[19:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 514\n",
      "[19:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 515\n",
      "[19:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 516\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 517\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 518\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 519\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 520\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 521\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 522\n",
      "[19:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 523\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 524\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 525\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 526\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 527\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 528\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 529\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 530\n",
      "[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 531\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 532\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 533\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 534\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 535\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 536\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 537\n",
      "[19:52:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 538\n",
      "[19:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 539\n",
      "[19:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 540\n",
      "[19:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 541\n",
      "[19:52:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 542\n",
      "[19:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 543\n",
      "[19:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 544\n",
      "[19:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 545\n",
      "[19:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 546\n",
      "[19:52:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 547\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.8073394495412844 random_state 548\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 549\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 550\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 551\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 552\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 553\n",
      "[19:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 554\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 555\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 556\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 557\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 558\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 559\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 560\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 561\n",
      "[19:52:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 562\n",
      "[19:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 563\n",
      "[19:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 564\n",
      "[19:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 565\n",
      "[19:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 566\n",
      "[19:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 567\n",
      "[19:52:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 568\n",
      "[19:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 569\n",
      "[19:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 570\n",
      "[19:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 571\n",
      "[19:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 572\n",
      "[19:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 573\n",
      "[19:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 574\n",
      "[19:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 575\n",
      "[19:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 576\n",
      "[19:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 577\n",
      "[19:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 578\n",
      "[19:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 579\n",
      "[19:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 580\n",
      "[19:52:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 581\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 582\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 583\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 584\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 585\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 586\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 587\n",
      "[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 588\n",
      "[19:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 589\n",
      "[19:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 590\n",
      "[19:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 591\n",
      "[19:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 592\n",
      "[19:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 593\n",
      "[19:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 594\n",
      "[19:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 595\n",
      "[19:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 596\n",
      "[19:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 597\n",
      "[19:52:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 598\n",
      "[19:52:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 599\n",
      "[19:52:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 600\n",
      "[19:52:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 601\n",
      "[19:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 602\n",
      "[19:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 603\n",
      "[19:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 604\n",
      "[19:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 605\n",
      "[19:52:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 606\n",
      "[19:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 607\n",
      "[19:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 608\n",
      "[19:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 609\n",
      "[19:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 610\n",
      "[19:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 611\n",
      "[19:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 612\n",
      "[19:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 613\n",
      "[19:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 614\n",
      "[19:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 615\n",
      "[19:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 616\n",
      "[19:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 617\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 618\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 619\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 620\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 621\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 622\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 623\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 624\n",
      "[19:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 625\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 626\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 627\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 628\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 629\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 630\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 631\n",
      "[19:52:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 632\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 633\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 634\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 635\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 636\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 637\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 638\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 639\n",
      "[19:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 640\n",
      "[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 641\n",
      "[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 642\n",
      "[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 643\n",
      "[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 644\n",
      "[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 645\n",
      "[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 646\n",
      "[19:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 647\n",
      "[19:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 648\n",
      "[19:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.8073394495412844 random_state 649\n",
      "[19:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 650\n",
      "[19:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 651\n",
      "[19:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 652\n",
      "[19:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 653\n",
      "[19:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 654\n",
      "[19:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 655\n",
      "[19:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 656\n",
      "[19:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 657\n",
      "[19:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 658\n",
      "[19:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 659\n",
      "[19:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 660\n",
      "[19:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 661\n",
      "[19:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 662\n",
      "[19:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 663\n",
      "[19:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 664\n",
      "[19:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 665\n",
      "[19:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 666\n",
      "[19:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 667\n",
      "[19:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 668\n",
      "[19:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 669\n",
      "[19:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 670\n",
      "[19:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 671\n",
      "[19:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 672\n",
      "[19:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 673\n",
      "[19:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 674\n",
      "[19:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 675\n",
      "[19:53:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 676\n",
      "[19:53:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 677\n",
      "[19:53:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 678\n",
      "[19:53:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 679\n",
      "[19:53:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 680\n",
      "[19:53:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 681\n",
      "[19:53:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 682\n",
      "[19:53:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 683\n",
      "[19:53:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 684\n",
      "[19:53:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 685\n",
      "[19:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 686\n",
      "[19:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 687\n",
      "[19:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 688\n",
      "[19:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 689\n",
      "[19:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 690\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 691\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 692\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 693\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 694\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 695\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 696\n",
      "[19:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 697\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 698\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 699\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 700\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 701\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 702\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 703\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 704\n",
      "[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 705\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 706\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 707\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 708\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 709\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 710\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 711\n",
      "[19:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 712\n",
      "[19:53:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 713\n",
      "[19:53:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 714\n",
      "[19:53:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 715\n",
      "[19:53:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 716\n",
      "[19:53:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 717\n",
      "[19:53:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 718\n",
      "[19:53:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 719\n",
      "[19:53:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 720\n",
      "[19:53:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 721\n",
      "[19:53:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 722\n",
      "[19:53:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 723\n",
      "[19:53:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 724\n",
      "[19:53:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 725\n",
      "[19:53:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 726\n",
      "[19:53:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 727\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6055045871559633 random_state 728\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 729\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 730\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 731\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 732\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 733\n",
      "[19:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 734\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 735\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 736\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 737\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 738\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 739\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 740\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 741\n",
      "[19:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 742\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 743\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 744\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 745\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 746\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 747\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 748\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 749\n",
      "[19:53:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 750\n",
      "[19:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 751\n",
      "[19:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 752\n",
      "[19:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 753\n",
      "[19:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 754\n",
      "[19:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 755\n",
      "[19:53:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 756\n",
      "[19:53:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 757\n",
      "[19:53:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 758\n",
      "[19:53:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 759\n",
      "[19:53:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 760\n",
      "[19:53:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 761\n",
      "[19:53:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 762\n",
      "[19:53:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 763\n",
      "[19:53:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 764\n",
      "[19:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 765\n",
      "[19:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 766\n",
      "[19:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 767\n",
      "[19:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 768\n",
      "[19:53:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 769\n",
      "[19:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 770\n",
      "[19:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 771\n",
      "[19:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 772\n",
      "[19:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 773\n",
      "[19:53:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 774\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 775\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 776\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 777\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 778\n",
      "[19:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 779\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 780\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 781\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 782\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 783\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 784\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 785\n",
      "[19:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 786\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 787\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 788\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 789\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 790\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 791\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 792\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 793\n",
      "[19:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 794\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 795\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 796\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 797\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 798\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 799\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 800\n",
      "[19:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 801\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 802\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 803\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 804\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 805\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 806\n",
      "[19:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 807\n",
      "[19:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 808\n",
      "[19:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 809\n",
      "[19:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 810\n",
      "[19:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 811\n",
      "[19:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 812\n",
      "[19:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 813\n",
      "[19:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 814\n",
      "[19:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 815\n",
      "[19:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 816\n",
      "[19:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 817\n",
      "[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 818\n",
      "[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 819\n",
      "[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 820\n",
      "[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 821\n",
      "[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 822\n",
      "[19:53:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 823\n",
      "[19:53:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 824\n",
      "[19:53:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 825\n",
      "[19:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 826\n",
      "[19:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 827\n",
      "[19:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 828\n",
      "[19:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 829\n",
      "[19:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 830\n",
      "[19:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 831\n",
      "[19:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 832\n",
      "[19:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 833\n",
      "[19:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 834\n",
      "[19:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 835\n",
      "[19:53:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 836\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 837\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 838\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 839\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 840\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 841\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 842\n",
      "[19:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 843\n",
      "[19:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 844\n",
      "[19:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 845\n",
      "[19:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 846\n",
      "[19:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 847\n",
      "[19:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 848\n",
      "[19:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7981651376146789 random_state 849\n",
      "[19:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 850\n",
      "[19:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 851\n",
      "[19:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 852\n",
      "[19:53:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 853\n",
      "[19:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 854\n",
      "[19:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 855\n",
      "[19:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 856\n",
      "[19:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 857\n",
      "[19:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.8073394495412844 random_state 858\n",
      "[19:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 859\n",
      "[19:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 860\n",
      "[19:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 861\n",
      "[19:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 862\n",
      "[19:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 863\n",
      "[19:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 864\n",
      "[19:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 865\n",
      "[19:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 866\n",
      "[19:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 867\n",
      "[19:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 868\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6146788990825688 random_state 869\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 870\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 871\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 872\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 873\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 874\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 875\n",
      "[19:53:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 876\n",
      "[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 877\n",
      "[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 878\n",
      "[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 879\n",
      "[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 880\n",
      "[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 881\n",
      "[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 882\n",
      "[19:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 883\n",
      "[19:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 884\n",
      "[19:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 885\n",
      "[19:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 886\n",
      "[19:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 887\n",
      "[19:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 888\n",
      "[19:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 889\n",
      "[19:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 890\n",
      "[19:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 891\n",
      "[19:53:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 892\n",
      "[19:53:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 893\n",
      "[19:53:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 894\n",
      "[19:53:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 895\n",
      "[19:53:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 896\n",
      "[19:53:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 897\n",
      "[19:53:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 898\n",
      "[19:53:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 899\n",
      "[19:53:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 900\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 901\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 902\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 903\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 904\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 905\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 906\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 907\n",
      "[19:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 908\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 909\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 910\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 911\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 912\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 913\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 914\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 915\n",
      "[19:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 916\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 917\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 918\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 919\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 920\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 921\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 922\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 923\n",
      "[19:53:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 924\n",
      "[19:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 925\n",
      "[19:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 926\n",
      "[19:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 927\n",
      "[19:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 928\n",
      "[19:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 929\n",
      "[19:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 930\n",
      "[19:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 931\n",
      "[19:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 932\n",
      "[19:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 933\n",
      "[19:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 934\n",
      "[19:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 935\n",
      "[19:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 936\n",
      "[19:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 937\n",
      "[19:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 938\n",
      "[19:53:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 939\n",
      "[19:53:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 940\n",
      "[19:53:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 941\n",
      "[19:53:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6697247706422018 random_state 942\n",
      "[19:53:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 943\n",
      "[19:53:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 944\n",
      "[19:53:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 945\n",
      "[19:53:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 946\n",
      "[19:53:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 947\n",
      "[19:53:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 948\n",
      "[19:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 949\n",
      "[19:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 950\n",
      "[19:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 951\n",
      "[19:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 952\n",
      "[19:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 953\n",
      "[19:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 954\n",
      "[19:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 955\n",
      "[19:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 956\n",
      "[19:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 957\n",
      "[19:53:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 958\n",
      "[19:53:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 959\n",
      "[19:53:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 960\n",
      "[19:53:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 961\n",
      "[19:53:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 962\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6330275229357798 random_state 963\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 964\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 965\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 966\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 967\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 968\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 969\n",
      "[19:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 970\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 971\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 972\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6788990825688074 random_state 973\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6605504587155964 random_state 974\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 975\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 976\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 977\n",
      "[19:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6238532110091743 random_state 978\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6422018348623854 random_state 979\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 980\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 981\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 982\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 983\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.5871559633027523 random_state 984\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 985\n",
      "[19:53:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7064220183486238 random_state 986\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 987\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7431192660550459 random_state 988\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 989\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7247706422018348 random_state 990\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7614678899082569 random_state 991\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7522935779816514 random_state 992\n",
      "[19:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6513761467889908 random_state 993\n",
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6972477064220184 random_state 994\n",
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.6880733944954128 random_state 995\n",
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7798165137614679 random_state 996\n",
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7339449541284404 random_state 997\n",
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7706422018348624 random_state 998\n",
      "[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7155963302752294 random_state 999\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,1000):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    xe=XGBRFClassifier()\n",
    "    xe.fit(x_train, y_train)\n",
    "    pred=xe.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5f97b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8165137614678899 in random state 494\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ed6f283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.6697247706422018 random_state 1\n",
      "accuracy of the optimum model 0.6697247706422018 random_state 1\n",
      "accuracy of the model 0.6422018348623854 random_state 2\n",
      "accuracy of the model 0.7247706422018348 random_state 3\n",
      "accuracy of the optimum model 0.7247706422018348 random_state 3\n",
      "accuracy of the model 0.6605504587155964 random_state 4\n",
      "accuracy of the model 0.6880733944954128 random_state 5\n",
      "accuracy of the model 0.7339449541284404 random_state 6\n",
      "accuracy of the optimum model 0.7339449541284404 random_state 6\n",
      "accuracy of the model 0.6880733944954128 random_state 7\n",
      "accuracy of the model 0.7247706422018348 random_state 8\n",
      "accuracy of the model 0.6513761467889908 random_state 9\n",
      "accuracy of the model 0.6605504587155964 random_state 10\n",
      "accuracy of the model 0.6330275229357798 random_state 11\n",
      "accuracy of the model 0.6697247706422018 random_state 12\n",
      "accuracy of the model 0.6605504587155964 random_state 13\n",
      "accuracy of the model 0.6513761467889908 random_state 14\n",
      "accuracy of the model 0.7064220183486238 random_state 15\n",
      "accuracy of the model 0.6238532110091743 random_state 16\n",
      "accuracy of the model 0.6513761467889908 random_state 17\n",
      "accuracy of the model 0.6880733944954128 random_state 18\n",
      "accuracy of the model 0.6788990825688074 random_state 19\n",
      "accuracy of the model 0.7431192660550459 random_state 20\n",
      "accuracy of the optimum model 0.7431192660550459 random_state 20\n",
      "accuracy of the model 0.7431192660550459 random_state 21\n",
      "accuracy of the model 0.7247706422018348 random_state 22\n",
      "accuracy of the model 0.6972477064220184 random_state 23\n",
      "accuracy of the model 0.7247706422018348 random_state 24\n",
      "accuracy of the model 0.6972477064220184 random_state 25\n",
      "accuracy of the model 0.6513761467889908 random_state 26\n",
      "accuracy of the model 0.6972477064220184 random_state 27\n",
      "accuracy of the model 0.6788990825688074 random_state 28\n",
      "accuracy of the model 0.7522935779816514 random_state 29\n",
      "accuracy of the optimum model 0.7522935779816514 random_state 29\n",
      "accuracy of the model 0.6788990825688074 random_state 30\n",
      "accuracy of the model 0.6330275229357798 random_state 31\n",
      "accuracy of the model 0.7247706422018348 random_state 32\n",
      "accuracy of the model 0.6972477064220184 random_state 33\n",
      "accuracy of the model 0.7798165137614679 random_state 34\n",
      "accuracy of the optimum model 0.7798165137614679 random_state 34\n",
      "accuracy of the model 0.6238532110091743 random_state 35\n",
      "accuracy of the model 0.6880733944954128 random_state 36\n",
      "accuracy of the model 0.6422018348623854 random_state 37\n",
      "accuracy of the model 0.6880733944954128 random_state 38\n",
      "accuracy of the model 0.6880733944954128 random_state 39\n",
      "accuracy of the model 0.6238532110091743 random_state 40\n",
      "accuracy of the model 0.6330275229357798 random_state 41\n",
      "accuracy of the model 0.6972477064220184 random_state 42\n",
      "accuracy of the model 0.7064220183486238 random_state 43\n",
      "accuracy of the model 0.6697247706422018 random_state 44\n",
      "accuracy of the model 0.6238532110091743 random_state 45\n",
      "accuracy of the model 0.6146788990825688 random_state 46\n",
      "accuracy of the model 0.7064220183486238 random_state 47\n",
      "accuracy of the model 0.7064220183486238 random_state 48\n",
      "accuracy of the model 0.7247706422018348 random_state 49\n",
      "accuracy of the model 0.7064220183486238 random_state 50\n",
      "accuracy of the model 0.6605504587155964 random_state 51\n",
      "accuracy of the model 0.6605504587155964 random_state 52\n",
      "accuracy of the model 0.6880733944954128 random_state 53\n",
      "accuracy of the model 0.6605504587155964 random_state 54\n",
      "accuracy of the model 0.7247706422018348 random_state 55\n",
      "accuracy of the model 0.6880733944954128 random_state 56\n",
      "accuracy of the model 0.6788990825688074 random_state 57\n",
      "accuracy of the model 0.6972477064220184 random_state 58\n",
      "accuracy of the model 0.7247706422018348 random_state 59\n",
      "accuracy of the model 0.7522935779816514 random_state 60\n",
      "accuracy of the model 0.6605504587155964 random_state 61\n",
      "accuracy of the model 0.6330275229357798 random_state 62\n",
      "accuracy of the model 0.7155963302752294 random_state 63\n",
      "accuracy of the model 0.7247706422018348 random_state 64\n",
      "accuracy of the model 0.6880733944954128 random_state 65\n",
      "accuracy of the model 0.6055045871559633 random_state 66\n",
      "accuracy of the model 0.6697247706422018 random_state 67\n",
      "accuracy of the model 0.7064220183486238 random_state 68\n",
      "accuracy of the model 0.6513761467889908 random_state 69\n",
      "accuracy of the model 0.6605504587155964 random_state 70\n",
      "accuracy of the model 0.7431192660550459 random_state 71\n",
      "accuracy of the model 0.6422018348623854 random_state 72\n",
      "accuracy of the model 0.6422018348623854 random_state 73\n",
      "accuracy of the model 0.6697247706422018 random_state 74\n",
      "accuracy of the model 0.6513761467889908 random_state 75\n",
      "accuracy of the model 0.6788990825688074 random_state 76\n",
      "accuracy of the model 0.6330275229357798 random_state 77\n",
      "accuracy of the model 0.6788990825688074 random_state 78\n",
      "accuracy of the model 0.5963302752293578 random_state 79\n",
      "accuracy of the model 0.6972477064220184 random_state 80\n",
      "accuracy of the model 0.7339449541284404 random_state 81\n",
      "accuracy of the model 0.6972477064220184 random_state 82\n",
      "accuracy of the model 0.6422018348623854 random_state 83\n",
      "accuracy of the model 0.7339449541284404 random_state 84\n",
      "accuracy of the model 0.6513761467889908 random_state 85\n",
      "accuracy of the model 0.6513761467889908 random_state 86\n",
      "accuracy of the model 0.6880733944954128 random_state 87\n",
      "accuracy of the model 0.7064220183486238 random_state 88\n",
      "accuracy of the model 0.6972477064220184 random_state 89\n",
      "accuracy of the model 0.5779816513761468 random_state 90\n",
      "accuracy of the model 0.7155963302752294 random_state 91\n",
      "accuracy of the model 0.6788990825688074 random_state 92\n",
      "accuracy of the model 0.7522935779816514 random_state 93\n",
      "accuracy of the model 0.6605504587155964 random_state 94\n",
      "accuracy of the model 0.6880733944954128 random_state 95\n",
      "accuracy of the model 0.7064220183486238 random_state 96\n",
      "accuracy of the model 0.6513761467889908 random_state 97\n",
      "accuracy of the model 0.6972477064220184 random_state 98\n",
      "accuracy of the model 0.6422018348623854 random_state 99\n",
      "accuracy of the model 0.6697247706422018 random_state 100\n",
      "accuracy of the model 0.6880733944954128 random_state 101\n",
      "accuracy of the model 0.6422018348623854 random_state 102\n",
      "accuracy of the model 0.6788990825688074 random_state 103\n",
      "accuracy of the model 0.6055045871559633 random_state 104\n",
      "accuracy of the model 0.6422018348623854 random_state 105\n",
      "accuracy of the model 0.6422018348623854 random_state 106\n",
      "accuracy of the model 0.6880733944954128 random_state 107\n",
      "accuracy of the model 0.6972477064220184 random_state 108\n",
      "accuracy of the model 0.6513761467889908 random_state 109\n",
      "accuracy of the model 0.6330275229357798 random_state 110\n",
      "accuracy of the model 0.6972477064220184 random_state 111\n",
      "accuracy of the model 0.6330275229357798 random_state 112\n",
      "accuracy of the model 0.6788990825688074 random_state 113\n",
      "accuracy of the model 0.7339449541284404 random_state 114\n",
      "accuracy of the model 0.6880733944954128 random_state 115\n",
      "accuracy of the model 0.7339449541284404 random_state 116\n",
      "accuracy of the model 0.6880733944954128 random_state 117\n",
      "accuracy of the model 0.6605504587155964 random_state 118\n",
      "accuracy of the model 0.6880733944954128 random_state 119\n",
      "accuracy of the model 0.6605504587155964 random_state 120\n",
      "accuracy of the model 0.6880733944954128 random_state 121\n",
      "accuracy of the model 0.6880733944954128 random_state 122\n",
      "accuracy of the model 0.6880733944954128 random_state 123\n",
      "accuracy of the model 0.7247706422018348 random_state 124\n",
      "accuracy of the model 0.6605504587155964 random_state 125\n",
      "accuracy of the model 0.6146788990825688 random_state 126\n",
      "accuracy of the model 0.5871559633027523 random_state 127\n",
      "accuracy of the model 0.7889908256880734 random_state 128\n",
      "accuracy of the optimum model 0.7889908256880734 random_state 128\n",
      "accuracy of the model 0.6788990825688074 random_state 129\n",
      "accuracy of the model 0.7522935779816514 random_state 130\n",
      "accuracy of the model 0.7064220183486238 random_state 131\n",
      "accuracy of the model 0.6788990825688074 random_state 132\n",
      "accuracy of the model 0.6605504587155964 random_state 133\n",
      "accuracy of the model 0.6880733944954128 random_state 134\n",
      "accuracy of the model 0.6697247706422018 random_state 135\n",
      "accuracy of the model 0.6880733944954128 random_state 136\n",
      "accuracy of the model 0.6972477064220184 random_state 137\n",
      "accuracy of the model 0.7339449541284404 random_state 138\n",
      "accuracy of the model 0.7431192660550459 random_state 139\n",
      "accuracy of the model 0.6605504587155964 random_state 140\n",
      "accuracy of the model 0.6513761467889908 random_state 141\n",
      "accuracy of the model 0.6972477064220184 random_state 142\n",
      "accuracy of the model 0.6880733944954128 random_state 143\n",
      "accuracy of the model 0.7155963302752294 random_state 144\n",
      "accuracy of the model 0.6513761467889908 random_state 145\n",
      "accuracy of the model 0.5963302752293578 random_state 146\n",
      "accuracy of the model 0.7339449541284404 random_state 147\n",
      "accuracy of the model 0.7155963302752294 random_state 148\n",
      "accuracy of the model 0.6605504587155964 random_state 149\n",
      "accuracy of the model 0.5963302752293578 random_state 150\n",
      "accuracy of the model 0.6513761467889908 random_state 151\n",
      "accuracy of the model 0.7339449541284404 random_state 152\n",
      "accuracy of the model 0.6146788990825688 random_state 153\n",
      "accuracy of the model 0.7431192660550459 random_state 154\n",
      "accuracy of the model 0.6697247706422018 random_state 155\n",
      "accuracy of the model 0.7064220183486238 random_state 156\n",
      "accuracy of the model 0.6880733944954128 random_state 157\n",
      "accuracy of the model 0.6238532110091743 random_state 158\n",
      "accuracy of the model 0.6788990825688074 random_state 159\n",
      "accuracy of the model 0.6605504587155964 random_state 160\n",
      "accuracy of the model 0.6880733944954128 random_state 161\n",
      "accuracy of the model 0.6880733944954128 random_state 162\n",
      "accuracy of the model 0.7155963302752294 random_state 163\n",
      "accuracy of the model 0.6605504587155964 random_state 164\n",
      "accuracy of the model 0.6513761467889908 random_state 165\n",
      "accuracy of the model 0.6697247706422018 random_state 166\n",
      "accuracy of the model 0.6238532110091743 random_state 167\n",
      "accuracy of the model 0.6972477064220184 random_state 168\n",
      "accuracy of the model 0.7064220183486238 random_state 169\n",
      "accuracy of the model 0.6605504587155964 random_state 170\n",
      "accuracy of the model 0.7431192660550459 random_state 171\n",
      "accuracy of the model 0.7522935779816514 random_state 172\n",
      "accuracy of the model 0.6605504587155964 random_state 173\n",
      "accuracy of the model 0.6422018348623854 random_state 174\n",
      "accuracy of the model 0.6605504587155964 random_state 175\n",
      "accuracy of the model 0.6513761467889908 random_state 176\n",
      "accuracy of the model 0.6422018348623854 random_state 177\n",
      "accuracy of the model 0.7522935779816514 random_state 178\n",
      "accuracy of the model 0.6238532110091743 random_state 179\n",
      "accuracy of the model 0.6880733944954128 random_state 180\n",
      "accuracy of the model 0.7247706422018348 random_state 181\n",
      "accuracy of the model 0.6422018348623854 random_state 182\n",
      "accuracy of the model 0.7064220183486238 random_state 183\n",
      "accuracy of the model 0.6880733944954128 random_state 184\n",
      "accuracy of the model 0.6788990825688074 random_state 185\n",
      "accuracy of the model 0.6788990825688074 random_state 186\n",
      "accuracy of the model 0.6788990825688074 random_state 187\n",
      "accuracy of the model 0.6513761467889908 random_state 188\n",
      "accuracy of the model 0.6422018348623854 random_state 189\n",
      "accuracy of the model 0.6697247706422018 random_state 190\n",
      "accuracy of the model 0.6513761467889908 random_state 191\n",
      "accuracy of the model 0.6972477064220184 random_state 192\n",
      "accuracy of the model 0.6513761467889908 random_state 193\n",
      "accuracy of the model 0.6880733944954128 random_state 194\n",
      "accuracy of the model 0.6422018348623854 random_state 195\n",
      "accuracy of the model 0.6605504587155964 random_state 196\n",
      "accuracy of the model 0.6697247706422018 random_state 197\n",
      "accuracy of the model 0.6605504587155964 random_state 198\n",
      "accuracy of the model 0.7064220183486238 random_state 199\n",
      "accuracy of the model 0.6697247706422018 random_state 200\n",
      "accuracy of the model 0.6880733944954128 random_state 201\n",
      "accuracy of the model 0.6422018348623854 random_state 202\n",
      "accuracy of the model 0.7431192660550459 random_state 203\n",
      "accuracy of the model 0.6605504587155964 random_state 204\n",
      "accuracy of the model 0.6880733944954128 random_state 205\n",
      "accuracy of the model 0.6513761467889908 random_state 206\n",
      "accuracy of the model 0.6697247706422018 random_state 207\n",
      "accuracy of the model 0.7064220183486238 random_state 208\n",
      "accuracy of the model 0.7247706422018348 random_state 209\n",
      "accuracy of the model 0.5871559633027523 random_state 210\n",
      "accuracy of the model 0.6238532110091743 random_state 211\n",
      "accuracy of the model 0.6422018348623854 random_state 212\n",
      "accuracy of the model 0.6697247706422018 random_state 213\n",
      "accuracy of the model 0.6513761467889908 random_state 214\n",
      "accuracy of the model 0.6788990825688074 random_state 215\n",
      "accuracy of the model 0.6605504587155964 random_state 216\n",
      "accuracy of the model 0.6788990825688074 random_state 217\n",
      "accuracy of the model 0.7431192660550459 random_state 218\n",
      "accuracy of the model 0.6880733944954128 random_state 219\n",
      "accuracy of the model 0.6513761467889908 random_state 220\n",
      "accuracy of the model 0.6605504587155964 random_state 221\n",
      "accuracy of the model 0.6880733944954128 random_state 222\n",
      "accuracy of the model 0.6880733944954128 random_state 223\n",
      "accuracy of the model 0.6880733944954128 random_state 224\n",
      "accuracy of the model 0.6605504587155964 random_state 225\n",
      "accuracy of the model 0.7981651376146789 random_state 226\n",
      "accuracy of the optimum model 0.7981651376146789 random_state 226\n",
      "accuracy of the model 0.6880733944954128 random_state 227\n",
      "accuracy of the model 0.7522935779816514 random_state 228\n",
      "accuracy of the model 0.7064220183486238 random_state 229\n",
      "accuracy of the model 0.6146788990825688 random_state 230\n",
      "accuracy of the model 0.6513761467889908 random_state 231\n",
      "accuracy of the model 0.6422018348623854 random_state 232\n",
      "accuracy of the model 0.6605504587155964 random_state 233\n",
      "accuracy of the model 0.6880733944954128 random_state 234\n",
      "accuracy of the model 0.6972477064220184 random_state 235\n",
      "accuracy of the model 0.7522935779816514 random_state 236\n",
      "accuracy of the model 0.6788990825688074 random_state 237\n",
      "accuracy of the model 0.6880733944954128 random_state 238\n",
      "accuracy of the model 0.6972477064220184 random_state 239\n",
      "accuracy of the model 0.6972477064220184 random_state 240\n",
      "accuracy of the model 0.6788990825688074 random_state 241\n",
      "accuracy of the model 0.6055045871559633 random_state 242\n",
      "accuracy of the model 0.6513761467889908 random_state 243\n",
      "accuracy of the model 0.7339449541284404 random_state 244\n",
      "accuracy of the model 0.7064220183486238 random_state 245\n",
      "accuracy of the model 0.6238532110091743 random_state 246\n",
      "accuracy of the model 0.7155963302752294 random_state 247\n",
      "accuracy of the model 0.6513761467889908 random_state 248\n",
      "accuracy of the model 0.7064220183486238 random_state 249\n",
      "accuracy of the model 0.7339449541284404 random_state 250\n",
      "accuracy of the model 0.7339449541284404 random_state 251\n",
      "accuracy of the model 0.6055045871559633 random_state 252\n",
      "accuracy of the model 0.6972477064220184 random_state 253\n",
      "accuracy of the model 0.6788990825688074 random_state 254\n",
      "accuracy of the model 0.6605504587155964 random_state 255\n",
      "accuracy of the model 0.6788990825688074 random_state 256\n",
      "accuracy of the model 0.7064220183486238 random_state 257\n",
      "accuracy of the model 0.6880733944954128 random_state 258\n",
      "accuracy of the model 0.6788990825688074 random_state 259\n",
      "accuracy of the model 0.6880733944954128 random_state 260\n",
      "accuracy of the model 0.7614678899082569 random_state 261\n",
      "accuracy of the model 0.6422018348623854 random_state 262\n",
      "accuracy of the model 0.6697247706422018 random_state 263\n",
      "accuracy of the model 0.6238532110091743 random_state 264\n",
      "accuracy of the model 0.6513761467889908 random_state 265\n",
      "accuracy of the model 0.6788990825688074 random_state 266\n",
      "accuracy of the model 0.7155963302752294 random_state 267\n",
      "accuracy of the model 0.6513761467889908 random_state 268\n",
      "accuracy of the model 0.6880733944954128 random_state 269\n",
      "accuracy of the model 0.7064220183486238 random_state 270\n",
      "accuracy of the model 0.7064220183486238 random_state 271\n",
      "accuracy of the model 0.7064220183486238 random_state 272\n",
      "accuracy of the model 0.6146788990825688 random_state 273\n",
      "accuracy of the model 0.6238532110091743 random_state 274\n",
      "accuracy of the model 0.7155963302752294 random_state 275\n",
      "accuracy of the model 0.6605504587155964 random_state 276\n",
      "accuracy of the model 0.6972477064220184 random_state 277\n",
      "accuracy of the model 0.7155963302752294 random_state 278\n",
      "accuracy of the model 0.6880733944954128 random_state 279\n",
      "accuracy of the model 0.6697247706422018 random_state 280\n",
      "accuracy of the model 0.6880733944954128 random_state 281\n",
      "accuracy of the model 0.6422018348623854 random_state 282\n",
      "accuracy of the model 0.6972477064220184 random_state 283\n",
      "accuracy of the model 0.6238532110091743 random_state 284\n",
      "accuracy of the model 0.6788990825688074 random_state 285\n",
      "accuracy of the model 0.7431192660550459 random_state 286\n",
      "accuracy of the model 0.6330275229357798 random_state 287\n",
      "accuracy of the model 0.6788990825688074 random_state 288\n",
      "accuracy of the model 0.6788990825688074 random_state 289\n",
      "accuracy of the model 0.6422018348623854 random_state 290\n",
      "accuracy of the model 0.7155963302752294 random_state 291\n",
      "accuracy of the model 0.6788990825688074 random_state 292\n",
      "accuracy of the model 0.7247706422018348 random_state 293\n",
      "accuracy of the model 0.6605504587155964 random_state 294\n",
      "accuracy of the model 0.6697247706422018 random_state 295\n",
      "accuracy of the model 0.6972477064220184 random_state 296\n",
      "accuracy of the model 0.7247706422018348 random_state 297\n",
      "accuracy of the model 0.5871559633027523 random_state 298\n",
      "accuracy of the model 0.6788990825688074 random_state 299\n",
      "accuracy of the model 0.7247706422018348 random_state 300\n",
      "accuracy of the model 0.6880733944954128 random_state 301\n",
      "accuracy of the model 0.5688073394495413 random_state 302\n",
      "accuracy of the model 0.6238532110091743 random_state 303\n",
      "accuracy of the model 0.6422018348623854 random_state 304\n",
      "accuracy of the model 0.6972477064220184 random_state 305\n",
      "accuracy of the model 0.7155963302752294 random_state 306\n",
      "accuracy of the model 0.6605504587155964 random_state 307\n",
      "accuracy of the model 0.6788990825688074 random_state 308\n",
      "accuracy of the model 0.6238532110091743 random_state 309\n",
      "accuracy of the model 0.6605504587155964 random_state 310\n",
      "accuracy of the model 0.6880733944954128 random_state 311\n",
      "accuracy of the model 0.6697247706422018 random_state 312\n",
      "accuracy of the model 0.6513761467889908 random_state 313\n",
      "accuracy of the model 0.7339449541284404 random_state 314\n",
      "accuracy of the model 0.6972477064220184 random_state 315\n",
      "accuracy of the model 0.5871559633027523 random_state 316\n",
      "accuracy of the model 0.6605504587155964 random_state 317\n",
      "accuracy of the model 0.6146788990825688 random_state 318\n",
      "accuracy of the model 0.6697247706422018 random_state 319\n",
      "accuracy of the model 0.6513761467889908 random_state 320\n",
      "accuracy of the model 0.6422018348623854 random_state 321\n",
      "accuracy of the model 0.6880733944954128 random_state 322\n",
      "accuracy of the model 0.6697247706422018 random_state 323\n",
      "accuracy of the model 0.7064220183486238 random_state 324\n",
      "accuracy of the model 0.7247706422018348 random_state 325\n",
      "accuracy of the model 0.6330275229357798 random_state 326\n",
      "accuracy of the model 0.6605504587155964 random_state 327\n",
      "accuracy of the model 0.6972477064220184 random_state 328\n",
      "accuracy of the model 0.6788990825688074 random_state 329\n",
      "accuracy of the model 0.6513761467889908 random_state 330\n",
      "accuracy of the model 0.6422018348623854 random_state 331\n",
      "accuracy of the model 0.7522935779816514 random_state 332\n",
      "accuracy of the model 0.6880733944954128 random_state 333\n",
      "accuracy of the model 0.7247706422018348 random_state 334\n",
      "accuracy of the model 0.6972477064220184 random_state 335\n",
      "accuracy of the model 0.6605504587155964 random_state 336\n",
      "accuracy of the model 0.7431192660550459 random_state 337\n",
      "accuracy of the model 0.6605504587155964 random_state 338\n",
      "accuracy of the model 0.6513761467889908 random_state 339\n",
      "accuracy of the model 0.7339449541284404 random_state 340\n",
      "accuracy of the model 0.6238532110091743 random_state 341\n",
      "accuracy of the model 0.6972477064220184 random_state 342\n",
      "accuracy of the model 0.6697247706422018 random_state 343\n",
      "accuracy of the model 0.6697247706422018 random_state 344\n",
      "accuracy of the model 0.7064220183486238 random_state 345\n",
      "accuracy of the model 0.7431192660550459 random_state 346\n",
      "accuracy of the model 0.7522935779816514 random_state 347\n",
      "accuracy of the model 0.7064220183486238 random_state 348\n",
      "accuracy of the model 0.6330275229357798 random_state 349\n",
      "accuracy of the model 0.6513761467889908 random_state 350\n",
      "accuracy of the model 0.6697247706422018 random_state 351\n",
      "accuracy of the model 0.7247706422018348 random_state 352\n",
      "accuracy of the model 0.6238532110091743 random_state 353\n",
      "accuracy of the model 0.6697247706422018 random_state 354\n",
      "accuracy of the model 0.7155963302752294 random_state 355\n",
      "accuracy of the model 0.7064220183486238 random_state 356\n",
      "accuracy of the model 0.7064220183486238 random_state 357\n",
      "accuracy of the model 0.7614678899082569 random_state 358\n",
      "accuracy of the model 0.6513761467889908 random_state 359\n",
      "accuracy of the model 0.6788990825688074 random_state 360\n",
      "accuracy of the model 0.7155963302752294 random_state 361\n",
      "accuracy of the model 0.6880733944954128 random_state 362\n",
      "accuracy of the model 0.6788990825688074 random_state 363\n",
      "accuracy of the model 0.7155963302752294 random_state 364\n",
      "accuracy of the model 0.7339449541284404 random_state 365\n",
      "accuracy of the model 0.6880733944954128 random_state 366\n",
      "accuracy of the model 0.6880733944954128 random_state 367\n",
      "accuracy of the model 0.6788990825688074 random_state 368\n",
      "accuracy of the model 0.6513761467889908 random_state 369\n",
      "accuracy of the model 0.7522935779816514 random_state 370\n",
      "accuracy of the model 0.6972477064220184 random_state 371\n",
      "accuracy of the model 0.6788990825688074 random_state 372\n",
      "accuracy of the model 0.7522935779816514 random_state 373\n",
      "accuracy of the model 0.6880733944954128 random_state 374\n",
      "accuracy of the model 0.6422018348623854 random_state 375\n",
      "accuracy of the model 0.7155963302752294 random_state 376\n",
      "accuracy of the model 0.6330275229357798 random_state 377\n",
      "accuracy of the model 0.6880733944954128 random_state 378\n",
      "accuracy of the model 0.7155963302752294 random_state 379\n",
      "accuracy of the model 0.6422018348623854 random_state 380\n",
      "accuracy of the model 0.6697247706422018 random_state 381\n",
      "accuracy of the model 0.6605504587155964 random_state 382\n",
      "accuracy of the model 0.6238532110091743 random_state 383\n",
      "accuracy of the model 0.5963302752293578 random_state 384\n",
      "accuracy of the model 0.6605504587155964 random_state 385\n",
      "accuracy of the model 0.7064220183486238 random_state 386\n",
      "accuracy of the model 0.6605504587155964 random_state 387\n",
      "accuracy of the model 0.6605504587155964 random_state 388\n",
      "accuracy of the model 0.6788990825688074 random_state 389\n",
      "accuracy of the model 0.7064220183486238 random_state 390\n",
      "accuracy of the model 0.6880733944954128 random_state 391\n",
      "accuracy of the model 0.6238532110091743 random_state 392\n",
      "accuracy of the model 0.6880733944954128 random_state 393\n",
      "accuracy of the model 0.6238532110091743 random_state 394\n",
      "accuracy of the model 0.7064220183486238 random_state 395\n",
      "accuracy of the model 0.7706422018348624 random_state 396\n",
      "accuracy of the model 0.6788990825688074 random_state 397\n",
      "accuracy of the model 0.6972477064220184 random_state 398\n",
      "accuracy of the model 0.6513761467889908 random_state 399\n",
      "accuracy of the model 0.6880733944954128 random_state 400\n",
      "accuracy of the model 0.5871559633027523 random_state 401\n",
      "accuracy of the model 0.7431192660550459 random_state 402\n",
      "accuracy of the model 0.6238532110091743 random_state 403\n",
      "accuracy of the model 0.6788990825688074 random_state 404\n",
      "accuracy of the model 0.7247706422018348 random_state 405\n",
      "accuracy of the model 0.7339449541284404 random_state 406\n",
      "accuracy of the model 0.6238532110091743 random_state 407\n",
      "accuracy of the model 0.6238532110091743 random_state 408\n",
      "accuracy of the model 0.6605504587155964 random_state 409\n",
      "accuracy of the model 0.6330275229357798 random_state 410\n",
      "accuracy of the model 0.6513761467889908 random_state 411\n",
      "accuracy of the model 0.6605504587155964 random_state 412\n",
      "accuracy of the model 0.6513761467889908 random_state 413\n",
      "accuracy of the model 0.5963302752293578 random_state 414\n",
      "accuracy of the model 0.7431192660550459 random_state 415\n",
      "accuracy of the model 0.7064220183486238 random_state 416\n",
      "accuracy of the model 0.7064220183486238 random_state 417\n",
      "accuracy of the model 0.7064220183486238 random_state 418\n",
      "accuracy of the model 0.6697247706422018 random_state 419\n",
      "accuracy of the model 0.6972477064220184 random_state 420\n",
      "accuracy of the model 0.6788990825688074 random_state 421\n",
      "accuracy of the model 0.7247706422018348 random_state 422\n",
      "accuracy of the model 0.6605504587155964 random_state 423\n",
      "accuracy of the model 0.6422018348623854 random_state 424\n",
      "accuracy of the model 0.6697247706422018 random_state 425\n",
      "accuracy of the model 0.6605504587155964 random_state 426\n",
      "accuracy of the model 0.6697247706422018 random_state 427\n",
      "accuracy of the model 0.7155963302752294 random_state 428\n",
      "accuracy of the model 0.6972477064220184 random_state 429\n",
      "accuracy of the model 0.6788990825688074 random_state 430\n",
      "accuracy of the model 0.7706422018348624 random_state 431\n",
      "accuracy of the model 0.6880733944954128 random_state 432\n",
      "accuracy of the model 0.7155963302752294 random_state 433\n",
      "accuracy of the model 0.7155963302752294 random_state 434\n",
      "accuracy of the model 0.6513761467889908 random_state 435\n",
      "accuracy of the model 0.6605504587155964 random_state 436\n",
      "accuracy of the model 0.6238532110091743 random_state 437\n",
      "accuracy of the model 0.6880733944954128 random_state 438\n",
      "accuracy of the model 0.7064220183486238 random_state 439\n",
      "accuracy of the model 0.7431192660550459 random_state 440\n",
      "accuracy of the model 0.6605504587155964 random_state 441\n",
      "accuracy of the model 0.7064220183486238 random_state 442\n",
      "accuracy of the model 0.6422018348623854 random_state 443\n",
      "accuracy of the model 0.6880733944954128 random_state 444\n",
      "accuracy of the model 0.7247706422018348 random_state 445\n",
      "accuracy of the model 0.6513761467889908 random_state 446\n",
      "accuracy of the model 0.6238532110091743 random_state 447\n",
      "accuracy of the model 0.6605504587155964 random_state 448\n",
      "accuracy of the model 0.6605504587155964 random_state 449\n",
      "accuracy of the model 0.6697247706422018 random_state 450\n",
      "accuracy of the model 0.6697247706422018 random_state 451\n",
      "accuracy of the model 0.6513761467889908 random_state 452\n",
      "accuracy of the model 0.6697247706422018 random_state 453\n",
      "accuracy of the model 0.6697247706422018 random_state 454\n",
      "accuracy of the model 0.6972477064220184 random_state 455\n",
      "accuracy of the model 0.6697247706422018 random_state 456\n",
      "accuracy of the model 0.5504587155963303 random_state 457\n",
      "accuracy of the model 0.6146788990825688 random_state 458\n",
      "accuracy of the model 0.6605504587155964 random_state 459\n",
      "accuracy of the model 0.7155963302752294 random_state 460\n",
      "accuracy of the model 0.6330275229357798 random_state 461\n",
      "accuracy of the model 0.7064220183486238 random_state 462\n",
      "accuracy of the model 0.6513761467889908 random_state 463\n",
      "accuracy of the model 0.6513761467889908 random_state 464\n",
      "accuracy of the model 0.6697247706422018 random_state 465\n",
      "accuracy of the model 0.7155963302752294 random_state 466\n",
      "accuracy of the model 0.6513761467889908 random_state 467\n",
      "accuracy of the model 0.6697247706422018 random_state 468\n",
      "accuracy of the model 0.6972477064220184 random_state 469\n",
      "accuracy of the model 0.7064220183486238 random_state 470\n",
      "accuracy of the model 0.6513761467889908 random_state 471\n",
      "accuracy of the model 0.6697247706422018 random_state 472\n",
      "accuracy of the model 0.6146788990825688 random_state 473\n",
      "accuracy of the model 0.6697247706422018 random_state 474\n",
      "accuracy of the model 0.7247706422018348 random_state 475\n",
      "accuracy of the model 0.6697247706422018 random_state 476\n",
      "accuracy of the model 0.6238532110091743 random_state 477\n",
      "accuracy of the model 0.6880733944954128 random_state 478\n",
      "accuracy of the model 0.6238532110091743 random_state 479\n",
      "accuracy of the model 0.6146788990825688 random_state 480\n",
      "accuracy of the model 0.6513761467889908 random_state 481\n",
      "accuracy of the model 0.5963302752293578 random_state 482\n",
      "accuracy of the model 0.6697247706422018 random_state 483\n",
      "accuracy of the model 0.6697247706422018 random_state 484\n",
      "accuracy of the model 0.7064220183486238 random_state 485\n",
      "accuracy of the model 0.6880733944954128 random_state 486\n",
      "accuracy of the model 0.6880733944954128 random_state 487\n",
      "accuracy of the model 0.6972477064220184 random_state 488\n",
      "accuracy of the model 0.6972477064220184 random_state 489\n",
      "accuracy of the model 0.7155963302752294 random_state 490\n",
      "accuracy of the model 0.6697247706422018 random_state 491\n",
      "accuracy of the model 0.7155963302752294 random_state 492\n",
      "accuracy of the model 0.6788990825688074 random_state 493\n",
      "accuracy of the model 0.7706422018348624 random_state 494\n",
      "accuracy of the model 0.6880733944954128 random_state 495\n",
      "accuracy of the model 0.7247706422018348 random_state 496\n",
      "accuracy of the model 0.6330275229357798 random_state 497\n",
      "accuracy of the model 0.6972477064220184 random_state 498\n",
      "accuracy of the model 0.7155963302752294 random_state 499\n",
      "accuracy of the model 0.6605504587155964 random_state 500\n",
      "accuracy of the model 0.6788990825688074 random_state 501\n",
      "accuracy of the model 0.7064220183486238 random_state 502\n",
      "accuracy of the model 0.6605504587155964 random_state 503\n",
      "accuracy of the model 0.6697247706422018 random_state 504\n",
      "accuracy of the model 0.7247706422018348 random_state 505\n",
      "accuracy of the model 0.6697247706422018 random_state 506\n",
      "accuracy of the model 0.6788990825688074 random_state 507\n",
      "accuracy of the model 0.6697247706422018 random_state 508\n",
      "accuracy of the model 0.6330275229357798 random_state 509\n",
      "accuracy of the model 0.6972477064220184 random_state 510\n",
      "accuracy of the model 0.7339449541284404 random_state 511\n",
      "accuracy of the model 0.6880733944954128 random_state 512\n",
      "accuracy of the model 0.6788990825688074 random_state 513\n",
      "accuracy of the model 0.7431192660550459 random_state 514\n",
      "accuracy of the model 0.7155963302752294 random_state 515\n",
      "accuracy of the model 0.6788990825688074 random_state 516\n",
      "accuracy of the model 0.7431192660550459 random_state 517\n",
      "accuracy of the model 0.7155963302752294 random_state 518\n",
      "accuracy of the model 0.6422018348623854 random_state 519\n",
      "accuracy of the model 0.6788990825688074 random_state 520\n",
      "accuracy of the model 0.6422018348623854 random_state 521\n",
      "accuracy of the model 0.6880733944954128 random_state 522\n",
      "accuracy of the model 0.7614678899082569 random_state 523\n",
      "accuracy of the model 0.7064220183486238 random_state 524\n",
      "accuracy of the model 0.6605504587155964 random_state 525\n",
      "accuracy of the model 0.6330275229357798 random_state 526\n",
      "accuracy of the model 0.6513761467889908 random_state 527\n",
      "accuracy of the model 0.6972477064220184 random_state 528\n",
      "accuracy of the model 0.7339449541284404 random_state 529\n",
      "accuracy of the model 0.6788990825688074 random_state 530\n",
      "accuracy of the model 0.6972477064220184 random_state 531\n",
      "accuracy of the model 0.7155963302752294 random_state 532\n",
      "accuracy of the model 0.7155963302752294 random_state 533\n",
      "accuracy of the model 0.6972477064220184 random_state 534\n",
      "accuracy of the model 0.6788990825688074 random_state 535\n",
      "accuracy of the model 0.6422018348623854 random_state 536\n",
      "accuracy of the model 0.6788990825688074 random_state 537\n",
      "accuracy of the model 0.6238532110091743 random_state 538\n",
      "accuracy of the model 0.7155963302752294 random_state 539\n",
      "accuracy of the model 0.6238532110091743 random_state 540\n",
      "accuracy of the model 0.6605504587155964 random_state 541\n",
      "accuracy of the model 0.6330275229357798 random_state 542\n",
      "accuracy of the model 0.6513761467889908 random_state 543\n",
      "accuracy of the model 0.6972477064220184 random_state 544\n",
      "accuracy of the model 0.6972477064220184 random_state 545\n",
      "accuracy of the model 0.6146788990825688 random_state 546\n",
      "accuracy of the model 0.6788990825688074 random_state 547\n",
      "accuracy of the model 0.7798165137614679 random_state 548\n",
      "accuracy of the model 0.6513761467889908 random_state 549\n",
      "accuracy of the model 0.7339449541284404 random_state 550\n",
      "accuracy of the model 0.6972477064220184 random_state 551\n",
      "accuracy of the model 0.7247706422018348 random_state 552\n",
      "accuracy of the model 0.7339449541284404 random_state 553\n",
      "accuracy of the model 0.6788990825688074 random_state 554\n",
      "accuracy of the model 0.6788990825688074 random_state 555\n",
      "accuracy of the model 0.6880733944954128 random_state 556\n",
      "accuracy of the model 0.6513761467889908 random_state 557\n",
      "accuracy of the model 0.6330275229357798 random_state 558\n",
      "accuracy of the model 0.6605504587155964 random_state 559\n",
      "accuracy of the model 0.6238532110091743 random_state 560\n",
      "accuracy of the model 0.7247706422018348 random_state 561\n",
      "accuracy of the model 0.7155963302752294 random_state 562\n",
      "accuracy of the model 0.6513761467889908 random_state 563\n",
      "accuracy of the model 0.6697247706422018 random_state 564\n",
      "accuracy of the model 0.6697247706422018 random_state 565\n",
      "accuracy of the model 0.7064220183486238 random_state 566\n",
      "accuracy of the model 0.6422018348623854 random_state 567\n",
      "accuracy of the model 0.7522935779816514 random_state 568\n",
      "accuracy of the model 0.7339449541284404 random_state 569\n",
      "accuracy of the model 0.6513761467889908 random_state 570\n",
      "accuracy of the model 0.6146788990825688 random_state 571\n",
      "accuracy of the model 0.6697247706422018 random_state 572\n",
      "accuracy of the model 0.7155963302752294 random_state 573\n",
      "accuracy of the model 0.6238532110091743 random_state 574\n",
      "accuracy of the model 0.6880733944954128 random_state 575\n",
      "accuracy of the model 0.6513761467889908 random_state 576\n",
      "accuracy of the model 0.7706422018348624 random_state 577\n",
      "accuracy of the model 0.6422018348623854 random_state 578\n",
      "accuracy of the model 0.7064220183486238 random_state 579\n",
      "accuracy of the model 0.7155963302752294 random_state 580\n",
      "accuracy of the model 0.6605504587155964 random_state 581\n",
      "accuracy of the model 0.7155963302752294 random_state 582\n",
      "accuracy of the model 0.7614678899082569 random_state 583\n",
      "accuracy of the model 0.6422018348623854 random_state 584\n",
      "accuracy of the model 0.6605504587155964 random_state 585\n",
      "accuracy of the model 0.7155963302752294 random_state 586\n",
      "accuracy of the model 0.6972477064220184 random_state 587\n",
      "accuracy of the model 0.6422018348623854 random_state 588\n",
      "accuracy of the model 0.7339449541284404 random_state 589\n",
      "accuracy of the model 0.6513761467889908 random_state 590\n",
      "accuracy of the model 0.6146788990825688 random_state 591\n",
      "accuracy of the model 0.7431192660550459 random_state 592\n",
      "accuracy of the model 0.6697247706422018 random_state 593\n",
      "accuracy of the model 0.7247706422018348 random_state 594\n",
      "accuracy of the model 0.6513761467889908 random_state 595\n",
      "accuracy of the model 0.7155963302752294 random_state 596\n",
      "accuracy of the model 0.6330275229357798 random_state 597\n",
      "accuracy of the model 0.7247706422018348 random_state 598\n",
      "accuracy of the model 0.6697247706422018 random_state 599\n",
      "accuracy of the model 0.7339449541284404 random_state 600\n",
      "accuracy of the model 0.6605504587155964 random_state 601\n",
      "accuracy of the model 0.7064220183486238 random_state 602\n",
      "accuracy of the model 0.7431192660550459 random_state 603\n",
      "accuracy of the model 0.6238532110091743 random_state 604\n",
      "accuracy of the model 0.6513761467889908 random_state 605\n",
      "accuracy of the model 0.7339449541284404 random_state 606\n",
      "accuracy of the model 0.6330275229357798 random_state 607\n",
      "accuracy of the model 0.6513761467889908 random_state 608\n",
      "accuracy of the model 0.7064220183486238 random_state 609\n",
      "accuracy of the model 0.6788990825688074 random_state 610\n",
      "accuracy of the model 0.6697247706422018 random_state 611\n",
      "accuracy of the model 0.6605504587155964 random_state 612\n",
      "accuracy of the model 0.7431192660550459 random_state 613\n",
      "accuracy of the model 0.6513761467889908 random_state 614\n",
      "accuracy of the model 0.6422018348623854 random_state 615\n",
      "accuracy of the model 0.6788990825688074 random_state 616\n",
      "accuracy of the model 0.7155963302752294 random_state 617\n",
      "accuracy of the model 0.6422018348623854 random_state 618\n",
      "accuracy of the model 0.6330275229357798 random_state 619\n",
      "accuracy of the model 0.6788990825688074 random_state 620\n",
      "accuracy of the model 0.7155963302752294 random_state 621\n",
      "accuracy of the model 0.6697247706422018 random_state 622\n",
      "accuracy of the model 0.6697247706422018 random_state 623\n",
      "accuracy of the model 0.7889908256880734 random_state 624\n",
      "accuracy of the model 0.6146788990825688 random_state 625\n",
      "accuracy of the model 0.6513761467889908 random_state 626\n",
      "accuracy of the model 0.6697247706422018 random_state 627\n",
      "accuracy of the model 0.7706422018348624 random_state 628\n",
      "accuracy of the model 0.6697247706422018 random_state 629\n",
      "accuracy of the model 0.7247706422018348 random_state 630\n",
      "accuracy of the model 0.7522935779816514 random_state 631\n",
      "accuracy of the model 0.6880733944954128 random_state 632\n",
      "accuracy of the model 0.7522935779816514 random_state 633\n",
      "accuracy of the model 0.6422018348623854 random_state 634\n",
      "accuracy of the model 0.6972477064220184 random_state 635\n",
      "accuracy of the model 0.6238532110091743 random_state 636\n",
      "accuracy of the model 0.6880733944954128 random_state 637\n",
      "accuracy of the model 0.7247706422018348 random_state 638\n",
      "accuracy of the model 0.6788990825688074 random_state 639\n",
      "accuracy of the model 0.6972477064220184 random_state 640\n",
      "accuracy of the model 0.7431192660550459 random_state 641\n",
      "accuracy of the model 0.7339449541284404 random_state 642\n",
      "accuracy of the model 0.7247706422018348 random_state 643\n",
      "accuracy of the model 0.6697247706422018 random_state 644\n",
      "accuracy of the model 0.6880733944954128 random_state 645\n",
      "accuracy of the model 0.6605504587155964 random_state 646\n",
      "accuracy of the model 0.6238532110091743 random_state 647\n",
      "accuracy of the model 0.7064220183486238 random_state 648\n",
      "accuracy of the model 0.7064220183486238 random_state 649\n",
      "accuracy of the model 0.6422018348623854 random_state 650\n",
      "accuracy of the model 0.5963302752293578 random_state 651\n",
      "accuracy of the model 0.6880733944954128 random_state 652\n",
      "accuracy of the model 0.6422018348623854 random_state 653\n",
      "accuracy of the model 0.7155963302752294 random_state 654\n",
      "accuracy of the model 0.6880733944954128 random_state 655\n",
      "accuracy of the model 0.6972477064220184 random_state 656\n",
      "accuracy of the model 0.7064220183486238 random_state 657\n",
      "accuracy of the model 0.6330275229357798 random_state 658\n",
      "accuracy of the model 0.6238532110091743 random_state 659\n",
      "accuracy of the model 0.7431192660550459 random_state 660\n",
      "accuracy of the model 0.7431192660550459 random_state 661\n",
      "accuracy of the model 0.7064220183486238 random_state 662\n",
      "accuracy of the model 0.6697247706422018 random_state 663\n",
      "accuracy of the model 0.7064220183486238 random_state 664\n",
      "accuracy of the model 0.6513761467889908 random_state 665\n",
      "accuracy of the model 0.6788990825688074 random_state 666\n",
      "accuracy of the model 0.7064220183486238 random_state 667\n",
      "accuracy of the model 0.6238532110091743 random_state 668\n",
      "accuracy of the model 0.6788990825688074 random_state 669\n",
      "accuracy of the model 0.6513761467889908 random_state 670\n",
      "accuracy of the model 0.7247706422018348 random_state 671\n",
      "accuracy of the model 0.6880733944954128 random_state 672\n",
      "accuracy of the model 0.6972477064220184 random_state 673\n",
      "accuracy of the model 0.7064220183486238 random_state 674\n",
      "accuracy of the model 0.7155963302752294 random_state 675\n",
      "accuracy of the model 0.6697247706422018 random_state 676\n",
      "accuracy of the model 0.6697247706422018 random_state 677\n",
      "accuracy of the model 0.7431192660550459 random_state 678\n",
      "accuracy of the model 0.6788990825688074 random_state 679\n",
      "accuracy of the model 0.6238532110091743 random_state 680\n",
      "accuracy of the model 0.7431192660550459 random_state 681\n",
      "accuracy of the model 0.6972477064220184 random_state 682\n",
      "accuracy of the model 0.7431192660550459 random_state 683\n",
      "accuracy of the model 0.5963302752293578 random_state 684\n",
      "accuracy of the model 0.6788990825688074 random_state 685\n",
      "accuracy of the model 0.7431192660550459 random_state 686\n",
      "accuracy of the model 0.6880733944954128 random_state 687\n",
      "accuracy of the model 0.6972477064220184 random_state 688\n",
      "accuracy of the model 0.5779816513761468 random_state 689\n",
      "accuracy of the model 0.7339449541284404 random_state 690\n",
      "accuracy of the model 0.6697247706422018 random_state 691\n",
      "accuracy of the model 0.6697247706422018 random_state 692\n",
      "accuracy of the model 0.6697247706422018 random_state 693\n",
      "accuracy of the model 0.6513761467889908 random_state 694\n",
      "accuracy of the model 0.7064220183486238 random_state 695\n",
      "accuracy of the model 0.6330275229357798 random_state 696\n",
      "accuracy of the model 0.6788990825688074 random_state 697\n",
      "accuracy of the model 0.7247706422018348 random_state 698\n",
      "accuracy of the model 0.6513761467889908 random_state 699\n",
      "accuracy of the model 0.7064220183486238 random_state 700\n",
      "accuracy of the model 0.6422018348623854 random_state 701\n",
      "accuracy of the model 0.6972477064220184 random_state 702\n",
      "accuracy of the model 0.5688073394495413 random_state 703\n",
      "accuracy of the model 0.6330275229357798 random_state 704\n",
      "accuracy of the model 0.6330275229357798 random_state 705\n",
      "accuracy of the model 0.7614678899082569 random_state 706\n",
      "accuracy of the model 0.6788990825688074 random_state 707\n",
      "accuracy of the model 0.6972477064220184 random_state 708\n",
      "accuracy of the model 0.6880733944954128 random_state 709\n",
      "accuracy of the model 0.5963302752293578 random_state 710\n",
      "accuracy of the model 0.8165137614678899 random_state 711\n",
      "accuracy of the optimum model 0.8165137614678899 random_state 711\n",
      "accuracy of the model 0.6697247706422018 random_state 712\n",
      "accuracy of the model 0.6972477064220184 random_state 713\n",
      "accuracy of the model 0.6513761467889908 random_state 714\n",
      "accuracy of the model 0.6697247706422018 random_state 715\n",
      "accuracy of the model 0.7064220183486238 random_state 716\n",
      "accuracy of the model 0.6788990825688074 random_state 717\n",
      "accuracy of the model 0.7155963302752294 random_state 718\n",
      "accuracy of the model 0.6605504587155964 random_state 719\n",
      "accuracy of the model 0.7064220183486238 random_state 720\n",
      "accuracy of the model 0.7339449541284404 random_state 721\n",
      "accuracy of the model 0.7155963302752294 random_state 722\n",
      "accuracy of the model 0.6146788990825688 random_state 723\n",
      "accuracy of the model 0.5871559633027523 random_state 724\n",
      "accuracy of the model 0.6513761467889908 random_state 725\n",
      "accuracy of the model 0.7064220183486238 random_state 726\n",
      "accuracy of the model 0.6972477064220184 random_state 727\n",
      "accuracy of the model 0.6238532110091743 random_state 728\n",
      "accuracy of the model 0.6513761467889908 random_state 729\n",
      "accuracy of the model 0.6238532110091743 random_state 730\n",
      "accuracy of the model 0.7431192660550459 random_state 731\n",
      "accuracy of the model 0.7431192660550459 random_state 732\n",
      "accuracy of the model 0.6605504587155964 random_state 733\n",
      "accuracy of the model 0.7155963302752294 random_state 734\n",
      "accuracy of the model 0.6422018348623854 random_state 735\n",
      "accuracy of the model 0.6422018348623854 random_state 736\n",
      "accuracy of the model 0.6605504587155964 random_state 737\n",
      "accuracy of the model 0.6697247706422018 random_state 738\n",
      "accuracy of the model 0.6697247706422018 random_state 739\n",
      "accuracy of the model 0.7247706422018348 random_state 740\n",
      "accuracy of the model 0.6697247706422018 random_state 741\n",
      "accuracy of the model 0.6238532110091743 random_state 742\n",
      "accuracy of the model 0.7431192660550459 random_state 743\n",
      "accuracy of the model 0.7798165137614679 random_state 744\n",
      "accuracy of the model 0.7522935779816514 random_state 745\n",
      "accuracy of the model 0.6146788990825688 random_state 746\n",
      "accuracy of the model 0.7247706422018348 random_state 747\n",
      "accuracy of the model 0.6238532110091743 random_state 748\n",
      "accuracy of the model 0.6422018348623854 random_state 749\n",
      "accuracy of the model 0.6697247706422018 random_state 750\n",
      "accuracy of the model 0.6972477064220184 random_state 751\n",
      "accuracy of the model 0.6238532110091743 random_state 752\n",
      "accuracy of the model 0.6422018348623854 random_state 753\n",
      "accuracy of the model 0.6605504587155964 random_state 754\n",
      "accuracy of the model 0.6605504587155964 random_state 755\n",
      "accuracy of the model 0.7431192660550459 random_state 756\n",
      "accuracy of the model 0.6880733944954128 random_state 757\n",
      "accuracy of the model 0.7155963302752294 random_state 758\n",
      "accuracy of the model 0.7064220183486238 random_state 759\n",
      "accuracy of the model 0.7614678899082569 random_state 760\n",
      "accuracy of the model 0.5963302752293578 random_state 761\n",
      "accuracy of the model 0.7064220183486238 random_state 762\n",
      "accuracy of the model 0.6330275229357798 random_state 763\n",
      "accuracy of the model 0.6788990825688074 random_state 764\n",
      "accuracy of the model 0.6788990825688074 random_state 765\n",
      "accuracy of the model 0.7247706422018348 random_state 766\n",
      "accuracy of the model 0.6697247706422018 random_state 767\n",
      "accuracy of the model 0.7431192660550459 random_state 768\n",
      "accuracy of the model 0.7431192660550459 random_state 769\n",
      "accuracy of the model 0.6972477064220184 random_state 770\n",
      "accuracy of the model 0.5963302752293578 random_state 771\n",
      "accuracy of the model 0.7247706422018348 random_state 772\n",
      "accuracy of the model 0.7155963302752294 random_state 773\n",
      "accuracy of the model 0.6880733944954128 random_state 774\n",
      "accuracy of the model 0.6788990825688074 random_state 775\n",
      "accuracy of the model 0.7155963302752294 random_state 776\n",
      "accuracy of the model 0.6605504587155964 random_state 777\n",
      "accuracy of the model 0.6697247706422018 random_state 778\n",
      "accuracy of the model 0.6880733944954128 random_state 779\n",
      "accuracy of the model 0.6788990825688074 random_state 780\n",
      "accuracy of the model 0.7247706422018348 random_state 781\n",
      "accuracy of the model 0.6513761467889908 random_state 782\n",
      "accuracy of the model 0.6972477064220184 random_state 783\n",
      "accuracy of the model 0.6605504587155964 random_state 784\n",
      "accuracy of the model 0.6330275229357798 random_state 785\n",
      "accuracy of the model 0.6880733944954128 random_state 786\n",
      "accuracy of the model 0.6330275229357798 random_state 787\n",
      "accuracy of the model 0.7522935779816514 random_state 788\n",
      "accuracy of the model 0.7522935779816514 random_state 789\n",
      "accuracy of the model 0.7339449541284404 random_state 790\n",
      "accuracy of the model 0.6513761467889908 random_state 791\n",
      "accuracy of the model 0.7064220183486238 random_state 792\n",
      "accuracy of the model 0.7155963302752294 random_state 793\n",
      "accuracy of the model 0.6972477064220184 random_state 794\n",
      "accuracy of the model 0.6513761467889908 random_state 795\n",
      "accuracy of the model 0.7064220183486238 random_state 796\n",
      "accuracy of the model 0.6513761467889908 random_state 797\n",
      "accuracy of the model 0.7706422018348624 random_state 798\n",
      "accuracy of the model 0.6238532110091743 random_state 799\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,800):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    ad=AdaBoostClassifier()\n",
    "    ad.fit(x_train, y_train)\n",
    "    pred=ad.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "203cb491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8165137614678899 in random state 711\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2e12b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7064220183486238 random_state 1\n",
      "accuracy of the optimum model 0.7064220183486238 random_state 1\n",
      "accuracy of the model 0.7431192660550459 random_state 2\n",
      "accuracy of the optimum model 0.7431192660550459 random_state 2\n",
      "accuracy of the model 0.6788990825688074 random_state 3\n",
      "accuracy of the model 0.7431192660550459 random_state 4\n",
      "accuracy of the model 0.7155963302752294 random_state 5\n",
      "accuracy of the model 0.8073394495412844 random_state 6\n",
      "accuracy of the optimum model 0.8073394495412844 random_state 6\n",
      "accuracy of the model 0.6880733944954128 random_state 7\n",
      "accuracy of the model 0.7522935779816514 random_state 8\n",
      "accuracy of the model 0.7064220183486238 random_state 9\n",
      "accuracy of the model 0.6788990825688074 random_state 10\n",
      "accuracy of the model 0.7339449541284404 random_state 11\n",
      "accuracy of the model 0.7247706422018348 random_state 12\n",
      "accuracy of the model 0.6605504587155964 random_state 13\n",
      "accuracy of the model 0.6788990825688074 random_state 14\n",
      "accuracy of the model 0.7889908256880734 random_state 15\n",
      "accuracy of the model 0.6330275229357798 random_state 16\n",
      "accuracy of the model 0.7155963302752294 random_state 17\n",
      "accuracy of the model 0.6513761467889908 random_state 18\n",
      "accuracy of the model 0.7614678899082569 random_state 19\n",
      "accuracy of the model 0.7614678899082569 random_state 20\n",
      "accuracy of the model 0.7706422018348624 random_state 21\n",
      "accuracy of the model 0.7155963302752294 random_state 22\n",
      "accuracy of the model 0.6788990825688074 random_state 23\n",
      "accuracy of the model 0.7155963302752294 random_state 24\n",
      "accuracy of the model 0.7155963302752294 random_state 25\n",
      "accuracy of the model 0.7339449541284404 random_state 26\n",
      "accuracy of the model 0.7614678899082569 random_state 27\n",
      "accuracy of the model 0.6788990825688074 random_state 28\n",
      "accuracy of the model 0.7247706422018348 random_state 29\n",
      "accuracy of the model 0.6605504587155964 random_state 30\n",
      "accuracy of the model 0.6513761467889908 random_state 31\n",
      "accuracy of the model 0.7614678899082569 random_state 32\n",
      "accuracy of the model 0.7247706422018348 random_state 33\n",
      "accuracy of the model 0.7614678899082569 random_state 34\n",
      "accuracy of the model 0.6880733944954128 random_state 35\n",
      "accuracy of the model 0.7247706422018348 random_state 36\n",
      "accuracy of the model 0.6880733944954128 random_state 37\n",
      "accuracy of the model 0.6972477064220184 random_state 38\n",
      "accuracy of the model 0.6697247706422018 random_state 39\n",
      "accuracy of the model 0.6605504587155964 random_state 40\n",
      "accuracy of the model 0.7155963302752294 random_state 41\n",
      "accuracy of the model 0.7064220183486238 random_state 42\n",
      "accuracy of the model 0.7798165137614679 random_state 43\n",
      "accuracy of the model 0.6330275229357798 random_state 44\n",
      "accuracy of the model 0.6605504587155964 random_state 45\n",
      "accuracy of the model 0.6422018348623854 random_state 46\n",
      "accuracy of the model 0.7798165137614679 random_state 47\n",
      "accuracy of the model 0.7155963302752294 random_state 48\n",
      "accuracy of the model 0.6788990825688074 random_state 49\n",
      "accuracy of the model 0.7706422018348624 random_state 50\n",
      "accuracy of the model 0.6788990825688074 random_state 51\n",
      "accuracy of the model 0.6697247706422018 random_state 52\n",
      "accuracy of the model 0.7247706422018348 random_state 53\n",
      "accuracy of the model 0.7339449541284404 random_state 54\n",
      "accuracy of the model 0.7064220183486238 random_state 55\n",
      "accuracy of the model 0.6972477064220184 random_state 56\n",
      "accuracy of the model 0.6697247706422018 random_state 57\n",
      "accuracy of the model 0.7431192660550459 random_state 58\n",
      "accuracy of the model 0.7155963302752294 random_state 59\n",
      "accuracy of the model 0.7614678899082569 random_state 60\n",
      "accuracy of the model 0.7614678899082569 random_state 61\n",
      "accuracy of the model 0.6513761467889908 random_state 62\n",
      "accuracy of the model 0.7522935779816514 random_state 63\n",
      "accuracy of the model 0.7155963302752294 random_state 64\n",
      "accuracy of the model 0.7247706422018348 random_state 65\n",
      "accuracy of the model 0.6330275229357798 random_state 66\n",
      "accuracy of the model 0.7064220183486238 random_state 67\n",
      "accuracy of the model 0.7064220183486238 random_state 68\n",
      "accuracy of the model 0.7155963302752294 random_state 69\n",
      "accuracy of the model 0.7522935779816514 random_state 70\n",
      "accuracy of the model 0.7155963302752294 random_state 71\n",
      "accuracy of the model 0.6513761467889908 random_state 72\n",
      "accuracy of the model 0.7064220183486238 random_state 73\n",
      "accuracy of the model 0.6972477064220184 random_state 74\n",
      "accuracy of the model 0.6605504587155964 random_state 75\n",
      "accuracy of the model 0.6880733944954128 random_state 76\n",
      "accuracy of the model 0.6513761467889908 random_state 77\n",
      "accuracy of the model 0.7064220183486238 random_state 78\n",
      "accuracy of the model 0.6697247706422018 random_state 79\n",
      "accuracy of the model 0.7155963302752294 random_state 80\n",
      "accuracy of the model 0.7431192660550459 random_state 81\n",
      "accuracy of the model 0.7339449541284404 random_state 82\n",
      "accuracy of the model 0.6697247706422018 random_state 83\n",
      "accuracy of the model 0.7431192660550459 random_state 84\n",
      "accuracy of the model 0.6330275229357798 random_state 85\n",
      "accuracy of the model 0.6513761467889908 random_state 86\n",
      "accuracy of the model 0.7522935779816514 random_state 87\n",
      "accuracy of the model 0.6972477064220184 random_state 88\n",
      "accuracy of the model 0.7339449541284404 random_state 89\n",
      "accuracy of the model 0.6972477064220184 random_state 90\n",
      "accuracy of the model 0.6972477064220184 random_state 91\n",
      "accuracy of the model 0.6605504587155964 random_state 92\n",
      "accuracy of the model 0.7614678899082569 random_state 93\n",
      "accuracy of the model 0.6788990825688074 random_state 94\n",
      "accuracy of the model 0.7706422018348624 random_state 95\n",
      "accuracy of the model 0.6788990825688074 random_state 96\n",
      "accuracy of the model 0.6972477064220184 random_state 97\n",
      "accuracy of the model 0.7155963302752294 random_state 98\n",
      "accuracy of the model 0.7614678899082569 random_state 99\n",
      "accuracy of the model 0.6697247706422018 random_state 100\n",
      "accuracy of the model 0.6788990825688074 random_state 101\n",
      "accuracy of the model 0.6972477064220184 random_state 102\n",
      "accuracy of the model 0.7064220183486238 random_state 103\n",
      "accuracy of the model 0.7431192660550459 random_state 104\n",
      "accuracy of the model 0.7155963302752294 random_state 105\n",
      "accuracy of the model 0.6513761467889908 random_state 106\n",
      "accuracy of the model 0.6972477064220184 random_state 107\n",
      "accuracy of the model 0.7614678899082569 random_state 108\n",
      "accuracy of the model 0.7064220183486238 random_state 109\n",
      "accuracy of the model 0.7155963302752294 random_state 110\n",
      "accuracy of the model 0.7339449541284404 random_state 111\n",
      "accuracy of the model 0.6697247706422018 random_state 112\n",
      "accuracy of the model 0.7339449541284404 random_state 113\n",
      "accuracy of the model 0.6513761467889908 random_state 114\n",
      "accuracy of the model 0.7339449541284404 random_state 115\n",
      "accuracy of the model 0.7155963302752294 random_state 116\n",
      "accuracy of the model 0.6697247706422018 random_state 117\n",
      "accuracy of the model 0.7064220183486238 random_state 118\n",
      "accuracy of the model 0.7247706422018348 random_state 119\n",
      "accuracy of the model 0.6605504587155964 random_state 120\n",
      "accuracy of the model 0.7614678899082569 random_state 121\n",
      "accuracy of the model 0.7155963302752294 random_state 122\n",
      "accuracy of the model 0.7064220183486238 random_state 123\n",
      "accuracy of the model 0.7522935779816514 random_state 124\n",
      "accuracy of the model 0.6697247706422018 random_state 125\n",
      "accuracy of the model 0.6513761467889908 random_state 126\n",
      "accuracy of the model 0.6880733944954128 random_state 127\n",
      "accuracy of the model 0.7889908256880734 random_state 128\n",
      "accuracy of the model 0.7155963302752294 random_state 129\n",
      "accuracy of the model 0.7247706422018348 random_state 130\n",
      "accuracy of the model 0.7339449541284404 random_state 131\n",
      "accuracy of the model 0.7064220183486238 random_state 132\n",
      "accuracy of the model 0.7247706422018348 random_state 133\n",
      "accuracy of the model 0.6788990825688074 random_state 134\n",
      "accuracy of the model 0.7339449541284404 random_state 135\n",
      "accuracy of the model 0.7522935779816514 random_state 136\n",
      "accuracy of the model 0.6422018348623854 random_state 137\n",
      "accuracy of the model 0.7064220183486238 random_state 138\n",
      "accuracy of the model 0.7431192660550459 random_state 139\n",
      "accuracy of the model 0.7981651376146789 random_state 140\n",
      "accuracy of the model 0.7064220183486238 random_state 141\n",
      "accuracy of the model 0.7247706422018348 random_state 142\n",
      "accuracy of the model 0.7247706422018348 random_state 143\n",
      "accuracy of the model 0.7155963302752294 random_state 144\n",
      "accuracy of the model 0.6972477064220184 random_state 145\n",
      "accuracy of the model 0.6146788990825688 random_state 146\n",
      "accuracy of the model 0.7981651376146789 random_state 147\n",
      "accuracy of the model 0.7339449541284404 random_state 148\n",
      "accuracy of the model 0.6972477064220184 random_state 149\n",
      "accuracy of the model 0.6055045871559633 random_state 150\n",
      "accuracy of the model 0.7339449541284404 random_state 151\n",
      "accuracy of the model 0.6880733944954128 random_state 152\n",
      "accuracy of the model 0.6422018348623854 random_state 153\n",
      "accuracy of the model 0.7247706422018348 random_state 154\n",
      "accuracy of the model 0.7522935779816514 random_state 155\n",
      "accuracy of the model 0.7431192660550459 random_state 156\n",
      "accuracy of the model 0.7155963302752294 random_state 157\n",
      "accuracy of the model 0.6880733944954128 random_state 158\n",
      "accuracy of the model 0.6972477064220184 random_state 159\n",
      "accuracy of the model 0.7431192660550459 random_state 160\n",
      "accuracy of the model 0.7798165137614679 random_state 161\n",
      "accuracy of the model 0.7339449541284404 random_state 162\n",
      "accuracy of the model 0.7981651376146789 random_state 163\n",
      "accuracy of the model 0.6788990825688074 random_state 164\n",
      "accuracy of the model 0.6788990825688074 random_state 165\n",
      "accuracy of the model 0.7706422018348624 random_state 166\n",
      "accuracy of the model 0.6605504587155964 random_state 167\n",
      "accuracy of the model 0.7522935779816514 random_state 168\n",
      "accuracy of the model 0.6972477064220184 random_state 169\n",
      "accuracy of the model 0.6697247706422018 random_state 170\n",
      "accuracy of the model 0.7798165137614679 random_state 171\n",
      "accuracy of the model 0.6880733944954128 random_state 172\n",
      "accuracy of the model 0.7339449541284404 random_state 173\n",
      "accuracy of the model 0.7431192660550459 random_state 174\n",
      "accuracy of the model 0.7339449541284404 random_state 175\n",
      "accuracy of the model 0.7339449541284404 random_state 176\n",
      "accuracy of the model 0.7064220183486238 random_state 177\n",
      "accuracy of the model 0.7981651376146789 random_state 178\n",
      "accuracy of the model 0.6513761467889908 random_state 179\n",
      "accuracy of the model 0.7155963302752294 random_state 180\n",
      "accuracy of the model 0.7339449541284404 random_state 181\n",
      "accuracy of the model 0.7064220183486238 random_state 182\n",
      "accuracy of the model 0.6880733944954128 random_state 183\n",
      "accuracy of the model 0.6972477064220184 random_state 184\n",
      "accuracy of the model 0.7431192660550459 random_state 185\n",
      "accuracy of the model 0.7155963302752294 random_state 186\n",
      "accuracy of the model 0.7339449541284404 random_state 187\n",
      "accuracy of the model 0.7339449541284404 random_state 188\n",
      "accuracy of the model 0.6788990825688074 random_state 189\n",
      "accuracy of the model 0.7798165137614679 random_state 190\n",
      "accuracy of the model 0.7522935779816514 random_state 191\n",
      "accuracy of the model 0.7706422018348624 random_state 192\n",
      "accuracy of the model 0.7522935779816514 random_state 193\n",
      "accuracy of the model 0.6880733944954128 random_state 194\n",
      "accuracy of the model 0.6788990825688074 random_state 195\n",
      "accuracy of the model 0.6880733944954128 random_state 196\n",
      "accuracy of the model 0.6972477064220184 random_state 197\n",
      "accuracy of the model 0.6880733944954128 random_state 198\n",
      "accuracy of the model 0.7247706422018348 random_state 199\n",
      "accuracy of the model 0.7339449541284404 random_state 200\n",
      "accuracy of the model 0.7431192660550459 random_state 201\n",
      "accuracy of the model 0.7247706422018348 random_state 202\n",
      "accuracy of the model 0.7247706422018348 random_state 203\n",
      "accuracy of the model 0.8256880733944955 random_state 204\n",
      "accuracy of the optimum model 0.8256880733944955 random_state 204\n",
      "accuracy of the model 0.7064220183486238 random_state 205\n",
      "accuracy of the model 0.6788990825688074 random_state 206\n",
      "accuracy of the model 0.7431192660550459 random_state 207\n",
      "accuracy of the model 0.7064220183486238 random_state 208\n",
      "accuracy of the model 0.7798165137614679 random_state 209\n",
      "accuracy of the model 0.6788990825688074 random_state 210\n",
      "accuracy of the model 0.6880733944954128 random_state 211\n",
      "accuracy of the model 0.7064220183486238 random_state 212\n",
      "accuracy of the model 0.6422018348623854 random_state 213\n",
      "accuracy of the model 0.7247706422018348 random_state 214\n",
      "accuracy of the model 0.7522935779816514 random_state 215\n",
      "accuracy of the model 0.6788990825688074 random_state 216\n",
      "accuracy of the model 0.7155963302752294 random_state 217\n",
      "accuracy of the model 0.7706422018348624 random_state 218\n",
      "accuracy of the model 0.6697247706422018 random_state 219\n",
      "accuracy of the model 0.6788990825688074 random_state 220\n",
      "accuracy of the model 0.6880733944954128 random_state 221\n",
      "accuracy of the model 0.6605504587155964 random_state 222\n",
      "accuracy of the model 0.6972477064220184 random_state 223\n",
      "accuracy of the model 0.7706422018348624 random_state 224\n",
      "accuracy of the model 0.6880733944954128 random_state 225\n",
      "accuracy of the model 0.7706422018348624 random_state 226\n",
      "accuracy of the model 0.7064220183486238 random_state 227\n",
      "accuracy of the model 0.7247706422018348 random_state 228\n",
      "accuracy of the model 0.7431192660550459 random_state 229\n",
      "accuracy of the model 0.7064220183486238 random_state 230\n",
      "accuracy of the model 0.7431192660550459 random_state 231\n",
      "accuracy of the model 0.7155963302752294 random_state 232\n",
      "accuracy of the model 0.7247706422018348 random_state 233\n",
      "accuracy of the model 0.7064220183486238 random_state 234\n",
      "accuracy of the model 0.7339449541284404 random_state 235\n",
      "accuracy of the model 0.7706422018348624 random_state 236\n",
      "accuracy of the model 0.6880733944954128 random_state 237\n",
      "accuracy of the model 0.6605504587155964 random_state 238\n",
      "accuracy of the model 0.7247706422018348 random_state 239\n",
      "accuracy of the model 0.7339449541284404 random_state 240\n",
      "accuracy of the model 0.7247706422018348 random_state 241\n",
      "accuracy of the model 0.6422018348623854 random_state 242\n",
      "accuracy of the model 0.6972477064220184 random_state 243\n",
      "accuracy of the model 0.7981651376146789 random_state 244\n",
      "accuracy of the model 0.7431192660550459 random_state 245\n",
      "accuracy of the model 0.7064220183486238 random_state 246\n",
      "accuracy of the model 0.6972477064220184 random_state 247\n",
      "accuracy of the model 0.7798165137614679 random_state 248\n",
      "accuracy of the model 0.7339449541284404 random_state 249\n",
      "accuracy of the model 0.7431192660550459 random_state 250\n",
      "accuracy of the model 0.7614678899082569 random_state 251\n",
      "accuracy of the model 0.6238532110091743 random_state 252\n",
      "accuracy of the model 0.7614678899082569 random_state 253\n",
      "accuracy of the model 0.6880733944954128 random_state 254\n",
      "accuracy of the model 0.6972477064220184 random_state 255\n",
      "accuracy of the model 0.6972477064220184 random_state 256\n",
      "accuracy of the model 0.6880733944954128 random_state 257\n",
      "accuracy of the model 0.7247706422018348 random_state 258\n",
      "accuracy of the model 0.6880733944954128 random_state 259\n",
      "accuracy of the model 0.7247706422018348 random_state 260\n",
      "accuracy of the model 0.7614678899082569 random_state 261\n",
      "accuracy of the model 0.6972477064220184 random_state 262\n",
      "accuracy of the model 0.7706422018348624 random_state 263\n",
      "accuracy of the model 0.7339449541284404 random_state 264\n",
      "accuracy of the model 0.6788990825688074 random_state 265\n",
      "accuracy of the model 0.7522935779816514 random_state 266\n",
      "accuracy of the model 0.7339449541284404 random_state 267\n",
      "accuracy of the model 0.7522935779816514 random_state 268\n",
      "accuracy of the model 0.6972477064220184 random_state 269\n",
      "accuracy of the model 0.7522935779816514 random_state 270\n",
      "accuracy of the model 0.7339449541284404 random_state 271\n",
      "accuracy of the model 0.7064220183486238 random_state 272\n",
      "accuracy of the model 0.6880733944954128 random_state 273\n",
      "accuracy of the model 0.7155963302752294 random_state 274\n",
      "accuracy of the model 0.7706422018348624 random_state 275\n",
      "accuracy of the model 0.6972477064220184 random_state 276\n",
      "accuracy of the model 0.7247706422018348 random_state 277\n",
      "accuracy of the model 0.6972477064220184 random_state 278\n",
      "accuracy of the model 0.6788990825688074 random_state 279\n",
      "accuracy of the model 0.7614678899082569 random_state 280\n",
      "accuracy of the model 0.7431192660550459 random_state 281\n",
      "accuracy of the model 0.7064220183486238 random_state 282\n",
      "accuracy of the model 0.6330275229357798 random_state 283\n",
      "accuracy of the model 0.7155963302752294 random_state 284\n",
      "accuracy of the model 0.7614678899082569 random_state 285\n",
      "accuracy of the model 0.7431192660550459 random_state 286\n",
      "accuracy of the model 0.6697247706422018 random_state 287\n",
      "accuracy of the model 0.7155963302752294 random_state 288\n",
      "accuracy of the model 0.7247706422018348 random_state 289\n",
      "accuracy of the model 0.6972477064220184 random_state 290\n",
      "accuracy of the model 0.7155963302752294 random_state 291\n",
      "accuracy of the model 0.7614678899082569 random_state 292\n",
      "accuracy of the model 0.7339449541284404 random_state 293\n",
      "accuracy of the model 0.6788990825688074 random_state 294\n",
      "accuracy of the model 0.6697247706422018 random_state 295\n",
      "accuracy of the model 0.7155963302752294 random_state 296\n",
      "accuracy of the model 0.7431192660550459 random_state 297\n",
      "accuracy of the model 0.6238532110091743 random_state 298\n",
      "accuracy of the model 0.7522935779816514 random_state 299\n",
      "accuracy of the model 0.7431192660550459 random_state 300\n",
      "accuracy of the model 0.6788990825688074 random_state 301\n",
      "accuracy of the model 0.6788990825688074 random_state 302\n",
      "accuracy of the model 0.6880733944954128 random_state 303\n",
      "accuracy of the model 0.6880733944954128 random_state 304\n",
      "accuracy of the model 0.7706422018348624 random_state 305\n",
      "accuracy of the model 0.7614678899082569 random_state 306\n",
      "accuracy of the model 0.6697247706422018 random_state 307\n",
      "accuracy of the model 0.7247706422018348 random_state 308\n",
      "accuracy of the model 0.7155963302752294 random_state 309\n",
      "accuracy of the model 0.7431192660550459 random_state 310\n",
      "accuracy of the model 0.7339449541284404 random_state 311\n",
      "accuracy of the model 0.6605504587155964 random_state 312\n",
      "accuracy of the model 0.6788990825688074 random_state 313\n",
      "accuracy of the model 0.7522935779816514 random_state 314\n",
      "accuracy of the model 0.7247706422018348 random_state 315\n",
      "accuracy of the model 0.7064220183486238 random_state 316\n",
      "accuracy of the model 0.6330275229357798 random_state 317\n",
      "accuracy of the model 0.6422018348623854 random_state 318\n",
      "accuracy of the model 0.6422018348623854 random_state 319\n",
      "accuracy of the model 0.7064220183486238 random_state 320\n",
      "accuracy of the model 0.7431192660550459 random_state 321\n",
      "accuracy of the model 0.7431192660550459 random_state 322\n",
      "accuracy of the model 0.7247706422018348 random_state 323\n",
      "accuracy of the model 0.6513761467889908 random_state 324\n",
      "accuracy of the model 0.7706422018348624 random_state 325\n",
      "accuracy of the model 0.6972477064220184 random_state 326\n",
      "accuracy of the model 0.7064220183486238 random_state 327\n",
      "accuracy of the model 0.7431192660550459 random_state 328\n",
      "accuracy of the model 0.7155963302752294 random_state 329\n",
      "accuracy of the model 0.6880733944954128 random_state 330\n",
      "accuracy of the model 0.6605504587155964 random_state 331\n",
      "accuracy of the model 0.7155963302752294 random_state 332\n",
      "accuracy of the model 0.7614678899082569 random_state 333\n",
      "accuracy of the model 0.7798165137614679 random_state 334\n",
      "accuracy of the model 0.6880733944954128 random_state 335\n",
      "accuracy of the model 0.6880733944954128 random_state 336\n",
      "accuracy of the model 0.7981651376146789 random_state 337\n",
      "accuracy of the model 0.7064220183486238 random_state 338\n",
      "accuracy of the model 0.7614678899082569 random_state 339\n",
      "accuracy of the model 0.7339449541284404 random_state 340\n",
      "accuracy of the model 0.7155963302752294 random_state 341\n",
      "accuracy of the model 0.6330275229357798 random_state 342\n",
      "accuracy of the model 0.7247706422018348 random_state 343\n",
      "accuracy of the model 0.6880733944954128 random_state 344\n",
      "accuracy of the model 0.7522935779816514 random_state 345\n",
      "accuracy of the model 0.7614678899082569 random_state 346\n",
      "accuracy of the model 0.7706422018348624 random_state 347\n",
      "accuracy of the model 0.7064220183486238 random_state 348\n",
      "accuracy of the model 0.7064220183486238 random_state 349\n",
      "accuracy of the model 0.6605504587155964 random_state 350\n",
      "accuracy of the model 0.7706422018348624 random_state 351\n",
      "accuracy of the model 0.7339449541284404 random_state 352\n",
      "accuracy of the model 0.6697247706422018 random_state 353\n",
      "accuracy of the model 0.7155963302752294 random_state 354\n",
      "accuracy of the model 0.7431192660550459 random_state 355\n",
      "accuracy of the model 0.7155963302752294 random_state 356\n",
      "accuracy of the model 0.7431192660550459 random_state 357\n",
      "accuracy of the model 0.8256880733944955 random_state 358\n",
      "accuracy of the model 0.6880733944954128 random_state 359\n",
      "accuracy of the model 0.7247706422018348 random_state 360\n",
      "accuracy of the model 0.7431192660550459 random_state 361\n",
      "accuracy of the model 0.6788990825688074 random_state 362\n",
      "accuracy of the model 0.7064220183486238 random_state 363\n",
      "accuracy of the model 0.7522935779816514 random_state 364\n",
      "accuracy of the model 0.7522935779816514 random_state 365\n",
      "accuracy of the model 0.7155963302752294 random_state 366\n",
      "accuracy of the model 0.6513761467889908 random_state 367\n",
      "accuracy of the model 0.7064220183486238 random_state 368\n",
      "accuracy of the model 0.6880733944954128 random_state 369\n",
      "accuracy of the model 0.7339449541284404 random_state 370\n",
      "accuracy of the model 0.7155963302752294 random_state 371\n",
      "accuracy of the model 0.6513761467889908 random_state 372\n",
      "accuracy of the model 0.7339449541284404 random_state 373\n",
      "accuracy of the model 0.7706422018348624 random_state 374\n",
      "accuracy of the model 0.7431192660550459 random_state 375\n",
      "accuracy of the model 0.6880733944954128 random_state 376\n",
      "accuracy of the model 0.7706422018348624 random_state 377\n",
      "accuracy of the model 0.7339449541284404 random_state 378\n",
      "accuracy of the model 0.7155963302752294 random_state 379\n",
      "accuracy of the model 0.7064220183486238 random_state 380\n",
      "accuracy of the model 0.6788990825688074 random_state 381\n",
      "accuracy of the model 0.6422018348623854 random_state 382\n",
      "accuracy of the model 0.6697247706422018 random_state 383\n",
      "accuracy of the model 0.6605504587155964 random_state 384\n",
      "accuracy of the model 0.7064220183486238 random_state 385\n",
      "accuracy of the model 0.7247706422018348 random_state 386\n",
      "accuracy of the model 0.6238532110091743 random_state 387\n",
      "accuracy of the model 0.6972477064220184 random_state 388\n",
      "accuracy of the model 0.7522935779816514 random_state 389\n",
      "accuracy of the model 0.6972477064220184 random_state 390\n",
      "accuracy of the model 0.7522935779816514 random_state 391\n",
      "accuracy of the model 0.6513761467889908 random_state 392\n",
      "accuracy of the model 0.7247706422018348 random_state 393\n",
      "accuracy of the model 0.6605504587155964 random_state 394\n",
      "accuracy of the model 0.6422018348623854 random_state 395\n",
      "accuracy of the model 0.7706422018348624 random_state 396\n",
      "accuracy of the model 0.7614678899082569 random_state 397\n",
      "accuracy of the model 0.7339449541284404 random_state 398\n",
      "accuracy of the model 0.6972477064220184 random_state 399\n",
      "accuracy of the model 0.7247706422018348 random_state 400\n",
      "accuracy of the model 0.6513761467889908 random_state 401\n",
      "accuracy of the model 0.7522935779816514 random_state 402\n",
      "accuracy of the model 0.6788990825688074 random_state 403\n",
      "accuracy of the model 0.6605504587155964 random_state 404\n",
      "accuracy of the model 0.7522935779816514 random_state 405\n",
      "accuracy of the model 0.7431192660550459 random_state 406\n",
      "accuracy of the model 0.6972477064220184 random_state 407\n",
      "accuracy of the model 0.6330275229357798 random_state 408\n",
      "accuracy of the model 0.6513761467889908 random_state 409\n",
      "accuracy of the model 0.7706422018348624 random_state 410\n",
      "accuracy of the model 0.6788990825688074 random_state 411\n",
      "accuracy of the model 0.6788990825688074 random_state 412\n",
      "accuracy of the model 0.7339449541284404 random_state 413\n",
      "accuracy of the model 0.6972477064220184 random_state 414\n",
      "accuracy of the model 0.7339449541284404 random_state 415\n",
      "accuracy of the model 0.7431192660550459 random_state 416\n",
      "accuracy of the model 0.7522935779816514 random_state 417\n",
      "accuracy of the model 0.7247706422018348 random_state 418\n",
      "accuracy of the model 0.6697247706422018 random_state 419\n",
      "accuracy of the model 0.7155963302752294 random_state 420\n",
      "accuracy of the model 0.7339449541284404 random_state 421\n",
      "accuracy of the model 0.7247706422018348 random_state 422\n",
      "accuracy of the model 0.7155963302752294 random_state 423\n",
      "accuracy of the model 0.7339449541284404 random_state 424\n",
      "accuracy of the model 0.7339449541284404 random_state 425\n",
      "accuracy of the model 0.6330275229357798 random_state 426\n",
      "accuracy of the model 0.6788990825688074 random_state 427\n",
      "accuracy of the model 0.7339449541284404 random_state 428\n",
      "accuracy of the model 0.6697247706422018 random_state 429\n",
      "accuracy of the model 0.7155963302752294 random_state 430\n",
      "accuracy of the model 0.7247706422018348 random_state 431\n",
      "accuracy of the model 0.7155963302752294 random_state 432\n",
      "accuracy of the model 0.7614678899082569 random_state 433\n",
      "accuracy of the model 0.6880733944954128 random_state 434\n",
      "accuracy of the model 0.6330275229357798 random_state 435\n",
      "accuracy of the model 0.6972477064220184 random_state 436\n",
      "accuracy of the model 0.7247706422018348 random_state 437\n",
      "accuracy of the model 0.7431192660550459 random_state 438\n",
      "accuracy of the model 0.6880733944954128 random_state 439\n",
      "accuracy of the model 0.7155963302752294 random_state 440\n",
      "accuracy of the model 0.6697247706422018 random_state 441\n",
      "accuracy of the model 0.7981651376146789 random_state 442\n",
      "accuracy of the model 0.6605504587155964 random_state 443\n",
      "accuracy of the model 0.7247706422018348 random_state 444\n",
      "accuracy of the model 0.7431192660550459 random_state 445\n",
      "accuracy of the model 0.6513761467889908 random_state 446\n",
      "accuracy of the model 0.6972477064220184 random_state 447\n",
      "accuracy of the model 0.6513761467889908 random_state 448\n",
      "accuracy of the model 0.7064220183486238 random_state 449\n",
      "accuracy of the model 0.6788990825688074 random_state 450\n",
      "accuracy of the model 0.6697247706422018 random_state 451\n",
      "accuracy of the model 0.6605504587155964 random_state 452\n",
      "accuracy of the model 0.7798165137614679 random_state 453\n",
      "accuracy of the model 0.6972477064220184 random_state 454\n",
      "accuracy of the model 0.7431192660550459 random_state 455\n",
      "accuracy of the model 0.6972477064220184 random_state 456\n",
      "accuracy of the model 0.6697247706422018 random_state 457\n",
      "accuracy of the model 0.6788990825688074 random_state 458\n",
      "accuracy of the model 0.6788990825688074 random_state 459\n",
      "accuracy of the model 0.6972477064220184 random_state 460\n",
      "accuracy of the model 0.6697247706422018 random_state 461\n",
      "accuracy of the model 0.7798165137614679 random_state 462\n",
      "accuracy of the model 0.6697247706422018 random_state 463\n",
      "accuracy of the model 0.6605504587155964 random_state 464\n",
      "accuracy of the model 0.7247706422018348 random_state 465\n",
      "accuracy of the model 0.7522935779816514 random_state 466\n",
      "accuracy of the model 0.7064220183486238 random_state 467\n",
      "accuracy of the model 0.7339449541284404 random_state 468\n",
      "accuracy of the model 0.7522935779816514 random_state 469\n",
      "accuracy of the model 0.7339449541284404 random_state 470\n",
      "accuracy of the model 0.6697247706422018 random_state 471\n",
      "accuracy of the model 0.7339449541284404 random_state 472\n",
      "accuracy of the model 0.7431192660550459 random_state 473\n",
      "accuracy of the model 0.7155963302752294 random_state 474\n",
      "accuracy of the model 0.7889908256880734 random_state 475\n",
      "accuracy of the model 0.7522935779816514 random_state 476\n",
      "accuracy of the model 0.6972477064220184 random_state 477\n",
      "accuracy of the model 0.7614678899082569 random_state 478\n",
      "accuracy of the model 0.7155963302752294 random_state 479\n",
      "accuracy of the model 0.6513761467889908 random_state 480\n",
      "accuracy of the model 0.6972477064220184 random_state 481\n",
      "accuracy of the model 0.6513761467889908 random_state 482\n",
      "accuracy of the model 0.6513761467889908 random_state 483\n",
      "accuracy of the model 0.7339449541284404 random_state 484\n",
      "accuracy of the model 0.7247706422018348 random_state 485\n",
      "accuracy of the model 0.7431192660550459 random_state 486\n",
      "accuracy of the model 0.7798165137614679 random_state 487\n",
      "accuracy of the model 0.7155963302752294 random_state 488\n",
      "accuracy of the model 0.7064220183486238 random_state 489\n",
      "accuracy of the model 0.7522935779816514 random_state 490\n",
      "accuracy of the model 0.7706422018348624 random_state 491\n",
      "accuracy of the model 0.7247706422018348 random_state 492\n",
      "accuracy of the model 0.7614678899082569 random_state 493\n",
      "accuracy of the model 0.7706422018348624 random_state 494\n",
      "accuracy of the model 0.6330275229357798 random_state 495\n",
      "accuracy of the model 0.7614678899082569 random_state 496\n",
      "accuracy of the model 0.7247706422018348 random_state 497\n",
      "accuracy of the model 0.7339449541284404 random_state 498\n",
      "accuracy of the model 0.7064220183486238 random_state 499\n",
      "accuracy of the model 0.7155963302752294 random_state 500\n",
      "accuracy of the model 0.7339449541284404 random_state 501\n",
      "accuracy of the model 0.7155963302752294 random_state 502\n",
      "accuracy of the model 0.6788990825688074 random_state 503\n",
      "accuracy of the model 0.6972477064220184 random_state 504\n",
      "accuracy of the model 0.6972477064220184 random_state 505\n",
      "accuracy of the model 0.7155963302752294 random_state 506\n",
      "accuracy of the model 0.7522935779816514 random_state 507\n",
      "accuracy of the model 0.7339449541284404 random_state 508\n",
      "accuracy of the model 0.7798165137614679 random_state 509\n",
      "accuracy of the model 0.7614678899082569 random_state 510\n",
      "accuracy of the model 0.7706422018348624 random_state 511\n",
      "accuracy of the model 0.7247706422018348 random_state 512\n",
      "accuracy of the model 0.6972477064220184 random_state 513\n",
      "accuracy of the model 0.7522935779816514 random_state 514\n",
      "accuracy of the model 0.6880733944954128 random_state 515\n",
      "accuracy of the model 0.7706422018348624 random_state 516\n",
      "accuracy of the model 0.7339449541284404 random_state 517\n",
      "accuracy of the model 0.7706422018348624 random_state 518\n",
      "accuracy of the model 0.6880733944954128 random_state 519\n",
      "accuracy of the model 0.7247706422018348 random_state 520\n",
      "accuracy of the model 0.6697247706422018 random_state 521\n",
      "accuracy of the model 0.7155963302752294 random_state 522\n",
      "accuracy of the model 0.7522935779816514 random_state 523\n",
      "accuracy of the model 0.7431192660550459 random_state 524\n",
      "accuracy of the model 0.6605504587155964 random_state 525\n",
      "accuracy of the model 0.6422018348623854 random_state 526\n",
      "accuracy of the model 0.6788990825688074 random_state 527\n",
      "accuracy of the model 0.7614678899082569 random_state 528\n",
      "accuracy of the model 0.7339449541284404 random_state 529\n",
      "accuracy of the model 0.7247706422018348 random_state 530\n",
      "accuracy of the model 0.6238532110091743 random_state 531\n",
      "accuracy of the model 0.7064220183486238 random_state 532\n",
      "accuracy of the model 0.7247706422018348 random_state 533\n",
      "accuracy of the model 0.7431192660550459 random_state 534\n",
      "accuracy of the model 0.6788990825688074 random_state 535\n",
      "accuracy of the model 0.7155963302752294 random_state 536\n",
      "accuracy of the model 0.7339449541284404 random_state 537\n",
      "accuracy of the model 0.7614678899082569 random_state 538\n",
      "accuracy of the model 0.7155963302752294 random_state 539\n",
      "accuracy of the model 0.7064220183486238 random_state 540\n",
      "accuracy of the model 0.8073394495412844 random_state 541\n",
      "accuracy of the model 0.6513761467889908 random_state 542\n",
      "accuracy of the model 0.6972477064220184 random_state 543\n",
      "accuracy of the model 0.6972477064220184 random_state 544\n",
      "accuracy of the model 0.7339449541284404 random_state 545\n",
      "accuracy of the model 0.6697247706422018 random_state 546\n",
      "accuracy of the model 0.6513761467889908 random_state 547\n",
      "accuracy of the model 0.7981651376146789 random_state 548\n",
      "accuracy of the model 0.7706422018348624 random_state 549\n",
      "accuracy of the model 0.7339449541284404 random_state 550\n",
      "accuracy of the model 0.6880733944954128 random_state 551\n",
      "accuracy of the model 0.8073394495412844 random_state 552\n",
      "accuracy of the model 0.7522935779816514 random_state 553\n",
      "accuracy of the model 0.7614678899082569 random_state 554\n",
      "accuracy of the model 0.6880733944954128 random_state 555\n",
      "accuracy of the model 0.7247706422018348 random_state 556\n",
      "accuracy of the model 0.7064220183486238 random_state 557\n",
      "accuracy of the model 0.6605504587155964 random_state 558\n",
      "accuracy of the model 0.7155963302752294 random_state 559\n",
      "accuracy of the model 0.6788990825688074 random_state 560\n",
      "accuracy of the model 0.6788990825688074 random_state 561\n",
      "accuracy of the model 0.7339449541284404 random_state 562\n",
      "accuracy of the model 0.7064220183486238 random_state 563\n",
      "accuracy of the model 0.7247706422018348 random_state 564\n",
      "accuracy of the model 0.7155963302752294 random_state 565\n",
      "accuracy of the model 0.7064220183486238 random_state 566\n",
      "accuracy of the model 0.6880733944954128 random_state 567\n",
      "accuracy of the model 0.7431192660550459 random_state 568\n",
      "accuracy of the model 0.7339449541284404 random_state 569\n",
      "accuracy of the model 0.6788990825688074 random_state 570\n",
      "accuracy of the model 0.6697247706422018 random_state 571\n",
      "accuracy of the model 0.7431192660550459 random_state 572\n",
      "accuracy of the model 0.7614678899082569 random_state 573\n",
      "accuracy of the model 0.6697247706422018 random_state 574\n",
      "accuracy of the model 0.6880733944954128 random_state 575\n",
      "accuracy of the model 0.6972477064220184 random_state 576\n",
      "accuracy of the model 0.7798165137614679 random_state 577\n",
      "accuracy of the model 0.7431192660550459 random_state 578\n",
      "accuracy of the model 0.7339449541284404 random_state 579\n",
      "accuracy of the model 0.7522935779816514 random_state 580\n",
      "accuracy of the model 0.7155963302752294 random_state 581\n",
      "accuracy of the model 0.7247706422018348 random_state 582\n",
      "accuracy of the model 0.7798165137614679 random_state 583\n",
      "accuracy of the model 0.6513761467889908 random_state 584\n",
      "accuracy of the model 0.6697247706422018 random_state 585\n",
      "accuracy of the model 0.7614678899082569 random_state 586\n",
      "accuracy of the model 0.7706422018348624 random_state 587\n",
      "accuracy of the model 0.7339449541284404 random_state 588\n",
      "accuracy of the model 0.7247706422018348 random_state 589\n",
      "accuracy of the model 0.6788990825688074 random_state 590\n",
      "accuracy of the model 0.6697247706422018 random_state 591\n",
      "accuracy of the model 0.7522935779816514 random_state 592\n",
      "accuracy of the model 0.6972477064220184 random_state 593\n",
      "accuracy of the model 0.7889908256880734 random_state 594\n",
      "accuracy of the model 0.6513761467889908 random_state 595\n",
      "accuracy of the model 0.7155963302752294 random_state 596\n",
      "accuracy of the model 0.6605504587155964 random_state 597\n",
      "accuracy of the model 0.7522935779816514 random_state 598\n",
      "accuracy of the model 0.6788990825688074 random_state 599\n",
      "accuracy of the model 0.6788990825688074 random_state 600\n",
      "accuracy of the model 0.6972477064220184 random_state 601\n",
      "accuracy of the model 0.7064220183486238 random_state 602\n",
      "accuracy of the model 0.7614678899082569 random_state 603\n",
      "accuracy of the model 0.6880733944954128 random_state 604\n",
      "accuracy of the model 0.6880733944954128 random_state 605\n",
      "accuracy of the model 0.7339449541284404 random_state 606\n",
      "accuracy of the model 0.7155963302752294 random_state 607\n",
      "accuracy of the model 0.7064220183486238 random_state 608\n",
      "accuracy of the model 0.6972477064220184 random_state 609\n",
      "accuracy of the model 0.7339449541284404 random_state 610\n",
      "accuracy of the model 0.7155963302752294 random_state 611\n",
      "accuracy of the model 0.7706422018348624 random_state 612\n",
      "accuracy of the model 0.7339449541284404 random_state 613\n",
      "accuracy of the model 0.6513761467889908 random_state 614\n",
      "accuracy of the model 0.6972477064220184 random_state 615\n",
      "accuracy of the model 0.6788990825688074 random_state 616\n",
      "accuracy of the model 0.7522935779816514 random_state 617\n",
      "accuracy of the model 0.7064220183486238 random_state 618\n",
      "accuracy of the model 0.6697247706422018 random_state 619\n",
      "accuracy of the model 0.7155963302752294 random_state 620\n",
      "accuracy of the model 0.7522935779816514 random_state 621\n",
      "accuracy of the model 0.7064220183486238 random_state 622\n",
      "accuracy of the model 0.7155963302752294 random_state 623\n",
      "accuracy of the model 0.7522935779816514 random_state 624\n",
      "accuracy of the model 0.7614678899082569 random_state 625\n",
      "accuracy of the model 0.7064220183486238 random_state 626\n",
      "accuracy of the model 0.6788990825688074 random_state 627\n",
      "accuracy of the model 0.6880733944954128 random_state 628\n",
      "accuracy of the model 0.6605504587155964 random_state 629\n",
      "accuracy of the model 0.7431192660550459 random_state 630\n",
      "accuracy of the model 0.6880733944954128 random_state 631\n",
      "accuracy of the model 0.6422018348623854 random_state 632\n",
      "accuracy of the model 0.7706422018348624 random_state 633\n",
      "accuracy of the model 0.7614678899082569 random_state 634\n",
      "accuracy of the model 0.7431192660550459 random_state 635\n",
      "accuracy of the model 0.6513761467889908 random_state 636\n",
      "accuracy of the model 0.6880733944954128 random_state 637\n",
      "accuracy of the model 0.8073394495412844 random_state 638\n",
      "accuracy of the model 0.7522935779816514 random_state 639\n",
      "accuracy of the model 0.6972477064220184 random_state 640\n",
      "accuracy of the model 0.7339449541284404 random_state 641\n",
      "accuracy of the model 0.7522935779816514 random_state 642\n",
      "accuracy of the model 0.7247706422018348 random_state 643\n",
      "accuracy of the model 0.6697247706422018 random_state 644\n",
      "accuracy of the model 0.6972477064220184 random_state 645\n",
      "accuracy of the model 0.7064220183486238 random_state 646\n",
      "accuracy of the model 0.6330275229357798 random_state 647\n",
      "accuracy of the model 0.7339449541284404 random_state 648\n",
      "accuracy of the model 0.8256880733944955 random_state 649\n",
      "accuracy of the model 0.6880733944954128 random_state 650\n",
      "accuracy of the model 0.6513761467889908 random_state 651\n",
      "accuracy of the model 0.6880733944954128 random_state 652\n",
      "accuracy of the model 0.6788990825688074 random_state 653\n",
      "accuracy of the model 0.7981651376146789 random_state 654\n",
      "accuracy of the model 0.7064220183486238 random_state 655\n",
      "accuracy of the model 0.7155963302752294 random_state 656\n",
      "accuracy of the model 0.7339449541284404 random_state 657\n",
      "accuracy of the model 0.6697247706422018 random_state 658\n",
      "accuracy of the model 0.6788990825688074 random_state 659\n",
      "accuracy of the model 0.7064220183486238 random_state 660\n",
      "accuracy of the model 0.6972477064220184 random_state 661\n",
      "accuracy of the model 0.7706422018348624 random_state 662\n",
      "accuracy of the model 0.7339449541284404 random_state 663\n",
      "accuracy of the model 0.7798165137614679 random_state 664\n",
      "accuracy of the model 0.6788990825688074 random_state 665\n",
      "accuracy of the model 0.7155963302752294 random_state 666\n",
      "accuracy of the model 0.7706422018348624 random_state 667\n",
      "accuracy of the model 0.6238532110091743 random_state 668\n",
      "accuracy of the model 0.7522935779816514 random_state 669\n",
      "accuracy of the model 0.7064220183486238 random_state 670\n",
      "accuracy of the model 0.7706422018348624 random_state 671\n",
      "accuracy of the model 0.6880733944954128 random_state 672\n",
      "accuracy of the model 0.7247706422018348 random_state 673\n",
      "accuracy of the model 0.8073394495412844 random_state 674\n",
      "accuracy of the model 0.7339449541284404 random_state 675\n",
      "accuracy of the model 0.7339449541284404 random_state 676\n",
      "accuracy of the model 0.7522935779816514 random_state 677\n",
      "accuracy of the model 0.7339449541284404 random_state 678\n",
      "accuracy of the model 0.7064220183486238 random_state 679\n",
      "accuracy of the model 0.6605504587155964 random_state 680\n",
      "accuracy of the model 0.7431192660550459 random_state 681\n",
      "accuracy of the model 0.7339449541284404 random_state 682\n",
      "accuracy of the model 0.7614678899082569 random_state 683\n",
      "accuracy of the model 0.7064220183486238 random_state 684\n",
      "accuracy of the model 0.6697247706422018 random_state 685\n",
      "accuracy of the model 0.7431192660550459 random_state 686\n",
      "accuracy of the model 0.7064220183486238 random_state 687\n",
      "accuracy of the model 0.7155963302752294 random_state 688\n",
      "accuracy of the model 0.6513761467889908 random_state 689\n",
      "accuracy of the model 0.6788990825688074 random_state 690\n",
      "accuracy of the model 0.7247706422018348 random_state 691\n",
      "accuracy of the model 0.6788990825688074 random_state 692\n",
      "accuracy of the model 0.7064220183486238 random_state 693\n",
      "accuracy of the model 0.7064220183486238 random_state 694\n",
      "accuracy of the model 0.7431192660550459 random_state 695\n",
      "accuracy of the model 0.7064220183486238 random_state 696\n",
      "accuracy of the model 0.7064220183486238 random_state 697\n",
      "accuracy of the model 0.7889908256880734 random_state 698\n",
      "accuracy of the model 0.6880733944954128 random_state 699\n",
      "accuracy of the model 0.7706422018348624 random_state 700\n",
      "accuracy of the model 0.7247706422018348 random_state 701\n",
      "accuracy of the model 0.7339449541284404 random_state 702\n",
      "accuracy of the model 0.6972477064220184 random_state 703\n",
      "accuracy of the model 0.7247706422018348 random_state 704\n",
      "accuracy of the model 0.6513761467889908 random_state 705\n",
      "accuracy of the model 0.7889908256880734 random_state 706\n",
      "accuracy of the model 0.7155963302752294 random_state 707\n",
      "accuracy of the model 0.7706422018348624 random_state 708\n",
      "accuracy of the model 0.7247706422018348 random_state 709\n",
      "accuracy of the model 0.6788990825688074 random_state 710\n",
      "accuracy of the model 0.7706422018348624 random_state 711\n",
      "accuracy of the model 0.7798165137614679 random_state 712\n",
      "accuracy of the model 0.7247706422018348 random_state 713\n",
      "accuracy of the model 0.6513761467889908 random_state 714\n",
      "accuracy of the model 0.6972477064220184 random_state 715\n",
      "accuracy of the model 0.7614678899082569 random_state 716\n",
      "accuracy of the model 0.7155963302752294 random_state 717\n",
      "accuracy of the model 0.7247706422018348 random_state 718\n",
      "accuracy of the model 0.7064220183486238 random_state 719\n",
      "accuracy of the model 0.6513761467889908 random_state 720\n",
      "accuracy of the model 0.7247706422018348 random_state 721\n",
      "accuracy of the model 0.7522935779816514 random_state 722\n",
      "accuracy of the model 0.6788990825688074 random_state 723\n",
      "accuracy of the model 0.6972477064220184 random_state 724\n",
      "accuracy of the model 0.6972477064220184 random_state 725\n",
      "accuracy of the model 0.7247706422018348 random_state 726\n",
      "accuracy of the model 0.6146788990825688 random_state 727\n",
      "accuracy of the model 0.6513761467889908 random_state 728\n",
      "accuracy of the model 0.6330275229357798 random_state 729\n",
      "accuracy of the model 0.6880733944954128 random_state 730\n",
      "accuracy of the model 0.7981651376146789 random_state 731\n",
      "accuracy of the model 0.7614678899082569 random_state 732\n",
      "accuracy of the model 0.7339449541284404 random_state 733\n",
      "accuracy of the model 0.7247706422018348 random_state 734\n",
      "accuracy of the model 0.6605504587155964 random_state 735\n",
      "accuracy of the model 0.6422018348623854 random_state 736\n",
      "accuracy of the model 0.7247706422018348 random_state 737\n",
      "accuracy of the model 0.7431192660550459 random_state 738\n",
      "accuracy of the model 0.6788990825688074 random_state 739\n",
      "accuracy of the model 0.7339449541284404 random_state 740\n",
      "accuracy of the model 0.7339449541284404 random_state 741\n",
      "accuracy of the model 0.6880733944954128 random_state 742\n",
      "accuracy of the model 0.7614678899082569 random_state 743\n",
      "accuracy of the model 0.7522935779816514 random_state 744\n",
      "accuracy of the model 0.7798165137614679 random_state 745\n",
      "accuracy of the model 0.6422018348623854 random_state 746\n",
      "accuracy of the model 0.7889908256880734 random_state 747\n",
      "accuracy of the model 0.7247706422018348 random_state 748\n",
      "accuracy of the model 0.7064220183486238 random_state 749\n",
      "accuracy of the model 0.7431192660550459 random_state 750\n",
      "accuracy of the model 0.7155963302752294 random_state 751\n",
      "accuracy of the model 0.6513761467889908 random_state 752\n",
      "accuracy of the model 0.6697247706422018 random_state 753\n",
      "accuracy of the model 0.6788990825688074 random_state 754\n",
      "accuracy of the model 0.7522935779816514 random_state 755\n",
      "accuracy of the model 0.7247706422018348 random_state 756\n",
      "accuracy of the model 0.7339449541284404 random_state 757\n",
      "accuracy of the model 0.7247706422018348 random_state 758\n",
      "accuracy of the model 0.7064220183486238 random_state 759\n",
      "accuracy of the model 0.7706422018348624 random_state 760\n",
      "accuracy of the model 0.7155963302752294 random_state 761\n",
      "accuracy of the model 0.7706422018348624 random_state 762\n",
      "accuracy of the model 0.7064220183486238 random_state 763\n",
      "accuracy of the model 0.6697247706422018 random_state 764\n",
      "accuracy of the model 0.6972477064220184 random_state 765\n",
      "accuracy of the model 0.6972477064220184 random_state 766\n",
      "accuracy of the model 0.6880733944954128 random_state 767\n",
      "accuracy of the model 0.7339449541284404 random_state 768\n",
      "accuracy of the model 0.7798165137614679 random_state 769\n",
      "accuracy of the model 0.7247706422018348 random_state 770\n",
      "accuracy of the model 0.6055045871559633 random_state 771\n",
      "accuracy of the model 0.6697247706422018 random_state 772\n",
      "accuracy of the model 0.7431192660550459 random_state 773\n",
      "accuracy of the model 0.7339449541284404 random_state 774\n",
      "accuracy of the model 0.7522935779816514 random_state 775\n",
      "accuracy of the model 0.7247706422018348 random_state 776\n",
      "accuracy of the model 0.6513761467889908 random_state 777\n",
      "accuracy of the model 0.7064220183486238 random_state 778\n",
      "accuracy of the model 0.7431192660550459 random_state 779\n",
      "accuracy of the model 0.7798165137614679 random_state 780\n",
      "accuracy of the model 0.7155963302752294 random_state 781\n",
      "accuracy of the model 0.6880733944954128 random_state 782\n",
      "accuracy of the model 0.7247706422018348 random_state 783\n",
      "accuracy of the model 0.6788990825688074 random_state 784\n",
      "accuracy of the model 0.6788990825688074 random_state 785\n",
      "accuracy of the model 0.6880733944954128 random_state 786\n",
      "accuracy of the model 0.7064220183486238 random_state 787\n",
      "accuracy of the model 0.7614678899082569 random_state 788\n",
      "accuracy of the model 0.7706422018348624 random_state 789\n",
      "accuracy of the model 0.7889908256880734 random_state 790\n",
      "accuracy of the model 0.7798165137614679 random_state 791\n",
      "accuracy of the model 0.7431192660550459 random_state 792\n",
      "accuracy of the model 0.7431192660550459 random_state 793\n",
      "accuracy of the model 0.7155963302752294 random_state 794\n",
      "accuracy of the model 0.7247706422018348 random_state 795\n",
      "accuracy of the model 0.7706422018348624 random_state 796\n",
      "accuracy of the model 0.7431192660550459 random_state 797\n",
      "accuracy of the model 0.7064220183486238 random_state 798\n",
      "accuracy of the model 0.7339449541284404 random_state 799\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,800):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    gc=GradientBoostingClassifier()\n",
    "    gc.fit(x_train, y_train)\n",
    "    pred=gc.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a98568d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8256880733944955 in random state 204\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c52945bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7431192660550459 random_state 1\n",
      "accuracy of the optimum model 0.7431192660550459 random_state 1\n",
      "accuracy of the model 0.6697247706422018 random_state 2\n",
      "accuracy of the model 0.7522935779816514 random_state 3\n",
      "accuracy of the optimum model 0.7522935779816514 random_state 3\n",
      "accuracy of the model 0.7064220183486238 random_state 4\n",
      "accuracy of the model 0.6605504587155964 random_state 5\n",
      "accuracy of the model 0.7889908256880734 random_state 6\n",
      "accuracy of the optimum model 0.7889908256880734 random_state 6\n",
      "accuracy of the model 0.7155963302752294 random_state 7\n",
      "accuracy of the model 0.7614678899082569 random_state 8\n",
      "accuracy of the model 0.7064220183486238 random_state 9\n",
      "accuracy of the model 0.7431192660550459 random_state 10\n",
      "accuracy of the model 0.7064220183486238 random_state 11\n",
      "accuracy of the model 0.7247706422018348 random_state 12\n",
      "accuracy of the model 0.6880733944954128 random_state 13\n",
      "accuracy of the model 0.6697247706422018 random_state 14\n",
      "accuracy of the model 0.7522935779816514 random_state 15\n",
      "accuracy of the model 0.6513761467889908 random_state 16\n",
      "accuracy of the model 0.7247706422018348 random_state 17\n",
      "accuracy of the model 0.7155963302752294 random_state 18\n",
      "accuracy of the model 0.7614678899082569 random_state 19\n",
      "accuracy of the model 0.7706422018348624 random_state 20\n",
      "accuracy of the model 0.7339449541284404 random_state 21\n",
      "accuracy of the model 0.7339449541284404 random_state 22\n",
      "accuracy of the model 0.7339449541284404 random_state 23\n",
      "accuracy of the model 0.7339449541284404 random_state 24\n",
      "accuracy of the model 0.7339449541284404 random_state 25\n",
      "accuracy of the model 0.7064220183486238 random_state 26\n",
      "accuracy of the model 0.7339449541284404 random_state 27\n",
      "accuracy of the model 0.7522935779816514 random_state 28\n",
      "accuracy of the model 0.6972477064220184 random_state 29\n",
      "accuracy of the model 0.7431192660550459 random_state 30\n",
      "accuracy of the model 0.7339449541284404 random_state 31\n",
      "accuracy of the model 0.7614678899082569 random_state 32\n",
      "accuracy of the model 0.7155963302752294 random_state 33\n",
      "accuracy of the model 0.7431192660550459 random_state 34\n",
      "accuracy of the model 0.7064220183486238 random_state 35\n",
      "accuracy of the model 0.6788990825688074 random_state 36\n",
      "accuracy of the model 0.7064220183486238 random_state 37\n",
      "accuracy of the model 0.7064220183486238 random_state 38\n",
      "accuracy of the model 0.7155963302752294 random_state 39\n",
      "accuracy of the model 0.7155963302752294 random_state 40\n",
      "accuracy of the model 0.7247706422018348 random_state 41\n",
      "accuracy of the model 0.7064220183486238 random_state 42\n",
      "accuracy of the model 0.7706422018348624 random_state 43\n",
      "accuracy of the model 0.6880733944954128 random_state 44\n",
      "accuracy of the model 0.7522935779816514 random_state 45\n",
      "accuracy of the model 0.6605504587155964 random_state 46\n",
      "accuracy of the model 0.7522935779816514 random_state 47\n",
      "accuracy of the model 0.7155963302752294 random_state 48\n",
      "accuracy of the model 0.6972477064220184 random_state 49\n",
      "accuracy of the model 0.7339449541284404 random_state 50\n",
      "accuracy of the model 0.7155963302752294 random_state 51\n",
      "accuracy of the model 0.7155963302752294 random_state 52\n",
      "accuracy of the model 0.7064220183486238 random_state 53\n",
      "accuracy of the model 0.6972477064220184 random_state 54\n",
      "accuracy of the model 0.7706422018348624 random_state 55\n",
      "accuracy of the model 0.6972477064220184 random_state 56\n",
      "accuracy of the model 0.7155963302752294 random_state 57\n",
      "accuracy of the model 0.7614678899082569 random_state 58\n",
      "accuracy of the model 0.7247706422018348 random_state 59\n",
      "accuracy of the model 0.7706422018348624 random_state 60\n",
      "accuracy of the model 0.7155963302752294 random_state 61\n",
      "accuracy of the model 0.7247706422018348 random_state 62\n",
      "accuracy of the model 0.7155963302752294 random_state 63\n",
      "accuracy of the model 0.7614678899082569 random_state 64\n",
      "accuracy of the model 0.7339449541284404 random_state 65\n",
      "accuracy of the model 0.7522935779816514 random_state 66\n",
      "accuracy of the model 0.7981651376146789 random_state 67\n",
      "accuracy of the optimum model 0.7981651376146789 random_state 67\n",
      "accuracy of the model 0.7798165137614679 random_state 68\n",
      "accuracy of the model 0.7706422018348624 random_state 69\n",
      "accuracy of the model 0.7339449541284404 random_state 70\n",
      "accuracy of the model 0.7889908256880734 random_state 71\n",
      "accuracy of the model 0.7522935779816514 random_state 72\n",
      "accuracy of the model 0.7064220183486238 random_state 73\n",
      "accuracy of the model 0.7339449541284404 random_state 74\n",
      "accuracy of the model 0.6972477064220184 random_state 75\n",
      "accuracy of the model 0.7522935779816514 random_state 76\n",
      "accuracy of the model 0.6422018348623854 random_state 77\n",
      "accuracy of the model 0.7155963302752294 random_state 78\n",
      "accuracy of the model 0.7064220183486238 random_state 79\n",
      "accuracy of the model 0.7614678899082569 random_state 80\n",
      "accuracy of the model 0.7614678899082569 random_state 81\n",
      "accuracy of the model 0.7155963302752294 random_state 82\n",
      "accuracy of the model 0.6605504587155964 random_state 83\n",
      "accuracy of the model 0.6972477064220184 random_state 84\n",
      "accuracy of the model 0.6972477064220184 random_state 85\n",
      "accuracy of the model 0.6788990825688074 random_state 86\n",
      "accuracy of the model 0.7247706422018348 random_state 87\n",
      "accuracy of the model 0.6788990825688074 random_state 88\n",
      "accuracy of the model 0.6972477064220184 random_state 89\n",
      "accuracy of the model 0.6697247706422018 random_state 90\n",
      "accuracy of the model 0.7706422018348624 random_state 91\n",
      "accuracy of the model 0.6972477064220184 random_state 92\n",
      "accuracy of the model 0.7614678899082569 random_state 93\n",
      "accuracy of the model 0.7064220183486238 random_state 94\n",
      "accuracy of the model 0.7614678899082569 random_state 95\n",
      "accuracy of the model 0.7064220183486238 random_state 96\n",
      "accuracy of the model 0.7064220183486238 random_state 97\n",
      "accuracy of the model 0.6880733944954128 random_state 98\n",
      "accuracy of the model 0.7522935779816514 random_state 99\n",
      "accuracy of the model 0.6422018348623854 random_state 100\n",
      "accuracy of the model 0.7247706422018348 random_state 101\n",
      "accuracy of the model 0.6880733944954128 random_state 102\n",
      "accuracy of the model 0.7614678899082569 random_state 103\n",
      "accuracy of the model 0.7155963302752294 random_state 104\n",
      "accuracy of the model 0.7064220183486238 random_state 105\n",
      "accuracy of the model 0.7155963302752294 random_state 106\n",
      "accuracy of the model 0.7155963302752294 random_state 107\n",
      "accuracy of the model 0.7339449541284404 random_state 108\n",
      "accuracy of the model 0.7064220183486238 random_state 109\n",
      "accuracy of the model 0.7431192660550459 random_state 110\n",
      "accuracy of the model 0.7522935779816514 random_state 111\n",
      "accuracy of the model 0.7247706422018348 random_state 112\n",
      "accuracy of the model 0.7339449541284404 random_state 113\n",
      "accuracy of the model 0.7155963302752294 random_state 114\n",
      "accuracy of the model 0.6880733944954128 random_state 115\n",
      "accuracy of the model 0.7431192660550459 random_state 116\n",
      "accuracy of the model 0.6238532110091743 random_state 117\n",
      "accuracy of the model 0.6788990825688074 random_state 118\n",
      "accuracy of the model 0.6972477064220184 random_state 119\n",
      "accuracy of the model 0.7339449541284404 random_state 120\n",
      "accuracy of the model 0.7522935779816514 random_state 121\n",
      "accuracy of the model 0.7247706422018348 random_state 122\n",
      "accuracy of the model 0.7155963302752294 random_state 123\n",
      "accuracy of the model 0.7706422018348624 random_state 124\n",
      "accuracy of the model 0.6697247706422018 random_state 125\n",
      "accuracy of the model 0.6513761467889908 random_state 126\n",
      "accuracy of the model 0.6972477064220184 random_state 127\n",
      "accuracy of the model 0.8348623853211009 random_state 128\n",
      "accuracy of the optimum model 0.8348623853211009 random_state 128\n",
      "accuracy of the model 0.7247706422018348 random_state 129\n",
      "accuracy of the model 0.6972477064220184 random_state 130\n",
      "accuracy of the model 0.7614678899082569 random_state 131\n",
      "accuracy of the model 0.6697247706422018 random_state 132\n",
      "accuracy of the model 0.7064220183486238 random_state 133\n",
      "accuracy of the model 0.7064220183486238 random_state 134\n",
      "accuracy of the model 0.7247706422018348 random_state 135\n",
      "accuracy of the model 0.7798165137614679 random_state 136\n",
      "accuracy of the model 0.6972477064220184 random_state 137\n",
      "accuracy of the model 0.7431192660550459 random_state 138\n",
      "accuracy of the model 0.7614678899082569 random_state 139\n",
      "accuracy of the model 0.7155963302752294 random_state 140\n",
      "accuracy of the model 0.6972477064220184 random_state 141\n",
      "accuracy of the model 0.6972477064220184 random_state 142\n",
      "accuracy of the model 0.7431192660550459 random_state 143\n",
      "accuracy of the model 0.7064220183486238 random_state 144\n",
      "accuracy of the model 0.6972477064220184 random_state 145\n",
      "accuracy of the model 0.7155963302752294 random_state 146\n",
      "accuracy of the model 0.7431192660550459 random_state 147\n",
      "accuracy of the model 0.6972477064220184 random_state 148\n",
      "accuracy of the model 0.6880733944954128 random_state 149\n",
      "accuracy of the model 0.6422018348623854 random_state 150\n",
      "accuracy of the model 0.6788990825688074 random_state 151\n",
      "accuracy of the model 0.7431192660550459 random_state 152\n",
      "accuracy of the model 0.6697247706422018 random_state 153\n",
      "accuracy of the model 0.8073394495412844 random_state 154\n",
      "accuracy of the model 0.7431192660550459 random_state 155\n",
      "accuracy of the model 0.7155963302752294 random_state 156\n",
      "accuracy of the model 0.7889908256880734 random_state 157\n",
      "accuracy of the model 0.7064220183486238 random_state 158\n",
      "accuracy of the model 0.7155963302752294 random_state 159\n",
      "accuracy of the model 0.6880733944954128 random_state 160\n",
      "accuracy of the model 0.7431192660550459 random_state 161\n",
      "accuracy of the model 0.7247706422018348 random_state 162\n",
      "accuracy of the model 0.7614678899082569 random_state 163\n",
      "accuracy of the model 0.7064220183486238 random_state 164\n",
      "accuracy of the model 0.6972477064220184 random_state 165\n",
      "accuracy of the model 0.7247706422018348 random_state 166\n",
      "accuracy of the model 0.6697247706422018 random_state 167\n",
      "accuracy of the model 0.7247706422018348 random_state 168\n",
      "accuracy of the model 0.7339449541284404 random_state 169\n",
      "accuracy of the model 0.6697247706422018 random_state 170\n",
      "accuracy of the model 0.7706422018348624 random_state 171\n",
      "accuracy of the model 0.7247706422018348 random_state 172\n",
      "accuracy of the model 0.6605504587155964 random_state 173\n",
      "accuracy of the model 0.7706422018348624 random_state 174\n",
      "accuracy of the model 0.7431192660550459 random_state 175\n",
      "accuracy of the model 0.7064220183486238 random_state 176\n",
      "accuracy of the model 0.7431192660550459 random_state 177\n",
      "accuracy of the model 0.8073394495412844 random_state 178\n",
      "accuracy of the model 0.7247706422018348 random_state 179\n",
      "accuracy of the model 0.7339449541284404 random_state 180\n",
      "accuracy of the model 0.6697247706422018 random_state 181\n",
      "accuracy of the model 0.7064220183486238 random_state 182\n",
      "accuracy of the model 0.7339449541284404 random_state 183\n",
      "accuracy of the model 0.7247706422018348 random_state 184\n",
      "accuracy of the model 0.6788990825688074 random_state 185\n",
      "accuracy of the model 0.7155963302752294 random_state 186\n",
      "accuracy of the model 0.7339449541284404 random_state 187\n",
      "accuracy of the model 0.7431192660550459 random_state 188\n",
      "accuracy of the model 0.7064220183486238 random_state 189\n",
      "accuracy of the model 0.7247706422018348 random_state 190\n",
      "accuracy of the model 0.7339449541284404 random_state 191\n",
      "accuracy of the model 0.7798165137614679 random_state 192\n",
      "accuracy of the model 0.6972477064220184 random_state 193\n",
      "accuracy of the model 0.7339449541284404 random_state 194\n",
      "accuracy of the model 0.7247706422018348 random_state 195\n",
      "accuracy of the model 0.7155963302752294 random_state 196\n",
      "accuracy of the model 0.7064220183486238 random_state 197\n",
      "accuracy of the model 0.7064220183486238 random_state 198\n",
      "accuracy of the model 0.6972477064220184 random_state 199\n",
      "accuracy of the model 0.7431192660550459 random_state 200\n",
      "accuracy of the model 0.7247706422018348 random_state 201\n",
      "accuracy of the model 0.6697247706422018 random_state 202\n",
      "accuracy of the model 0.7798165137614679 random_state 203\n",
      "accuracy of the model 0.7339449541284404 random_state 204\n",
      "accuracy of the model 0.7155963302752294 random_state 205\n",
      "accuracy of the model 0.6697247706422018 random_state 206\n",
      "accuracy of the model 0.6880733944954128 random_state 207\n",
      "accuracy of the model 0.6788990825688074 random_state 208\n",
      "accuracy of the model 0.7247706422018348 random_state 209\n",
      "accuracy of the model 0.6697247706422018 random_state 210\n",
      "accuracy of the model 0.6697247706422018 random_state 211\n",
      "accuracy of the model 0.7064220183486238 random_state 212\n",
      "accuracy of the model 0.6697247706422018 random_state 213\n",
      "accuracy of the model 0.7155963302752294 random_state 214\n",
      "accuracy of the model 0.7798165137614679 random_state 215\n",
      "accuracy of the model 0.6880733944954128 random_state 216\n",
      "accuracy of the model 0.7155963302752294 random_state 217\n",
      "accuracy of the model 0.7981651376146789 random_state 218\n",
      "accuracy of the model 0.7339449541284404 random_state 219\n",
      "accuracy of the model 0.6605504587155964 random_state 220\n",
      "accuracy of the model 0.7155963302752294 random_state 221\n",
      "accuracy of the model 0.6422018348623854 random_state 222\n",
      "accuracy of the model 0.7431192660550459 random_state 223\n",
      "accuracy of the model 0.7798165137614679 random_state 224\n",
      "accuracy of the model 0.7247706422018348 random_state 225\n",
      "accuracy of the model 0.8073394495412844 random_state 226\n",
      "accuracy of the model 0.7706422018348624 random_state 227\n",
      "accuracy of the model 0.7155963302752294 random_state 228\n",
      "accuracy of the model 0.7431192660550459 random_state 229\n",
      "accuracy of the model 0.7155963302752294 random_state 230\n",
      "accuracy of the model 0.7431192660550459 random_state 231\n",
      "accuracy of the model 0.7339449541284404 random_state 232\n",
      "accuracy of the model 0.7339449541284404 random_state 233\n",
      "accuracy of the model 0.7431192660550459 random_state 234\n",
      "accuracy of the model 0.7247706422018348 random_state 235\n",
      "accuracy of the model 0.7981651376146789 random_state 236\n",
      "accuracy of the model 0.7155963302752294 random_state 237\n",
      "accuracy of the model 0.6697247706422018 random_state 238\n",
      "accuracy of the model 0.7064220183486238 random_state 239\n",
      "accuracy of the model 0.7706422018348624 random_state 240\n",
      "accuracy of the model 0.7889908256880734 random_state 241\n",
      "accuracy of the model 0.6330275229357798 random_state 242\n",
      "accuracy of the model 0.7064220183486238 random_state 243\n",
      "accuracy of the model 0.7431192660550459 random_state 244\n",
      "accuracy of the model 0.7614678899082569 random_state 245\n",
      "accuracy of the model 0.6972477064220184 random_state 246\n",
      "accuracy of the model 0.7431192660550459 random_state 247\n",
      "accuracy of the model 0.6972477064220184 random_state 248\n",
      "accuracy of the model 0.7339449541284404 random_state 249\n",
      "accuracy of the model 0.7155963302752294 random_state 250\n",
      "accuracy of the model 0.7614678899082569 random_state 251\n",
      "accuracy of the model 0.6513761467889908 random_state 252\n",
      "accuracy of the model 0.7798165137614679 random_state 253\n",
      "accuracy of the model 0.7981651376146789 random_state 254\n",
      "accuracy of the model 0.7431192660550459 random_state 255\n",
      "accuracy of the model 0.7247706422018348 random_state 256\n",
      "accuracy of the model 0.7247706422018348 random_state 257\n",
      "accuracy of the model 0.7431192660550459 random_state 258\n",
      "accuracy of the model 0.6880733944954128 random_state 259\n",
      "accuracy of the model 0.7798165137614679 random_state 260\n",
      "accuracy of the model 0.7981651376146789 random_state 261\n",
      "accuracy of the model 0.6697247706422018 random_state 262\n",
      "accuracy of the model 0.6605504587155964 random_state 263\n",
      "accuracy of the model 0.7155963302752294 random_state 264\n",
      "accuracy of the model 0.6972477064220184 random_state 265\n",
      "accuracy of the model 0.7798165137614679 random_state 266\n",
      "accuracy of the model 0.7339449541284404 random_state 267\n",
      "accuracy of the model 0.6697247706422018 random_state 268\n",
      "accuracy of the model 0.6880733944954128 random_state 269\n",
      "accuracy of the model 0.7431192660550459 random_state 270\n",
      "accuracy of the model 0.7522935779816514 random_state 271\n",
      "accuracy of the model 0.7155963302752294 random_state 272\n",
      "accuracy of the model 0.6972477064220184 random_state 273\n",
      "accuracy of the model 0.7064220183486238 random_state 274\n",
      "accuracy of the model 0.7889908256880734 random_state 275\n",
      "accuracy of the model 0.7155963302752294 random_state 276\n",
      "accuracy of the model 0.7614678899082569 random_state 277\n",
      "accuracy of the model 0.7339449541284404 random_state 278\n",
      "accuracy of the model 0.7431192660550459 random_state 279\n",
      "accuracy of the model 0.7155963302752294 random_state 280\n",
      "accuracy of the model 0.7431192660550459 random_state 281\n",
      "accuracy of the model 0.6513761467889908 random_state 282\n",
      "accuracy of the model 0.6788990825688074 random_state 283\n",
      "accuracy of the model 0.6972477064220184 random_state 284\n",
      "accuracy of the model 0.6697247706422018 random_state 285\n",
      "accuracy of the model 0.7706422018348624 random_state 286\n",
      "accuracy of the model 0.6880733944954128 random_state 287\n",
      "accuracy of the model 0.6788990825688074 random_state 288\n",
      "accuracy of the model 0.7431192660550459 random_state 289\n",
      "accuracy of the model 0.7155963302752294 random_state 290\n",
      "accuracy of the model 0.7155963302752294 random_state 291\n",
      "accuracy of the model 0.7431192660550459 random_state 292\n",
      "accuracy of the model 0.7339449541284404 random_state 293\n",
      "accuracy of the model 0.7247706422018348 random_state 294\n",
      "accuracy of the model 0.6880733944954128 random_state 295\n",
      "accuracy of the model 0.7064220183486238 random_state 296\n",
      "accuracy of the model 0.7431192660550459 random_state 297\n",
      "accuracy of the model 0.6697247706422018 random_state 298\n",
      "accuracy of the model 0.7155963302752294 random_state 299\n",
      "accuracy of the model 0.7431192660550459 random_state 300\n",
      "accuracy of the model 0.7247706422018348 random_state 301\n",
      "accuracy of the model 0.6880733944954128 random_state 302\n",
      "accuracy of the model 0.7247706422018348 random_state 303\n",
      "accuracy of the model 0.6422018348623854 random_state 304\n",
      "accuracy of the model 0.7614678899082569 random_state 305\n",
      "accuracy of the model 0.7431192660550459 random_state 306\n",
      "accuracy of the model 0.7522935779816514 random_state 307\n",
      "accuracy of the model 0.7247706422018348 random_state 308\n",
      "accuracy of the model 0.6605504587155964 random_state 309\n",
      "accuracy of the model 0.7155963302752294 random_state 310\n",
      "accuracy of the model 0.7155963302752294 random_state 311\n",
      "accuracy of the model 0.6788990825688074 random_state 312\n",
      "accuracy of the model 0.6880733944954128 random_state 313\n",
      "accuracy of the model 0.7522935779816514 random_state 314\n",
      "accuracy of the model 0.7614678899082569 random_state 315\n",
      "accuracy of the model 0.6880733944954128 random_state 316\n",
      "accuracy of the model 0.6605504587155964 random_state 317\n",
      "accuracy of the model 0.6880733944954128 random_state 318\n",
      "accuracy of the model 0.7431192660550459 random_state 319\n",
      "accuracy of the model 0.6697247706422018 random_state 320\n",
      "accuracy of the model 0.7155963302752294 random_state 321\n",
      "accuracy of the model 0.7614678899082569 random_state 322\n",
      "accuracy of the model 0.7064220183486238 random_state 323\n",
      "accuracy of the model 0.6972477064220184 random_state 324\n",
      "accuracy of the model 0.7522935779816514 random_state 325\n",
      "accuracy of the model 0.6972477064220184 random_state 326\n",
      "accuracy of the model 0.6972477064220184 random_state 327\n",
      "accuracy of the model 0.7798165137614679 random_state 328\n",
      "accuracy of the model 0.7155963302752294 random_state 329\n",
      "accuracy of the model 0.7064220183486238 random_state 330\n",
      "accuracy of the model 0.6972477064220184 random_state 331\n",
      "accuracy of the model 0.7247706422018348 random_state 332\n",
      "accuracy of the model 0.7614678899082569 random_state 333\n",
      "accuracy of the model 0.7706422018348624 random_state 334\n",
      "accuracy of the model 0.7247706422018348 random_state 335\n",
      "accuracy of the model 0.7247706422018348 random_state 336\n",
      "accuracy of the model 0.7339449541284404 random_state 337\n",
      "accuracy of the model 0.6788990825688074 random_state 338\n",
      "accuracy of the model 0.7431192660550459 random_state 339\n",
      "accuracy of the model 0.7706422018348624 random_state 340\n",
      "accuracy of the model 0.7155963302752294 random_state 341\n",
      "accuracy of the model 0.6788990825688074 random_state 342\n",
      "accuracy of the model 0.7064220183486238 random_state 343\n",
      "accuracy of the model 0.6788990825688074 random_state 344\n",
      "accuracy of the model 0.7155963302752294 random_state 345\n",
      "accuracy of the model 0.8165137614678899 random_state 346\n",
      "accuracy of the model 0.7339449541284404 random_state 347\n",
      "accuracy of the model 0.6788990825688074 random_state 348\n",
      "accuracy of the model 0.7247706422018348 random_state 349\n",
      "accuracy of the model 0.6880733944954128 random_state 350\n",
      "accuracy of the model 0.7798165137614679 random_state 351\n",
      "accuracy of the model 0.7431192660550459 random_state 352\n",
      "accuracy of the model 0.6788990825688074 random_state 353\n",
      "accuracy of the model 0.7155963302752294 random_state 354\n",
      "accuracy of the model 0.6972477064220184 random_state 355\n",
      "accuracy of the model 0.7889908256880734 random_state 356\n",
      "accuracy of the model 0.7889908256880734 random_state 357\n",
      "accuracy of the model 0.7706422018348624 random_state 358\n",
      "accuracy of the model 0.7064220183486238 random_state 359\n",
      "accuracy of the model 0.7064220183486238 random_state 360\n",
      "accuracy of the model 0.7339449541284404 random_state 361\n",
      "accuracy of the model 0.6788990825688074 random_state 362\n",
      "accuracy of the model 0.7155963302752294 random_state 363\n",
      "accuracy of the model 0.7339449541284404 random_state 364\n",
      "accuracy of the model 0.7614678899082569 random_state 365\n",
      "accuracy of the model 0.7339449541284404 random_state 366\n",
      "accuracy of the model 0.6972477064220184 random_state 367\n",
      "accuracy of the model 0.7431192660550459 random_state 368\n",
      "accuracy of the model 0.7339449541284404 random_state 369\n",
      "accuracy of the model 0.7614678899082569 random_state 370\n",
      "accuracy of the model 0.7706422018348624 random_state 371\n",
      "accuracy of the model 0.7064220183486238 random_state 372\n",
      "accuracy of the model 0.7614678899082569 random_state 373\n",
      "accuracy of the model 0.7706422018348624 random_state 374\n",
      "accuracy of the model 0.7522935779816514 random_state 375\n",
      "accuracy of the model 0.7339449541284404 random_state 376\n",
      "accuracy of the model 0.6788990825688074 random_state 377\n",
      "accuracy of the model 0.7064220183486238 random_state 378\n",
      "accuracy of the model 0.7431192660550459 random_state 379\n",
      "accuracy of the model 0.6880733944954128 random_state 380\n",
      "accuracy of the model 0.6972477064220184 random_state 381\n",
      "accuracy of the model 0.7155963302752294 random_state 382\n",
      "accuracy of the model 0.6697247706422018 random_state 383\n",
      "accuracy of the model 0.6972477064220184 random_state 384\n",
      "accuracy of the model 0.6697247706422018 random_state 385\n",
      "accuracy of the model 0.7706422018348624 random_state 386\n",
      "accuracy of the model 0.6880733944954128 random_state 387\n",
      "accuracy of the model 0.6605504587155964 random_state 388\n",
      "accuracy of the model 0.7339449541284404 random_state 389\n",
      "accuracy of the model 0.7431192660550459 random_state 390\n",
      "accuracy of the model 0.7981651376146789 random_state 391\n",
      "accuracy of the model 0.7064220183486238 random_state 392\n",
      "accuracy of the model 0.7431192660550459 random_state 393\n",
      "accuracy of the model 0.6880733944954128 random_state 394\n",
      "accuracy of the model 0.7064220183486238 random_state 395\n",
      "accuracy of the model 0.8073394495412844 random_state 396\n",
      "accuracy of the model 0.6788990825688074 random_state 397\n",
      "accuracy of the model 0.7614678899082569 random_state 398\n",
      "accuracy of the model 0.7064220183486238 random_state 399\n",
      "accuracy of the model 0.7339449541284404 random_state 400\n",
      "accuracy of the model 0.6422018348623854 random_state 401\n",
      "accuracy of the model 0.7522935779816514 random_state 402\n",
      "accuracy of the model 0.7064220183486238 random_state 403\n",
      "accuracy of the model 0.6513761467889908 random_state 404\n",
      "accuracy of the model 0.7247706422018348 random_state 405\n",
      "accuracy of the model 0.7706422018348624 random_state 406\n",
      "accuracy of the model 0.7431192660550459 random_state 407\n",
      "accuracy of the model 0.7247706422018348 random_state 408\n",
      "accuracy of the model 0.7155963302752294 random_state 409\n",
      "accuracy of the model 0.7155963302752294 random_state 410\n",
      "accuracy of the model 0.7247706422018348 random_state 411\n",
      "accuracy of the model 0.7155963302752294 random_state 412\n",
      "accuracy of the model 0.7522935779816514 random_state 413\n",
      "accuracy of the model 0.6697247706422018 random_state 414\n",
      "accuracy of the model 0.8073394495412844 random_state 415\n",
      "accuracy of the model 0.7247706422018348 random_state 416\n",
      "accuracy of the model 0.7339449541284404 random_state 417\n",
      "accuracy of the model 0.7431192660550459 random_state 418\n",
      "accuracy of the model 0.7064220183486238 random_state 419\n",
      "accuracy of the model 0.6697247706422018 random_state 420\n",
      "accuracy of the model 0.7247706422018348 random_state 421\n",
      "accuracy of the model 0.7339449541284404 random_state 422\n",
      "accuracy of the model 0.7064220183486238 random_state 423\n",
      "accuracy of the model 0.6697247706422018 random_state 424\n",
      "accuracy of the model 0.7339449541284404 random_state 425\n",
      "accuracy of the model 0.6422018348623854 random_state 426\n",
      "accuracy of the model 0.6880733944954128 random_state 427\n",
      "accuracy of the model 0.7614678899082569 random_state 428\n",
      "accuracy of the model 0.7247706422018348 random_state 429\n",
      "accuracy of the model 0.7064220183486238 random_state 430\n",
      "accuracy of the model 0.7614678899082569 random_state 431\n",
      "accuracy of the model 0.7522935779816514 random_state 432\n",
      "accuracy of the model 0.6880733944954128 random_state 433\n",
      "accuracy of the model 0.7431192660550459 random_state 434\n",
      "accuracy of the model 0.7431192660550459 random_state 435\n",
      "accuracy of the model 0.6880733944954128 random_state 436\n",
      "accuracy of the model 0.6880733944954128 random_state 437\n",
      "accuracy of the model 0.7247706422018348 random_state 438\n",
      "accuracy of the model 0.7431192660550459 random_state 439\n",
      "accuracy of the model 0.7155963302752294 random_state 440\n",
      "accuracy of the model 0.7155963302752294 random_state 441\n",
      "accuracy of the model 0.7339449541284404 random_state 442\n",
      "accuracy of the model 0.6788990825688074 random_state 443\n",
      "accuracy of the model 0.7614678899082569 random_state 444\n",
      "accuracy of the model 0.7522935779816514 random_state 445\n",
      "accuracy of the model 0.6788990825688074 random_state 446\n",
      "accuracy of the model 0.7706422018348624 random_state 447\n",
      "accuracy of the model 0.7064220183486238 random_state 448\n",
      "accuracy of the model 0.7155963302752294 random_state 449\n",
      "accuracy of the model 0.7247706422018348 random_state 450\n",
      "accuracy of the model 0.7247706422018348 random_state 451\n",
      "accuracy of the model 0.7339449541284404 random_state 452\n",
      "accuracy of the model 0.7339449541284404 random_state 453\n",
      "accuracy of the model 0.7431192660550459 random_state 454\n",
      "accuracy of the model 0.7064220183486238 random_state 455\n",
      "accuracy of the model 0.7431192660550459 random_state 456\n",
      "accuracy of the model 0.6513761467889908 random_state 457\n",
      "accuracy of the model 0.6880733944954128 random_state 458\n",
      "accuracy of the model 0.6697247706422018 random_state 459\n",
      "accuracy of the model 0.7522935779816514 random_state 460\n",
      "accuracy of the model 0.6880733944954128 random_state 461\n",
      "accuracy of the model 0.7431192660550459 random_state 462\n",
      "accuracy of the model 0.6788990825688074 random_state 463\n",
      "accuracy of the model 0.7064220183486238 random_state 464\n",
      "accuracy of the model 0.6880733944954128 random_state 465\n",
      "accuracy of the model 0.7522935779816514 random_state 466\n",
      "accuracy of the model 0.6880733944954128 random_state 467\n",
      "accuracy of the model 0.7064220183486238 random_state 468\n",
      "accuracy of the model 0.7339449541284404 random_state 469\n",
      "accuracy of the model 0.7339449541284404 random_state 470\n",
      "accuracy of the model 0.7064220183486238 random_state 471\n",
      "accuracy of the model 0.7339449541284404 random_state 472\n",
      "accuracy of the model 0.7522935779816514 random_state 473\n",
      "accuracy of the model 0.7522935779816514 random_state 474\n",
      "accuracy of the model 0.7339449541284404 random_state 475\n",
      "accuracy of the model 0.7247706422018348 random_state 476\n",
      "accuracy of the model 0.6513761467889908 random_state 477\n",
      "accuracy of the model 0.7247706422018348 random_state 478\n",
      "accuracy of the model 0.6972477064220184 random_state 479\n",
      "accuracy of the model 0.6697247706422018 random_state 480\n",
      "accuracy of the model 0.6972477064220184 random_state 481\n",
      "accuracy of the model 0.7431192660550459 random_state 482\n",
      "accuracy of the model 0.6880733944954128 random_state 483\n",
      "accuracy of the model 0.7247706422018348 random_state 484\n",
      "accuracy of the model 0.7064220183486238 random_state 485\n",
      "accuracy of the model 0.7339449541284404 random_state 486\n",
      "accuracy of the model 0.7614678899082569 random_state 487\n",
      "accuracy of the model 0.7522935779816514 random_state 488\n",
      "accuracy of the model 0.7064220183486238 random_state 489\n",
      "accuracy of the model 0.7522935779816514 random_state 490\n",
      "accuracy of the model 0.7614678899082569 random_state 491\n",
      "accuracy of the model 0.7614678899082569 random_state 492\n",
      "accuracy of the model 0.7247706422018348 random_state 493\n",
      "accuracy of the model 0.8440366972477065 random_state 494\n",
      "accuracy of the optimum model 0.8440366972477065 random_state 494\n",
      "accuracy of the model 0.7155963302752294 random_state 495\n",
      "accuracy of the model 0.7706422018348624 random_state 496\n",
      "accuracy of the model 0.7155963302752294 random_state 497\n",
      "accuracy of the model 0.7339449541284404 random_state 498\n",
      "accuracy of the model 0.7522935779816514 random_state 499\n",
      "accuracy of the model 0.7064220183486238 random_state 500\n",
      "accuracy of the model 0.7339449541284404 random_state 501\n",
      "accuracy of the model 0.7522935779816514 random_state 502\n",
      "accuracy of the model 0.6788990825688074 random_state 503\n",
      "accuracy of the model 0.6880733944954128 random_state 504\n",
      "accuracy of the model 0.7339449541284404 random_state 505\n",
      "accuracy of the model 0.6972477064220184 random_state 506\n",
      "accuracy of the model 0.7064220183486238 random_state 507\n",
      "accuracy of the model 0.7155963302752294 random_state 508\n",
      "accuracy of the model 0.7431192660550459 random_state 509\n",
      "accuracy of the model 0.7431192660550459 random_state 510\n",
      "accuracy of the model 0.7155963302752294 random_state 511\n",
      "accuracy of the model 0.7247706422018348 random_state 512\n",
      "accuracy of the model 0.7522935779816514 random_state 513\n",
      "accuracy of the model 0.7981651376146789 random_state 514\n",
      "accuracy of the model 0.7155963302752294 random_state 515\n",
      "accuracy of the model 0.7247706422018348 random_state 516\n",
      "accuracy of the model 0.7339449541284404 random_state 517\n",
      "accuracy of the model 0.7614678899082569 random_state 518\n",
      "accuracy of the model 0.6972477064220184 random_state 519\n",
      "accuracy of the model 0.7431192660550459 random_state 520\n",
      "accuracy of the model 0.6697247706422018 random_state 521\n",
      "accuracy of the model 0.7064220183486238 random_state 522\n",
      "accuracy of the model 0.7706422018348624 random_state 523\n",
      "accuracy of the model 0.7247706422018348 random_state 524\n",
      "accuracy of the model 0.6972477064220184 random_state 525\n",
      "accuracy of the model 0.7064220183486238 random_state 526\n",
      "accuracy of the model 0.6697247706422018 random_state 527\n",
      "accuracy of the model 0.7155963302752294 random_state 528\n",
      "accuracy of the model 0.7889908256880734 random_state 529\n",
      "accuracy of the model 0.7339449541284404 random_state 530\n",
      "accuracy of the model 0.6972477064220184 random_state 531\n",
      "accuracy of the model 0.7247706422018348 random_state 532\n",
      "accuracy of the model 0.7064220183486238 random_state 533\n",
      "accuracy of the model 0.7981651376146789 random_state 534\n",
      "accuracy of the model 0.6605504587155964 random_state 535\n",
      "accuracy of the model 0.7155963302752294 random_state 536\n",
      "accuracy of the model 0.7522935779816514 random_state 537\n",
      "accuracy of the model 0.7431192660550459 random_state 538\n",
      "accuracy of the model 0.7706422018348624 random_state 539\n",
      "accuracy of the model 0.7522935779816514 random_state 540\n",
      "accuracy of the model 0.7614678899082569 random_state 541\n",
      "accuracy of the model 0.7064220183486238 random_state 542\n",
      "accuracy of the model 0.7155963302752294 random_state 543\n",
      "accuracy of the model 0.7339449541284404 random_state 544\n",
      "accuracy of the model 0.7706422018348624 random_state 545\n",
      "accuracy of the model 0.6788990825688074 random_state 546\n",
      "accuracy of the model 0.6880733944954128 random_state 547\n",
      "accuracy of the model 0.8073394495412844 random_state 548\n",
      "accuracy of the model 0.7431192660550459 random_state 549\n",
      "accuracy of the model 0.7798165137614679 random_state 550\n",
      "accuracy of the model 0.6605504587155964 random_state 551\n",
      "accuracy of the model 0.7981651376146789 random_state 552\n",
      "accuracy of the model 0.7431192660550459 random_state 553\n",
      "accuracy of the model 0.7614678899082569 random_state 554\n",
      "accuracy of the model 0.6788990825688074 random_state 555\n",
      "accuracy of the model 0.7431192660550459 random_state 556\n",
      "accuracy of the model 0.6788990825688074 random_state 557\n",
      "accuracy of the model 0.6972477064220184 random_state 558\n",
      "accuracy of the model 0.7339449541284404 random_state 559\n",
      "accuracy of the model 0.6605504587155964 random_state 560\n",
      "accuracy of the model 0.7247706422018348 random_state 561\n",
      "accuracy of the model 0.7339449541284404 random_state 562\n",
      "accuracy of the model 0.6697247706422018 random_state 563\n",
      "accuracy of the model 0.7155963302752294 random_state 564\n",
      "accuracy of the model 0.7339449541284404 random_state 565\n",
      "accuracy of the model 0.7155963302752294 random_state 566\n",
      "accuracy of the model 0.6972477064220184 random_state 567\n",
      "accuracy of the model 0.7889908256880734 random_state 568\n",
      "accuracy of the model 0.7522935779816514 random_state 569\n",
      "accuracy of the model 0.7339449541284404 random_state 570\n",
      "accuracy of the model 0.6697247706422018 random_state 571\n",
      "accuracy of the model 0.7155963302752294 random_state 572\n",
      "accuracy of the model 0.7798165137614679 random_state 573\n",
      "accuracy of the model 0.7155963302752294 random_state 574\n",
      "accuracy of the model 0.7339449541284404 random_state 575\n",
      "accuracy of the model 0.6880733944954128 random_state 576\n",
      "accuracy of the model 0.7706422018348624 random_state 577\n",
      "accuracy of the model 0.7522935779816514 random_state 578\n",
      "accuracy of the model 0.7339449541284404 random_state 579\n",
      "accuracy of the model 0.8073394495412844 random_state 580\n",
      "accuracy of the model 0.6880733944954128 random_state 581\n",
      "accuracy of the model 0.7431192660550459 random_state 582\n",
      "accuracy of the model 0.7247706422018348 random_state 583\n",
      "accuracy of the model 0.7064220183486238 random_state 584\n",
      "accuracy of the model 0.7064220183486238 random_state 585\n",
      "accuracy of the model 0.7522935779816514 random_state 586\n",
      "accuracy of the model 0.7155963302752294 random_state 587\n",
      "accuracy of the model 0.6972477064220184 random_state 588\n",
      "accuracy of the model 0.7706422018348624 random_state 589\n",
      "accuracy of the model 0.7247706422018348 random_state 590\n",
      "accuracy of the model 0.7339449541284404 random_state 591\n",
      "accuracy of the model 0.7522935779816514 random_state 592\n",
      "accuracy of the model 0.7247706422018348 random_state 593\n",
      "accuracy of the model 0.8165137614678899 random_state 594\n",
      "accuracy of the model 0.6605504587155964 random_state 595\n",
      "accuracy of the model 0.7798165137614679 random_state 596\n",
      "accuracy of the model 0.7522935779816514 random_state 597\n",
      "accuracy of the model 0.8073394495412844 random_state 598\n",
      "accuracy of the model 0.7522935779816514 random_state 599\n",
      "accuracy of the model 0.7339449541284404 random_state 600\n",
      "accuracy of the model 0.6880733944954128 random_state 601\n",
      "accuracy of the model 0.7706422018348624 random_state 602\n",
      "accuracy of the model 0.7064220183486238 random_state 603\n",
      "accuracy of the model 0.6605504587155964 random_state 604\n",
      "accuracy of the model 0.7247706422018348 random_state 605\n",
      "accuracy of the model 0.7339449541284404 random_state 606\n",
      "accuracy of the model 0.6972477064220184 random_state 607\n",
      "accuracy of the model 0.7155963302752294 random_state 608\n",
      "accuracy of the model 0.6972477064220184 random_state 609\n",
      "accuracy of the model 0.7247706422018348 random_state 610\n",
      "accuracy of the model 0.6788990825688074 random_state 611\n",
      "accuracy of the model 0.7247706422018348 random_state 612\n",
      "accuracy of the model 0.7522935779816514 random_state 613\n",
      "accuracy of the model 0.6513761467889908 random_state 614\n",
      "accuracy of the model 0.7431192660550459 random_state 615\n",
      "accuracy of the model 0.6972477064220184 random_state 616\n",
      "accuracy of the model 0.7706422018348624 random_state 617\n",
      "accuracy of the model 0.6972477064220184 random_state 618\n",
      "accuracy of the model 0.6788990825688074 random_state 619\n",
      "accuracy of the model 0.7247706422018348 random_state 620\n",
      "accuracy of the model 0.6880733944954128 random_state 621\n",
      "accuracy of the model 0.7064220183486238 random_state 622\n",
      "accuracy of the model 0.7614678899082569 random_state 623\n",
      "accuracy of the model 0.8165137614678899 random_state 624\n",
      "accuracy of the model 0.7247706422018348 random_state 625\n",
      "accuracy of the model 0.7064220183486238 random_state 626\n",
      "accuracy of the model 0.6788990825688074 random_state 627\n",
      "accuracy of the model 0.6972477064220184 random_state 628\n",
      "accuracy of the model 0.6880733944954128 random_state 629\n",
      "accuracy of the model 0.7522935779816514 random_state 630\n",
      "accuracy of the model 0.7706422018348624 random_state 631\n",
      "accuracy of the model 0.7706422018348624 random_state 632\n",
      "accuracy of the model 0.7339449541284404 random_state 633\n",
      "accuracy of the model 0.7247706422018348 random_state 634\n",
      "accuracy of the model 0.7431192660550459 random_state 635\n",
      "accuracy of the model 0.7798165137614679 random_state 636\n",
      "accuracy of the model 0.7339449541284404 random_state 637\n",
      "accuracy of the model 0.7614678899082569 random_state 638\n",
      "accuracy of the model 0.6880733944954128 random_state 639\n",
      "accuracy of the model 0.7614678899082569 random_state 640\n",
      "accuracy of the model 0.7798165137614679 random_state 641\n",
      "accuracy of the model 0.7706422018348624 random_state 642\n",
      "accuracy of the model 0.7339449541284404 random_state 643\n",
      "accuracy of the model 0.7431192660550459 random_state 644\n",
      "accuracy of the model 0.7431192660550459 random_state 645\n",
      "accuracy of the model 0.7155963302752294 random_state 646\n",
      "accuracy of the model 0.6697247706422018 random_state 647\n",
      "accuracy of the model 0.7706422018348624 random_state 648\n",
      "accuracy of the model 0.8348623853211009 random_state 649\n",
      "accuracy of the model 0.6788990825688074 random_state 650\n",
      "accuracy of the model 0.6972477064220184 random_state 651\n",
      "accuracy of the model 0.6972477064220184 random_state 652\n",
      "accuracy of the model 0.6788990825688074 random_state 653\n",
      "accuracy of the model 0.8073394495412844 random_state 654\n",
      "accuracy of the model 0.6880733944954128 random_state 655\n",
      "accuracy of the model 0.7247706422018348 random_state 656\n",
      "accuracy of the model 0.7706422018348624 random_state 657\n",
      "accuracy of the model 0.6972477064220184 random_state 658\n",
      "accuracy of the model 0.6788990825688074 random_state 659\n",
      "accuracy of the model 0.7798165137614679 random_state 660\n",
      "accuracy of the model 0.7431192660550459 random_state 661\n",
      "accuracy of the model 0.7522935779816514 random_state 662\n",
      "accuracy of the model 0.7339449541284404 random_state 663\n",
      "accuracy of the model 0.7339449541284404 random_state 664\n",
      "accuracy of the model 0.7155963302752294 random_state 665\n",
      "accuracy of the model 0.7522935779816514 random_state 666\n",
      "accuracy of the model 0.6972477064220184 random_state 667\n",
      "accuracy of the model 0.6880733944954128 random_state 668\n",
      "accuracy of the model 0.7798165137614679 random_state 669\n",
      "accuracy of the model 0.6880733944954128 random_state 670\n",
      "accuracy of the model 0.7798165137614679 random_state 671\n",
      "accuracy of the model 0.7614678899082569 random_state 672\n",
      "accuracy of the model 0.7339449541284404 random_state 673\n",
      "accuracy of the model 0.7339449541284404 random_state 674\n",
      "accuracy of the model 0.6880733944954128 random_state 675\n",
      "accuracy of the model 0.7431192660550459 random_state 676\n",
      "accuracy of the model 0.7339449541284404 random_state 677\n",
      "accuracy of the model 0.7431192660550459 random_state 678\n",
      "accuracy of the model 0.7798165137614679 random_state 679\n",
      "accuracy of the model 0.7339449541284404 random_state 680\n",
      "accuracy of the model 0.7339449541284404 random_state 681\n",
      "accuracy of the model 0.6972477064220184 random_state 682\n",
      "accuracy of the model 0.7798165137614679 random_state 683\n",
      "accuracy of the model 0.7155963302752294 random_state 684\n",
      "accuracy of the model 0.7339449541284404 random_state 685\n",
      "accuracy of the model 0.7339449541284404 random_state 686\n",
      "accuracy of the model 0.7339449541284404 random_state 687\n",
      "accuracy of the model 0.7247706422018348 random_state 688\n",
      "accuracy of the model 0.6513761467889908 random_state 689\n",
      "accuracy of the model 0.7247706422018348 random_state 690\n",
      "accuracy of the model 0.7614678899082569 random_state 691\n",
      "accuracy of the model 0.7155963302752294 random_state 692\n",
      "accuracy of the model 0.7522935779816514 random_state 693\n",
      "accuracy of the model 0.6880733944954128 random_state 694\n",
      "accuracy of the model 0.7339449541284404 random_state 695\n",
      "accuracy of the model 0.7431192660550459 random_state 696\n",
      "accuracy of the model 0.6880733944954128 random_state 697\n",
      "accuracy of the model 0.7614678899082569 random_state 698\n",
      "accuracy of the model 0.6697247706422018 random_state 699\n",
      "accuracy of the model 0.7064220183486238 random_state 700\n",
      "accuracy of the model 0.6972477064220184 random_state 701\n",
      "accuracy of the model 0.7155963302752294 random_state 702\n",
      "accuracy of the model 0.6422018348623854 random_state 703\n",
      "accuracy of the model 0.7064220183486238 random_state 704\n",
      "accuracy of the model 0.7247706422018348 random_state 705\n",
      "accuracy of the model 0.7889908256880734 random_state 706\n",
      "accuracy of the model 0.7706422018348624 random_state 707\n",
      "accuracy of the model 0.7614678899082569 random_state 708\n",
      "accuracy of the model 0.7155963302752294 random_state 709\n",
      "accuracy of the model 0.6880733944954128 random_state 710\n",
      "accuracy of the model 0.7889908256880734 random_state 711\n",
      "accuracy of the model 0.8165137614678899 random_state 712\n",
      "accuracy of the model 0.7614678899082569 random_state 713\n",
      "accuracy of the model 0.7155963302752294 random_state 714\n",
      "accuracy of the model 0.7614678899082569 random_state 715\n",
      "accuracy of the model 0.7522935779816514 random_state 716\n",
      "accuracy of the model 0.6513761467889908 random_state 717\n",
      "accuracy of the model 0.7431192660550459 random_state 718\n",
      "accuracy of the model 0.7431192660550459 random_state 719\n",
      "accuracy of the model 0.7247706422018348 random_state 720\n",
      "accuracy of the model 0.7706422018348624 random_state 721\n",
      "accuracy of the model 0.7522935779816514 random_state 722\n",
      "accuracy of the model 0.6697247706422018 random_state 723\n",
      "accuracy of the model 0.6972477064220184 random_state 724\n",
      "accuracy of the model 0.7431192660550459 random_state 725\n",
      "accuracy of the model 0.7798165137614679 random_state 726\n",
      "accuracy of the model 0.7247706422018348 random_state 727\n",
      "accuracy of the model 0.6513761467889908 random_state 728\n",
      "accuracy of the model 0.6697247706422018 random_state 729\n",
      "accuracy of the model 0.7247706422018348 random_state 730\n",
      "accuracy of the model 0.7798165137614679 random_state 731\n",
      "accuracy of the model 0.7431192660550459 random_state 732\n",
      "accuracy of the model 0.7247706422018348 random_state 733\n",
      "accuracy of the model 0.7706422018348624 random_state 734\n",
      "accuracy of the model 0.6422018348623854 random_state 735\n",
      "accuracy of the model 0.6422018348623854 random_state 736\n",
      "accuracy of the model 0.7155963302752294 random_state 737\n",
      "accuracy of the model 0.7339449541284404 random_state 738\n",
      "accuracy of the model 0.6880733944954128 random_state 739\n",
      "accuracy of the model 0.7614678899082569 random_state 740\n",
      "accuracy of the model 0.7155963302752294 random_state 741\n",
      "accuracy of the model 0.6697247706422018 random_state 742\n",
      "accuracy of the model 0.7889908256880734 random_state 743\n",
      "accuracy of the model 0.7798165137614679 random_state 744\n",
      "accuracy of the model 0.8348623853211009 random_state 745\n",
      "accuracy of the model 0.7431192660550459 random_state 746\n",
      "accuracy of the model 0.7431192660550459 random_state 747\n",
      "accuracy of the model 0.6972477064220184 random_state 748\n",
      "accuracy of the model 0.6788990825688074 random_state 749\n",
      "accuracy of the model 0.7247706422018348 random_state 750\n",
      "accuracy of the model 0.7247706422018348 random_state 751\n",
      "accuracy of the model 0.6972477064220184 random_state 752\n",
      "accuracy of the model 0.6422018348623854 random_state 753\n",
      "accuracy of the model 0.7339449541284404 random_state 754\n",
      "accuracy of the model 0.6788990825688074 random_state 755\n",
      "accuracy of the model 0.7431192660550459 random_state 756\n",
      "accuracy of the model 0.7889908256880734 random_state 757\n",
      "accuracy of the model 0.7614678899082569 random_state 758\n",
      "accuracy of the model 0.7339449541284404 random_state 759\n",
      "accuracy of the model 0.7339449541284404 random_state 760\n",
      "accuracy of the model 0.7431192660550459 random_state 761\n",
      "accuracy of the model 0.7798165137614679 random_state 762\n",
      "accuracy of the model 0.6697247706422018 random_state 763\n",
      "accuracy of the model 0.7064220183486238 random_state 764\n",
      "accuracy of the model 0.7614678899082569 random_state 765\n",
      "accuracy of the model 0.7247706422018348 random_state 766\n",
      "accuracy of the model 0.7064220183486238 random_state 767\n",
      "accuracy of the model 0.7614678899082569 random_state 768\n",
      "accuracy of the model 0.7431192660550459 random_state 769\n",
      "accuracy of the model 0.7247706422018348 random_state 770\n",
      "accuracy of the model 0.6513761467889908 random_state 771\n",
      "accuracy of the model 0.7064220183486238 random_state 772\n",
      "accuracy of the model 0.7064220183486238 random_state 773\n",
      "accuracy of the model 0.7614678899082569 random_state 774\n",
      "accuracy of the model 0.7431192660550459 random_state 775\n",
      "accuracy of the model 0.6788990825688074 random_state 776\n",
      "accuracy of the model 0.6972477064220184 random_state 777\n",
      "accuracy of the model 0.7064220183486238 random_state 778\n",
      "accuracy of the model 0.6972477064220184 random_state 779\n",
      "accuracy of the model 0.7431192660550459 random_state 780\n",
      "accuracy of the model 0.7339449541284404 random_state 781\n",
      "accuracy of the model 0.6880733944954128 random_state 782\n",
      "accuracy of the model 0.6788990825688074 random_state 783\n",
      "accuracy of the model 0.6880733944954128 random_state 784\n",
      "accuracy of the model 0.6972477064220184 random_state 785\n",
      "accuracy of the model 0.7155963302752294 random_state 786\n",
      "accuracy of the model 0.6788990825688074 random_state 787\n",
      "accuracy of the model 0.7614678899082569 random_state 788\n",
      "accuracy of the model 0.8165137614678899 random_state 789\n",
      "accuracy of the model 0.7614678899082569 random_state 790\n",
      "accuracy of the model 0.7431192660550459 random_state 791\n",
      "accuracy of the model 0.7981651376146789 random_state 792\n",
      "accuracy of the model 0.6972477064220184 random_state 793\n",
      "accuracy of the model 0.7247706422018348 random_state 794\n",
      "accuracy of the model 0.6788990825688074 random_state 795\n",
      "accuracy of the model 0.7614678899082569 random_state 796\n",
      "accuracy of the model 0.7339449541284404 random_state 797\n",
      "accuracy of the model 0.7155963302752294 random_state 798\n",
      "accuracy of the model 0.7706422018348624 random_state 799\n"
     ]
    }
   ],
   "source": [
    "# Finding the random state \n",
    "maxAc=0\n",
    "maxrs=0\n",
    "\n",
    "for i in range(1,800):\n",
    "    x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=i)\n",
    "    sc=SVC()\n",
    "    sc.fit(x_train, y_train)\n",
    "    pred=sc.predict(x_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    print('accuracy of the model', acc,'random_state', i)\n",
    "    \n",
    "    if acc>maxAc:\n",
    "        maxAc=acc\n",
    "        maxrs=i\n",
    "        print ('accuracy of the optimum model', acc,'random_state', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc7b068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum accuracy is obtaned in 0.8440366972477065 in random state 494\n"
     ]
    }
   ],
   "source": [
    "print ('Optimum accuracy is obtaned in', maxAc, 'in random state', maxrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c71982ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7614678899082569 random_state 494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.43      0.58        42\n",
      "           1       0.73      0.97      0.83        67\n",
      "\n",
      "    accuracy                           0.76       109\n",
      "   macro avg       0.82      0.70      0.71       109\n",
      "weighted avg       0.80      0.76      0.74       109\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.43      0.58        42\n",
      "           1       0.73      0.97      0.83        67\n",
      "\n",
      "    accuracy                           0.76       109\n",
      "   macro avg       0.82      0.70      0.71       109\n",
      "weighted avg       0.80      0.76      0.74       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=494)\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "pred1=lr.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred1)\n",
    "print('accuracy of the model', acc,'random_state', 494)\n",
    "print(classification_report(y_test,pred1))\n",
    "print(classification_report(y_test,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7d88fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7155963302752294 random_state 224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.58        35\n",
      "           1       0.80      0.77      0.79        74\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.68      0.69      0.68       109\n",
      "weighted avg       0.72      0.72      0.72       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=224)\n",
    "kn=KNeighborsClassifier()\n",
    "kn.fit(x_train, y_train)\n",
    "pred2=kn.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred2)\n",
    "print('accuracy of the model', acc,'random_state', 224)\n",
    "print(classification_report(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a5545a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7247706422018348 random_state 939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.71        49\n",
      "           1       0.77      0.72      0.74        60\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.72      0.73      0.72       109\n",
      "weighted avg       0.73      0.72      0.73       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=939)\n",
    "de=DecisionTreeClassifier()\n",
    "de.fit(x_train, y_train)\n",
    "pred3=de.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred3)\n",
    "print('accuracy of the model', acc,'random_state', 939)\n",
    "print(classification_report(y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "560435a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "accuracy of the model 0.7889908256880734 random_state 494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.64      0.70        42\n",
      "           1       0.80      0.88      0.84        67\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.78      0.76      0.77       109\n",
      "weighted avg       0.79      0.79      0.78       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=494)\n",
    "xe=XGBRFClassifier()\n",
    "xe.fit(x_train, y_train)\n",
    "pred4=xe.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred4)\n",
    "print('accuracy of the model', acc,'random_state', 494)\n",
    "print(classification_report(y_test,pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebeb22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7339449541284404 random_state 711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67        44\n",
      "           1       0.78      0.77      0.78        65\n",
      "\n",
      "    accuracy                           0.73       109\n",
      "   macro avg       0.72      0.73      0.72       109\n",
      "weighted avg       0.73      0.73      0.73       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=711)\n",
    "ad=AdaBoostClassifier()\n",
    "ad.fit(x_train, y_train)\n",
    "pred5=ad.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred5)\n",
    "print('accuracy of the model', acc,'random_state', 711)\n",
    "print(classification_report(y_test,pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c9dab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model 0.7706422018348624 random_state 494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.50      0.63        42\n",
      "           1       0.75      0.94      0.83        67\n",
      "\n",
      "    accuracy                           0.77       109\n",
      "   macro avg       0.79      0.72      0.73       109\n",
      "weighted avg       0.78      0.77      0.75       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=494)\n",
    "sc=SVC()\n",
    "sc.fit(x_train, y_train)\n",
    "pred6=sc.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred6)\n",
    "print('accuracy of the model', acc,'random_state', 494)\n",
    "print(classification_report(y_test,pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "040504cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting ROC and AUC curves\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "fpr1,tpr1,thresholds=roc_curve(y_test,pred1)\n",
    "roc_auc1=auc(fpr1,tpr1)\n",
    "fpr2,tpr2,thresholds=roc_curve(y_test,pred2)\n",
    "roc_auc2=auc(fpr2,tpr2)\n",
    "fpr3,tpr3,thresholds=roc_curve(y_test,pred3)\n",
    "roc_auc3=auc(fpr3,tpr3)\n",
    "fpr4,tpr4,thresholds=roc_curve(y_test,pred4)\n",
    "roc_auc4=auc(fpr4,tpr4)\n",
    "fpr5,tpr5,thresholds=roc_curve(y_test,pred5)\n",
    "roc_auc5=auc(fpr5,tpr5)\n",
    "fpr6,tpr6,thresholds=roc_curve(y_test,pred6)\n",
    "roc_auc6=auc(fpr6,tpr6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bac03d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007722007722008 0.41312741312741313 0.4552123552123552 0.7820463320463321 0.5295366795366796 0.7872586872586873\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc1,roc_auc2,roc_auc3,roc_auc4,roc_auc5,roc_auc6)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17754757",
   "metadata": {},
   "source": [
    "roc_auc1 has the maximum arear under the curve i.e. 0.800772200772200 which is logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "95d0e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso,RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5febc4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(normalize=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(normalize=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(normalize=True)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasscv=LassoCV(alphas=None, max_iter=1000,normalize=True)\n",
    "lasscv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd655de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=lasscv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd27d4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011393027147754856"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "74d7a023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.0011393027147754856)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0011393027147754856)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.0011393027147754856)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg=Lasso(alpha)\n",
    "lasso_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "48298aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35694774982570376"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d50eb68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=array([0.0001, 0.0101, 0.0201, 0.0301, 0.0401, 0.0501, 0.0601, 0.0701,\n",
       "       0.0801, 0.0901]),\n",
       "        normalize=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV(alphas=array([0.0001, 0.0101, 0.0201, 0.0301, 0.0401, 0.0501, 0.0601, 0.0701,\n",
       "       0.0801, 0.0901]),\n",
       "        normalize=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeCV(alphas=array([0.0001, 0.0101, 0.0201, 0.0301, 0.0401, 0.0501, 0.0601, 0.0701,\n",
       "       0.0801, 0.0901]),\n",
       "        normalize=True)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv=RidgeCV(alphas=np.arange(0.0001,0.1,0.01), normalize=True)\n",
    "ridgecv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5d29491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0901"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "80ce9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm= Ridge(alpha=ridgecv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20b87f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.0901)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.0901)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.0901)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d26cb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3581139009642581"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6baa194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [3, 2,1, 0.1, 0.01],\n",
    "              'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "872324c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are  {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "g=GridSearchCV(SVC(),param_grid=params)\n",
    "g.fit(x_train,y_train)\n",
    "print('The best parameters are ', g.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "667a1dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8440366972477065"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(prin_comp,y_train_ns,test_size=.20, random_state=494)\n",
    "sc=SVC(C=10, gamma=1, kernel='rbf')\n",
    "sc.fit(x_train, y_train)\n",
    "pred=sc.predict(x_test)\n",
    "acc=accuracy_score(y_test,pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'lo'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lo_dict,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be235b91",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The loan application status data is analyzed and different techniques like encoding and PCA was used and the model was built. The model is trained in SVC with 84.40366972477065 and logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
